---
output: 
  html_document:default
  html_notebook:default
---

# 回帰分析
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, collapse=TRUE)
```

```{r message=FALSE, warning=FALSE}
library(AER)
```


仮想的に以下のようにデータを生成する.
```{r}
N <- 100
x<-runif(N)
w<-sample(c("H","T"),N,replace=TRUE)
y <- 10 + 2*x + ifelse(w=="H",1,0) + rnorm(N)
df <- data.frame(w,x,y)
```

```{r}
plot(y~x)
```


## 単回帰モデル
次の単回帰モデルを考えてる.

$$
y = \alpha + \beta x + u
$$
ここで $x$ は説明変数で,  $y$ は被説明変数である. $u$ は誤差項である.
パラメータとして $\alpha$ は切片パラメータ, $\beta$ は傾きパラメータである.


次の仮定を置いている.

+ $(x_i,y_i)$ は独立同一分布にしたがう.
+ $E[u_i]=0$ である.
+ $u_i$ と $x_i$ は独立である.
+ $u_i$ は正規分布にしたがう.

このとき最小二乗推定量は一致で, 不偏であり, 正規分布にしたがう.
一致とは推定量が観測値を増やすことによって真のパラメータに (確率) 収束することある.
不偏とは推定量の期待値が真のパラメータになることである.
また他の線形不偏推定量のなかで最も分散が小さいことも知られている.


R で回帰分析を実施するには `lm` を実施する.
```{r}
fm <- lm(y ~ x, data=df)
```

`fm` 自体はリストであり, 以下の要素がある.
```{r}
typeof(fm)
names(fm)
```

係数は次のコマンドを実施する.
```{r}
coef(fm)
# coefficients(fm)
```

傾きの推定値は以下でも実行可能である.
```{r}
with(df, cov(x,y)/var(x))
```


作図すると以下のようになる.
```{r}
plot(y~x,data=df)
abline(fm)
```

残差は次のコマンドを実施する.
```{r}
head(resid(fm))
# residuals(fm)
# with(fm, residuals)
```

予測値は次のコマンドを実施する.
```{r}
head(fitted(fm))
# fitted.values(fm)
# with(fm, fitted.values)
```

残差自乗和は次のコマンドを実施する.
```{r}
deviance(fm)
sum(resid(fm)^2)
```

### ティー検定
その結果を見るには `summary` を実施する.
```{r}
summary(fm)
```

これをみれば各変数の係数がゼロのティー検定の結果が示されている.
他にも, 残差標準誤差, 決定係数, 修正済み決定係数, 全ての係数がゼロであるエフ検定の結果も示されている.

`summary(fm)` もリストであり, それぞれの要素は以下である.
```{r}
typeof(summary(fm))
names(summary(fm))
```

単なる `fm` と同じ名前もあるが, 中身が違っている場合もある.
例えば `residuals` は同じであるが, 係数はより情報が加わっている.
```{r}
coef(summary(fm))
# coefficients(summary(fm))
```

残差の標準誤差は次のようにして得られる.
```{r}
with(summary(fm),sigma)
sqrt(deviance(fm)/df.residual(fm))
```

決定係数は次のようにして計算する.
```{r}
with(summary(fm),r.squared)
1-deviance(fm)/with(df, sum((y-mean(y))^2))
```

調整済み決定係数は次のようにして計算する.
```{r}
with(summary(fm),adj.r.squared)
1-(deviance(fm)/df.residual(fm))/with(df, sum((y-mean(y))^2/(nrow(df)-1)))
```



### 対数変換
次のモデルを考える.
$$
y = \alpha + \beta \log(x) + u
$$

対数変換をおこなう場合, `log` を用いるとよい.
```{r}
fm <- lm(y~log(x),data=df)
summary(fm)
```

作図すると以下のようになる.
```{r}
plot(y~log(x),data=df)
abline(fm)
```

被説明変数が対数の場合も同様である.
```{r}
fm <- lm(log(y)~x,data=df)
summary(fm)
```

作図すると以下のようになる.
```{r}
plot(log(y)~x,data=df)
abline(fm)
```



### 切片なし回帰モデル
次のモデルを考える.
$$
y = \beta x + u
$$

切片なしモデルを推定したい場合は次のように `-1` とする.
```{r}
fm <- lm(y~x-1,data=df)
summary(fm)
```

もしくは `+0` を加える.
```{r}
fm <- lm(y~x+0,data=df)
summary(fm)
```



## 重回帰モデル
説明変数として $w$ を加えたモデルを考える.
$$
y = \alpha + \beta x +\gamma w+ u
$$

暗黙に次の仮定を置いている.

+ $(w_i, x_i,y_i)$ は独立同一分布にしたがう.
+ 誤差項の期待値はゼロである. $E[u_i]=0$ である.
+ 誤差項 $u_i$ は説明変数 $(x_i, w_i)$ に対して独立である.
+ 誤差項 $u_i$ は正規分布にしたがう.
+ 説明変数間に多重共線性は存在しない. つまり $x_i$ は $w_i$ の一次変換で表せない.

説明変数を加えたいときには `+` と変数名を使うことができる. 
```{r}
fm <- lm(y~x+w,data=df)
summary(fm)
```

R の特徴は因子もとくに変換することなくダミー変数として扱える.

### 自乗項
説明変数として自乗項を加えたモデルを考える.
$$
y = \alpha + \beta x + \gamma x^2 + u
$$

R では単に自乗するのでなく `I(x^2)` としなければならない.
```{r}
fm <- lm(y~x+I(x^2),data=df)
summary(fm)
```

### 交差項
説明変数として交差項を加えたモデルを考える.
$$
y = \alpha + \beta x + \gamma w + \delta xw + u
$$

説明変数 `x` と `w`の自乗項は自乗項は `x:w` である.
```{r}
fm<-lm(y~x+w+x:w,data=df)
summary(fm)
```

もしくは以下のように `*` を使って簡便的に表せる.
```{r}
fm <- lm(y~x*w,data=df)
summary(fm)
```

### エフ検定
今, 帰無仮説が
$$
y = \alpha + \beta x + u
$$
で, 対立仮説が
$$
y = \alpha + \beta x + \gamma w + \delta xw + u
$$
となる検定を実施したい. 

これは複数の係数がゼロであるエフ検定である.
対立仮説の残差自乗和を $SSR$ とし, その自由度を $df$ とする.
自由度は観測数から説明変数の数を減じた数である.
帰無仮説の残差自乗和を $SSR_0$ とし, 制約の数を $q$ とする.
制約の数は帰無仮説の自由度から帰無仮説の自由度を差し引いた数である.
このとき, 以下のF値は帰無仮説が正しいもと自由度 $df$ と $q$ のF分布にしたがう.
$$
\frac{(SSR_0-SSR)/q}{SSR/df}
$$

R でF値は次のようにして算出する.
```{r}
fm0 <- lm(y~x,data=df)
fm1 <- lm(y~x*w,data=df)
dof <- fm1$df
q <- fm0$df-dof
SSR0 <- deviance(fm0)
SSR <- deviance(fm1)
(F <- ((SSR0-SSR)/q)/(SSR/dof))
```

この時のP値は以下である.
```{r}
1-pf(F,df1=q,df2=dof)
```

これらの手順はコマンド `anova` を用いれば簡単に実現できる.
```{r}
anova(fm0,fm1)
```

順番を変えても, 検定統計量自体に変更はない.
```{r}
anova(fm1,fm0)
```

## 正規性の仮定について
単回帰において以下の仮定を置いていた.

+ $(x_i,y_i)$ は独立同一分布にしたがう.
+ $E[u_i]=0$ である.
+ $u_i$ と $x_i$ は独立である.
+ $u_i$ は正規分布にしたがう.

十分な観測値が得られるばあい, $u_i$ が正規分布にしたがっていないくても, 中心極限定理定理より, 最小二乗法推定量は正規分布に近似できる.

ここの係数ゼロのティー検定について, ライブラリ `AER` を導入して `coeftest` を用いればよい.
```{r}
coeftest(fm0,df=Inf)
```
ただ十分なデータのもとではティー値のままでもよい.

同様に複数制約の場合, エフ検定統計量に制約の数を乗じた統計量が
自由度が制約数のカイ二乗分布にしたがうことが知られている.
これをR で実施するには `waldtest` を用いればよい. 
```{r}
waldtest(fm0,fm1,test="Chisq")
```
エフ検定も十分なデータのもとではそのままでよいであろう.

オプション `test` を付けなければエフ検定を実施する.
```{r}
waldtest(fm0,fm1)
```
これは `anova` と同じである.
```{r}
anova(fm0,fm1)
```

複数制約の検定としてLM検定というのもある.
制約付きの回帰分析を実行し, その残差を制約なしのモデルの説明変数に回帰する.
その決定係数に観測数を掛けた統計量が自由どが制約の数のカイ二乗分布にしたがうことが知られている.
```{r}
lmt <- lm(I(resid(fm1))~w*x,data=df)
(lmt <- nrow(df)*summary(lmt)$r.squared)
1-pchisq(lmt,df=1)
```

## 誤差項と説明変数が独立の仮定について
また $u_i$ と $x_i$ は独立でなく, $u_i$ と $x_i$ が無相関という弱い条件のもとでも,
一致推定量であることが知られている.
ただ不偏推定量は保証できない. また 線形推定量のなかで最小の分散とも言えない.^[
正確にいえば, 不偏推定量のとめには条件付き期待値が説明変数に依存しないことが必要である. また線形推定量のなかで最小の分散になるためには
条件付き分散が説明変数に依存しないことが必要である. ]
また独立のときの標準誤差の推定量が一致推定量でない.

ただし, 別の分散のもとで正規分布に近似できることがしられている.^[
正確には観測される変数に4次のモーメントが存在するという仮定が必要となる.
この仮定の直感的な意味は異常値が存在しないことである.]
つまり, 説明変数と誤差項が無相関であるが, 独立とまでは言い切れない場合,
最小二乗推定量を実行した際, 別の方法で分散を推定する必要がある.
この別の分散をロバスト分散という.

R でロバスト分散を推定するにはパッケージ `AER` を導入するのが簡単である.
は次のコマンド `coeftest` を実行すればよい.
```{r message=FALSE, warning=FALSE}
coeftest(fm1,vcov=vcovHC)
```

先の値と標準誤差が違っていることが確認できるであろう.
ただこの値は STATA と少し異なっている. STATA と同じにするには
```{r}
coeftest(fm1,vcov=vcovHC(fm1,type="HC1"))
```
としなければならない.

またティー分布でなく正規分布とすることもできる.
```{r}
coeftest(fm0,vcov=vcovHC,df=Inf)
```

複数の係数についての検定は `waldtest` を実行すればよい.
```{r}
waldtest(fm0,fm1,vcov=vcovHC)
```

先の結果はエフ検定であるが, カイ二乗検定を実施するには以下を実施すればよい.
```{r}
waldtest(fm0,fm1,vcov=vcovHC, test="Chisq")
```


### 分散均一の検定
誤差項が説明変数と独立のときと無相関のときでは標準誤差の推定量が異なる.
正確にいうと, 条件付き分散が説明変数に依存するかどうかによって標準誤差の推定量が異なる. このことは分散均一と呼ばれている.

誤差項の分散が均一かどうかは検定可能である.
有名な検定方法としてBP (Breusch-Pagan) 検定というものがある.
BP検定は帰無仮説が分散均一で, 対立仮説が分散が説明変数と線形関係になっている場合の検定である.

残差の自乗を被説明変数として回帰分析をおこない,
その決定係数に観測数をかけたものが検定統計量となる.
```{r}
bpt <- lm(I(resid(fm1)^2)~w*x,data=df)
(bpt <- nrow(df)*summary(bpt)$r.squared)
1-pchisq(bpt,df=3)
```

ここでの例ではP値が5%を超えているので帰無仮説を棄却できないので,
分散均一を仮定してよいことが示唆されている.

R では以下のように実施すればよい.
```{r}
bptest(fm1)
```

これまでのBPテストは誤差項の分散が説明変数の線形関係あることを暗黙に仮定している.
非線形性を考慮するために説明変数の二次項を導入した分散不均一性の検定をホワイト検定という.
説明変数が複数ある場合ホワイト検定は煩雑になるため, 
被説明変数の予測値を使って計算することがある.
そのときホワイトテストは以下で実施する.
```{r}
wht <- lm(I(resid(fm1)^2)~fitted(fm1)+I(fitted(fm1)^2),data=df)
(wht <- nrow(df)*summary(wht)$r.squared)
1-pchisq(wht,df=2)
```
ホワイト検定でも分散均一が示唆されている.

もしくは以下を実行する.
```{r}
bptest(fm1,~fitted(fm1)+I(fitted(fm1)^2))
```

このように分散均一性は検定することが可能であるが, そもそも分散均一が疑われる場合は,
ロバスト分散で推定するので十分であるため最近の実証分析ではこの検定は実施されない.



