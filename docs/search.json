[
  {
    "objectID": "01-base.html",
    "href": "01-base.html",
    "title": "2  R の基本",
    "section": "",
    "text": "2.1 電卓としての R\nR は電卓としても利用できる。 代表的な算術演算子を以下に示す。\n演算は一般的な優先順位に従って処理されるが、() で囲めば計算の順序を明示的に指定できる。\n5 + 2\n## [1] 7\n5 - 2\n## [1] 3\n5 * 2\n## [1] 10\n5 / 2\n## [1] 2.5\n5 ^ 2\n## [1] 25\n5 ** 2\n## [1] 25\n5 %% 2\n## [1] 1\n5 %/% 2\n## [1] 2",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>R の基本</span>"
    ]
  },
  {
    "objectID": "01-base.html#電卓としての-r",
    "href": "01-base.html#電卓としての-r",
    "title": "2  R の基本",
    "section": "",
    "text": "演算子\n説明\n例\n\n\n\n\n+\n足し算\n5 + 2 = 7\n\n\n-\n引き算\n5 - 2 = 3\n\n\n*\n掛け算\n5 * 2 = 10\n\n\n/\n割り算\n5 / 2 = 2.5\n\n\n^, **\nべき算\n5 ^ 2 = 25, 5 ** 2 = 25\n\n\n%%\n割り算の余り\n5 %% 2 = 1\n\n\n%/%\n割り算の切り下げ\n5 %/% 2 = 2",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>R の基本</span>"
    ]
  },
  {
    "objectID": "01-base.html#関数電卓としての-r",
    "href": "01-base.html#関数電卓としての-r",
    "title": "2  R の基本",
    "section": "2.2 関数電卓としての R",
    "text": "2.2 関数電卓としての R\nR は関数電卓のようにさまざまな関数を呼び出して計算できる。たとえば以下の関数がある。\n\n\n\n関数\n説明\n\n\n\n\nsqrt()\n平方根 \\(\\sqrt{\\cdot}\\)\n\n\nexp()\n指数\n\n\nlog()\n対数\n\n\nfactorial()\n階乗\n\n\nchoose()\n組み合わせ\n\n\nabs()\n絶対値\n\n\nround()\n四捨五入\n\n\nfloor()\n切り下げ\n\n\nceiling()\n切り上げ\n\n\n\n\nsqrt(10)\n## [1] 3.162278\nexp(10)\n## [1] 22026.47\nlog(10)\n## [1] 2.302585\nfactorial(4)\n## [1] 24\nchoose(4,2)\n## [1] 6\nabs(-10)\n## [1] 10\nround(3.5)\n## [1] 4\nfloor(3.5)\n## [1] 3\nceiling(3.5)\n## [1] 4\n\n関数に渡す値は引数と呼ばれる。 組み合わせを計算する関数 choose の引数は 2 つあり、複数の引数は , で区切る。 引数の順序は、名前を明示すれば入れ替えられる。\n\nchoose(4, 2)\n## [1] 6\nchoose(n=4, k=2)\n## [1] 6\nchoose(k=2, n=4)\n## [1] 6\n\n引数によっては省略しても既定値が自動的に補われることがある。 詳細は関数ごとのヘルプを参照するとよい。\nたとえば choose のヘルプは次のように参照できる。\n\nhelp(choose)\n?choose\n\nで確認できる。\nヘルプには関数の説明、使用例、引数の既定値などがまとまっている。 RStudio を利用している場合は、ヘルプペインに整形されたドキュメントが表示される。",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>R の基本</span>"
    ]
  },
  {
    "objectID": "01-base.html#r-の型",
    "href": "01-base.html#r-の型",
    "title": "2  R の基本",
    "section": "2.3 R の型",
    "text": "2.3 R の型\nR では値に型 (type) があり、数値 (numeric)、文字列 (character)、論理値 (logical) など1が用意されている。 多くの言語と異なり、型をあらかじめ宣言しなくても自動的に決まる。\n数値には整数 (integer) や、実数をコンピュータ上で扱う倍精度浮動小数点数 (double) など2が含まれる。 整数か倍精度浮動小数点数かは自動的に振り分けられるが、数字の後ろに L を付けて整数を明示することもできる。\n文字列は \" (ダブルクォーテーション) もしくは ' (シングルクォーテーション) で囲む。 TRUE もしくは FALSE を取る値は論理値 (logical) と呼ばれる。省略して T や F と表せるが、混乱を招きやすいので推奨しない。\n値の型は関数 typeof() で確認できる。\n\ntypeof(3)\n## [1] \"double\"\ntypeof(3L)\n## [1] \"integer\"\ntypeof(\"3\")\n## [1] \"character\"\ntypeof(TRUE)\n## [1] \"logical\"\ntypeof(FALSE)\n## [1] \"logical\"\ntypeof(T)\n## [1] \"logical\"\ntypeof(F)\n## [1] \"logical\"\n\nオブジェクトのクラス（統計的な型付け）を確認するには class() を使う。 より複雑なオブジェクトでは typeof() と class() の結果が異なることもある点を覚えておきたい。\n特殊な値として、無限大を表す Inf、非数を表す NaN、欠損値を表す NA、空を表す NULL がある。 Inf と NaN は数値として分類され、NA の型は論理値として扱われる。 また、NULL は独自の型として扱われる。 NaN は 0 を 0 で割ったときのように値が定まらない計算で現れる。 NA はデータが欠損している場合に使われ、数値・文字列など別の型の NA も存在する。\n\n1/0\n## [1] Inf\ntypeof(1/0)\n## [1] \"double\"\n0/0\n## [1] NaN\ntypeof(0/0)\n## [1] \"double\"\ntypeof(NA)\n## [1] \"logical\"\ntypeof(NULL)\n## [1] \"NULL\"",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>R の基本</span>"
    ]
  },
  {
    "objectID": "01-base.html#変数",
    "href": "01-base.html#変数",
    "title": "2  R の基本",
    "section": "2.4 変数",
    "text": "2.4 変数\n値は変数 (variable) に代入すると再利用できる。 R では代入のことを付値 (assign) といい、次のように実行する。\n\nx &lt;- 4 \n4 -&gt; x\nx = 4\nassign(\"x\",4)\n\n多くのプログラミング言語では 3 番目の方法のみが一般的だが、 R では最初の方法が推奨されている。3\n代入した値は、その変数名を入力すれば確認できる。 代入と同時に確認したい場合は式全体を丸括弧で囲む。\n\nx\n## [1] 4\n(x&lt;-3)\n## [1] 3\n\n変数名は記号や数字で始まらなければ、ほぼ自由に付けられる。 アルファベットは大文字と小文字が区別される点に注意する。 日本語も変数名に使えるが、環境によって文字コードが異なるため避けるのが無難である。 アンダースコア _ やピリオド . は途中に入れられるが、a.b と a_b は別の名前として扱われる。\n予約語である if など一部の名前4は変数名に使えずエラーになる。 一方で pi のように既存の組み込み変数を上書きすることは可能である。\n\npi\n## [1] 3.141593\npi &lt;- 3\npi\n## [1] 3\n\n関数 objects() を使うと、現在存在するオブジェクトを確認できる。 ls() も同じ結果を返すエイリアスである。 R は変数や関数をすべてオブジェクトとして扱う言語である。 既存のオブジェクトを削除するには rm() を使う。 組み込み変数を上書きしていても、pi を削除すれば元の値が復活する。\n\nrm(pi)\npi\n## [1] 3.141593\n\nさらに、すべてのオブジェクトを削除したい場合は rm(list=ls(all=TRUE)) と入力する。",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>R の基本</span>"
    ]
  },
  {
    "objectID": "01-base.html#パッケージ",
    "href": "01-base.html#パッケージ",
    "title": "2  R の基本",
    "section": "2.5 パッケージ",
    "text": "2.5 パッケージ\nR ではパッケージを導入することで機能を拡張できる。\nパッケージ pkg を導入する際は次を 1 度だけ実行する。\n\ninstall.packages(\"pkg\")\n\nオプション dependencies = TRUE を指定すると、依存パッケージもまとめて導入される。 インストールは 1 度実行すればよいが、R を起動し直すたびに library() などで読み込む必要がある点に注意する。\nパッケージ pkg が導入済みであれば、そのパッケージ内のコマンド cmd を実行するには\n\npkg::cmd\n\nと、パッケージ名とコマンド名の間に :: を挟む必要がある。 この書き方は、パッケージを読み込まずに特定の関数だけを呼び出したいときや、名前が衝突したときに便利である。\nまた、事前に library(pkg) や require(pkg) を実行しておけば、 関数呼び出し時の pkg:: を省略できる。 複数のパッケージに同名のコマンドが含まれる場合は、 後から library や require で読み込んだパッケージが優先される点に注意する。\nlibrary と require の使い方はほとんど同じだが、 require では次のようにパッケージがなければインストールするといった書き方ができる。\n\nif (!require(lattice)){\n  install.packages(\"lattice\")\n  require(lattice)\n} \n\nlibrary() はパッケージが見つからない場合にエラーで処理を止めるのに対し、require() は失敗すると FALSE を返し、処理を続行できる。 私自身は慣れもあって library を使うことが多い。",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>R の基本</span>"
    ]
  },
  {
    "objectID": "01-base.html#footnotes",
    "href": "01-base.html#footnotes",
    "title": "2  R の基本",
    "section": "",
    "text": "他にも日付 (Date) やバイナリ (raw) がある。↩︎\n他にも複素数 (complex) がある。↩︎\n 例えば以下を参照されたい: http://adv-r.had.co.nz/Style.html↩︎\nbreak, else, FALSE, for, function, if, in, Inf, NA, NaN, next, NULL, repeat, TRUE, while など↩︎",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>R の基本</span>"
    ]
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "R と RStudio",
    "section": "",
    "text": "はじめに",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>R と RStudio</span>"
    ]
  },
  {
    "objectID": "index.html#r-とは",
    "href": "index.html#r-とは",
    "title": "R と RStudio",
    "section": "0.1 R とは",
    "text": "0.1 R とは\nRは統計・データ解析・統計グラフ作成のためのオープンソースソフトである. 基本的に無料で使える． 最近はその統合環境であるRStudioがデファクトスタンダードとなっている． さらにそれらは RStudio Cloud (https://rstudio.cloud/) としてクラウド環境でも使用できる． ここではまずローカル環境でR言語をいれる方法を解説する． 第2節にRStudioのローカル環境での導入方法を述べる．\nRStudio Cloud　については直接サイトに行き，そのヘルプを見て導入すれば良いだろう． 日本語の解説としては以下が参考になるだろう．\nhttps://qiita.com/ZaKama/items/937e6d7fa25f6d3cb385",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>R と RStudio</span>"
    ]
  },
  {
    "objectID": "index.html#r-のインストール",
    "href": "index.html#r-のインストール",
    "title": "R と RStudio",
    "section": "0.2 R のインストール",
    "text": "0.2 R のインストール\nRをインストールするには\nhttps://cran.r-project.org/\nにいき, 該当機種のファイルをダウンロードする. ダウンロードしたあとに実行すればインストールされる.\nWindows の場合, 32bit か 64bit を選択する. 最近のパソコンの CPU は 64bit と考えられるが, どちらかわからなければ 32bit にしておけばよい.\nUbuntu なら ppa を使って導入してもよい.\nsudo add-apt-repository ppa:marutter/rrutter\nsudo apt-get update\nsudo apt-get install r-base r-base-dev",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>R と RStudio</span>"
    ]
  },
  {
    "objectID": "index.html#r-の設定",
    "href": "index.html#r-の設定",
    "title": "R と RStudio",
    "section": "0.3 R の設定",
    "text": "0.3 R の設定\n設定ファイル .Rprofile をホームディレクトリに作成すれば, 設定を変更できる. ホームディレクトリはユーザー名が kenji のとき, Windows なら通常 C:\\Users\\kenji である. バックスラッシュ \\ は \\(\\yen\\) と読み替えて頂きたい. 最初は .Rprofile を特に作成しなくても大丈夫である.\nWindowsを利用して日本語のユーザー名を使用している場合に使えない． Rを実施するためのユーザー名を別に作成するか，アカウント名を変えた方がよいだろう． なお日本語ユーザー名のままファイルパスを英語化するには以下を参考されたい:\nhttps://clean-copy-of-onenote.hatenablog.com/entry/R_japanese_username",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>R と RStudio</span>"
    ]
  },
  {
    "objectID": "index.html#r-の使い方",
    "href": "index.html#r-の使い方",
    "title": "R と RStudio",
    "section": "0.4 R の使い方",
    "text": "0.4 R の使い方\nWindows だとコマンドプロンプトから R と入力して立ち上げるか, R のアイコンをダブルクリックすると, Rコンソールと言われる画面が現れる. コマンドプロンプトからだと最初の表示が文字化けしている可能性があるが, その後の起動に問題ないはずである. アイコンがなければ, Winキーを押した後, rgui と入力すれば起動できる. Mac や Ubuntu だとターミナルから R と入力して起動できる.\n立ち上げた後, コンソールから そこにコマンドを入力すると, その結果が直後に出力される. 終了には q() とする. 作業スペースを保存するかと聞かれたなら, No を意味する n を選択する.\nコマンド入力中, 最後の括弧を付け忘れたり, 正しく実行ができないときがある. たとえば, rnorm(5 としてEnterキーを押せば, 次の行に + とでてくる. ここでは正しく ) を付けて再度Enterキーを押せば正しく実行されるが, ときにはどれを入力すれば正しく実行されるかわからない一方で, 単にEnterを押すだけだと, 再度入力を求められることがある. そうしたとときは通常左上にあるエスケープキー (ESC) を押せば途中入力がキャンセルされる.\nR はRコンソールから対話式にコマンドを入力していく方法と, 拡張子 R のスクリプトファイルを実行していくやり方がある. 実行履歴を記録するためにスクリプトファイルを作成していくやり方を推奨する.\nスクリプトファイル project.R を Rコンソールから実行するには,\nsource(\"project.R\")\nとすればよい.\nR外部のコマンドプロンプトから実行するには\nRscript project.R\nとすればよい. 起動できないときには, 環境変数の PATH にRの実行ファイルの場所が登録されていない可能性がある.\nまた外部ファイルを導入する際やファイルを外部出力する際には, 現在の作業ディレクトリに気をつけなければならない. 現在の作業ディレクトリの場所はRコンソールから\ngetwd()\nとすれば, 確認できる. Windows だと通常の表記と異なっていることに注意されたい.\n作業ディレクトリの指定は以下のようにする.\nsetwd(PATH)\nWindows のとき指定の仕方に注意が必要である. たとえば作業ディレクトリが C:\\Users\\kenji\\work\\project のとき,\nsetwd(\"C:/Users/kenji/work/project\")\nとなる. バックスラッシュ \\ (\\(\\yen\\)) を スラッシュ / に変更しなければならない.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>R と RStudio</span>"
    ]
  },
  {
    "objectID": "03-vector.html",
    "href": "03-vector.html",
    "title": "4  vector",
    "section": "",
    "text": "5 ベクトル",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>vector</span>"
    ]
  },
  {
    "objectID": "03-vector.html#ベクトル-1",
    "href": "03-vector.html#ベクトル-1",
    "title": "4  vector",
    "section": "5.1 ベクトル",
    "text": "5.1 ベクトル\nR では同じ型の値を集めたものをベクトルという。 ベクトルは c()（concatenate の略）を用いて構成する。既存のベクトルを渡すと、ひと続きのベクトルとして結合される点にも注意する。\n\n(num&lt;-c(2,3,7,9))\n## [1] 2 3 7 9\n(chr &lt;- c(\"cat\",\"dog\",\"cow\"))\n## [1] \"cat\" \"dog\" \"cow\"\n\nベクトルには長さという属性 (attribute) が付く。length() で要素数を取得できるほか、str() を使えばオブジェクトの構造をまとめて確認できる。\n\nlength(num)\n## [1] 4\nlength(chr)\n## [1] 3\n\nベクトルはオブジェクトの基本単位であり、単一の値も長さ 1 のベクトルとみなせる。\n型が混在している場合は、自動的に最も表現力の高い型へ変換される。強制変換の優先順位は、おおむね「論理値 → 数値 → 文字列」の順と覚えておくとよい。 文字列が 1 つでも含まれると、すべて文字列に変換される。 数値と論理値が混在している場合は、論理値が数値に強制変換され、TRUE は 1、FALSE は 0 になる。\n\n(x&lt;- c(1,4))\n## [1] 1 4\ntypeof(x)\n## [1] \"double\"\n(y &lt;- c(2,FALSE,\"4\"))\n## [1] \"2\"     \"FALSE\" \"4\"\ntypeof(y)\n## [1] \"character\"\n(z &lt;- c(2,FALSE))\n## [1] 2 0\ntypeof(z)\n## [1] \"double\"",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>vector</span>"
    ]
  },
  {
    "objectID": "03-vector.html#算術演算子",
    "href": "03-vector.html#算術演算子",
    "title": "4  vector",
    "section": "5.2 算術演算子",
    "text": "5.2 算術演算子\n四則演算などの算術演算子は要素ごとに適用される。^ は累乗、%% は剰余、%/% は整数除算（切り捨て）を表す。\n\na&lt;-c(2,3,3,3)\nb&lt;-c(3,3,5,7)\na+b\n## [1]  5  6  8 10\na-b\n## [1] -1  0 -2 -4\na*b\n## [1]  6  9 15 21\na/b\n## [1] 0.6666667 1.0000000 0.6000000 0.4285714\na^b\n## [1]    8   27  243 2187\n\n片方がスカラーであっても、同じ長さのベクトルに再利用されて演算される。\n\na+2\n## [1] 4 5 5 5\na-2\n## [1] 0 1 1 1\na*2\n## [1] 4 6 6 6\na/2\n## [1] 1.0 1.5 1.5 1.5\na^2\n## [1] 4 9 9 9\n\n長さが異なるベクトル同士を演算する場合、短い方のベクトルが自動的にリサイクルされて長さを揃える。\n\nc&lt;-c(1,2)\na+c\n## [1] 3 5 4 5\na-c\n## [1] 1 1 2 1\na*c\n## [1] 2 6 3 6\na/c\n## [1] 2.0 1.5 3.0 1.5\na^c\n## [1] 2 9 3 9\n\nただし、短いベクトルの長さが長いベクトルの長さの約数でない場合は警告が表示される。",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>vector</span>"
    ]
  },
  {
    "objectID": "03-vector.html#論理演算子",
    "href": "03-vector.html#論理演算子",
    "title": "4  vector",
    "section": "5.3 論理演算子",
    "text": "5.3 論理演算子\n論理値を入力に取り、論理値を返す演算子を論理演算子という。 R では、否定 (!)、論理和 (|)、論理積 (&) などの演算子が用意されている。 これらの演算子も要素ごとに評価される。 || や && といった二重記号の演算子は、最初の要素のみを評価する短絡演算子であり、条件分岐で判定回数を抑えたいときに使う。\n\nlogic1 &lt;- c(TRUE, FALSE, FALSE)\nlogic2 &lt;- c(TRUE, TRUE, FALSE)\n!logic1\n## [1] FALSE  TRUE  TRUE\nlogic1 | logic2\n## [1]  TRUE  TRUE FALSE\nlogic1 & logic2\n## [1]  TRUE FALSE FALSE\n\nall() はすべての要素が TRUE かどうか、any() は少なくとも 1 つが TRUE かどうかを判定する。\n\nany(logic1)\n## [1] TRUE\nall(logic1)\n## [1] FALSE",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>vector</span>"
    ]
  },
  {
    "objectID": "03-vector.html#比較演算子",
    "href": "03-vector.html#比較演算子",
    "title": "4  vector",
    "section": "5.4 比較演算子",
    "text": "5.4 比較演算子\n2 つの値を比較して論理値を返す演算子を比較演算子という。 R では等しいかどうかを判定する ==、大小を判定する &gt; や &lt; などが用意されている。 これらもベクトルの要素ごとに評価される。\n\nvec1 &lt;- 1:4\nvec2 &lt;- c(2,1,3,4)\nvec1 == vec2\n## [1] FALSE FALSE  TRUE  TRUE\nvec1 &gt; vec2\n## [1] FALSE  TRUE FALSE FALSE\nvec1 &lt; vec2\n## [1]  TRUE FALSE FALSE FALSE\n\n不等号として !=（等しくない）、&gt;=（以上）、&lt;=（以下）も利用できる。\n\nvec1 != vec2 # !(vec1==vec2)\n## [1]  TRUE  TRUE FALSE FALSE\nvec1 &gt;= vec2 # (vec1 &gt; vec2 | vec1 == vec2)\n## [1] FALSE  TRUE  TRUE  TRUE\nvec1 &lt;= vec2 # (vec1 &lt; vec2 | vec1 == vec2)\n## [1]  TRUE FALSE  TRUE  TRUE\n\nスカラーとベクトルを比較する場合は、スカラーが再利用されて要素ごとに評価される。\n\nvec1 &gt; 2\n## [1] FALSE FALSE  TRUE  TRUE\n\n%in% 演算子を使うと、左側のベクトル要素が右側のベクトルに含まれているかを判定できる。返り値は論理値のベクトルで、元の長さと同じになる。\n\nvec1 %in% 4:5\n## [1] FALSE FALSE FALSE  TRUE",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>vector</span>"
    ]
  },
  {
    "objectID": "03-vector.html#要素",
    "href": "03-vector.html#要素",
    "title": "4  vector",
    "section": "5.5 要素",
    "text": "5.5 要素\nベクトルの要素は角括弧で取り出す。\n\nnum &lt;- c(2,3,7,9)\nnum[3]\n## [1] 7\n\n取り出すだけでなく、新しい値を代入することもできる。\n\nnum[3] &lt;- 500\nnum\n## [1]   2   3 500   9\n\n負のインデックスを指定すると、その位置の要素を除いたベクトルが得られる。\n\nnum[-3]\n## [1] 2 3 9\n\n複数の要素を同時に取り出すことも容易である。\n\nnum[c(1,4)]\n## [1] 2 9\n\n論理値ベクトルをインデックスとして使えば、条件に合致する要素のみを抽出できる。\n\nidx &lt;- c(TRUE,FALSE,TRUE,TRUE)\nnum[idx]\n## [1]   2 500   9\n\n比較演算子と組み合わせれば、条件式を直接インデックスに渡してフィルタリングできる。\n\n(num &gt; 4)\n## [1] FALSE FALSE  TRUE  TRUE\nnum[num &gt; 4]\n## [1] 500   9\n\n: 演算子で連続した整数ベクトルを生成し、その範囲を指定して抜き出すこともできる。非整数のステップや逆順が必要な場合は seq() を利用すると柔軟に制御できる。\n\n2:4\n## [1] 2 3 4\nnum[2:4]\n## [1]   3 500   9\n\nベクトルには名前属性を付与できる。\n\nvec &lt;- c(x= 3, y =3, z = 4)\n\n別の方法として次のように設定できる。\n\nnames(num) &lt;- letters[1:4]\n\n名前を付けると、文字列で要素を参照できる。\n\nvec[\"x\"]\n## x \n## 3\nnum[\"d\"]\n## d \n## 9\n\n現在の名前一覧は names() で取得でき、不要になった場合は names(num) &lt;- NULL のようにして削除する。",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>vector</span>"
    ]
  },
  {
    "objectID": "03-vector.html#関数",
    "href": "03-vector.html#関数",
    "title": "4  vector",
    "section": "5.6 関数",
    "text": "5.6 関数\nベクトルを引数に取る関数も多数用意されており、和や積などを簡単に計算できる。累積和（cumsum()）や累積積（cumprod()）は系列データの推移を追跡したいときに便利である。\n\nx&lt;-c(1,2,3,4,5)\nsum(x)\n## [1] 15\ncumsum(x)\n## [1]  1  3  6 10 15\nprod(x)\n## [1] 120\ncumprod(x)\n## [1]   1   2   6  24 120\n\n平均、中央値、分散、標準偏差といった統計量もワンライナーで求められる。\n\nx &lt;- c(x,10)\nmean(x)\n## [1] 4.166667\nmedian(x)\n## [1] 3.5\nvar(x)\n## [1] 10.16667\nsd(x)\n## [1] 3.188521\n\nベクトルを並べ替えたり、最小値・最大値やその位置を取得したりする関数も充実している。\n\nx &lt;- c(3,3,5,0)\nsort(x)\n## [1] 0 3 3 5\nsort(x,decreasing = TRUE)\n## [1] 5 3 3 0\nmin(x)\n## [1] 0\nmax(x)\n## [1] 5\nwhich.min(x)\n## [1] 4\nwhich.max(x)\n## [1] 3\n\n欠損値 NA が含まれている場合、mean() など多くの集計関数は既定の挙動として NA を返す。 集計から欠損を除外したいときは、na.rm = TRUE を指定する。\n\nx &lt;- c(4,2,NA,3)\nmean(x)\n## [1] NA\nmean(x, na.rm = TRUE)\n## [1] 3",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>vector</span>"
    ]
  },
  {
    "objectID": "03-vector.html#規則的なベクトル",
    "href": "03-vector.html#規則的なベクトル",
    "title": "4  vector",
    "section": "5.7 規則的なベクトル",
    "text": "5.7 規則的なベクトル\n1:5 のような規則的なベクトルを柔軟に作成するのに seq を用いるとよい。\n\n1:5\n## [1] 1 2 3 4 5\nseq(1, 5)\n## [1] 1 2 3 4 5\nseq(1, 5, by = 2)\n## [1] 1 3 5\nseq(1, 5, length.out = 4)\n## [1] 1.000000 2.333333 3.666667 5.000000\n\n繰り返しを作成することができる rep も覚えておくと便利である。\n\nrep(1, 5)\n## [1] 1 1 1 1 1\nrep(c(1, 2), times = 3)\n## [1] 1 2 1 2 1 2\nrep(c(1, 2), each = 3)\n## [1] 1 1 1 2 2 2\n\nまたアルファベットの文字列もあらかじめ組み込まれている。\n\nletters\n##  [1] \"a\" \"b\" \"c\" \"d\" \"e\" \"f\" \"g\" \"h\" \"i\" \"j\" \"k\" \"l\" \"m\" \"n\" \"o\" \"p\" \"q\" \"r\" \"s\"\n## [20] \"t\" \"u\" \"v\" \"w\" \"x\" \"y\" \"z\"\nLETTERS\n##  [1] \"A\" \"B\" \"C\" \"D\" \"E\" \"F\" \"G\" \"H\" \"I\" \"J\" \"K\" \"L\" \"M\" \"N\" \"O\" \"P\" \"Q\" \"R\" \"S\"\n## [20] \"T\" \"U\" \"V\" \"W\" \"X\" \"Y\" \"Z\"\nLETTERS[1:2]\n## [1] \"A\" \"B\"",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>vector</span>"
    ]
  },
  {
    "objectID": "03-vector.html#乱数ベクトル",
    "href": "03-vector.html#乱数ベクトル",
    "title": "4  vector",
    "section": "5.8 乱数ベクトル",
    "text": "5.8 乱数ベクトル\nベクトルを無作為に並べ替えたり抽出したりするには sample() を使う。\n\nset.seed(10)\nsample(1:5)\n## [1] 3 1 2 5 4\n\nここで set.seed() は乱数の種を固定し、別の環境でも同じ結果を再現できるようにするための設定である。\n上記は一度選ばれた値を再度選ばない非復元抽出である。復元抽出にする場合は replace = TRUE を指定する。\n\nsample(1:5, replace = TRUE)\n## [1] 3 2 2 2 5\n\nsize 引数を指定すれば、取り出す要素数も制御できる。\n\nsample(LETTERS[1:2], size = 10, replace = TRUE)\n##  [1] \"A\" \"B\" \"B\" \"A\" \"B\" \"A\" \"A\" \"B\" \"B\" \"A\"\n\n非復元抽出では、size を母集合の長さより大きくすることはできない点に注意する。\nさらに prob で各要素が選ばれる確率を指定できる（確率の合計は 1 になるようにする）。\n\nsample(LETTERS[1:2], prob = c(0.8, 0.2), size = 10, replace = TRUE)\n##  [1] \"A\" \"A\" \"A\" \"B\" \"A\" \"A\" \"B\" \"B\" \"A\" \"A\"\n\n独立な一様分布に従う長さ size のベクトルは runif(size)、平均と分散を指定した正規分布なら rnorm(size, mean, sd) で生成できる（既定値は平均 0、標準偏差 1）。\n\nsize &lt;- 8\nrunif(size)\n## [1] 0.27548386 0.22890394 0.01443391 0.72896456 0.24988047 0.16118328 0.01704265\n## [8] 0.48610035\nrnorm(size)\n## [1] -1.26519802 -0.37366156 -0.68755543 -0.87215883 -0.10176101 -0.25378053\n## [7] -1.85374045 -0.07794607",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>vector</span>"
    ]
  },
  {
    "objectID": "09-ivreg.html",
    "href": "09-ivreg.html",
    "title": "10  操作変数法",
    "section": "",
    "text": "10.1 データ\nlibrary(AER)\nlibrary(wooldridge)\nlibrary(estimatr)\ndata(\"mroz\", package=\"wooldridge\")\ndf &lt;- subset(mroz, inlf==1)",
    "crumbs": [
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>操作変数法</span>"
    ]
  },
  {
    "objectID": "09-ivreg.html#操作変数",
    "href": "09-ivreg.html#操作変数",
    "title": "10  操作変数法",
    "section": "10.2 操作変数",
    "text": "10.2 操作変数\nこれまで回帰モデルで一致推定量を得るためには次の仮定が必要であった.\n\n母集団が線形モデル\n標本が無作為抽出\n誤差項が平均ゼロで説明変数と無相関\n説明変数に多重共線性が存在しない\n\n3つ目の仮定が必ずしも成立しない場合の推定方法を紹介する.\nそのために, 外生変数と内生変数と操作変数の3つの概念を導入する. 誤差項と相関が無い説明変数を 外生変数 といい, 誤差項と相関がある説明変数を 内生変数 という. 操作変数 とは, 説明変数に含まれず, 説明変数と相関をもち, 誤差項と相関をもたない変数のことである. なお操作変数の個数は内生変数の個数より多苦なければならない。\nR においては ivreg コマンドを用いて操作変数法を実行する. このコマンドは AER パッケージに含まれており, 基本的な書式は ivreg(被説明変数 ~ 内生変数 | 操作変数, data=データフレーム) である. ここで被説明変数は log(wage), 内生変数は educ, 操作変数は fatheduc である.\n以下のコマンドで操作変数法を実行し, coef コマンドで推定された係数を取り出す.\n\nfm  &lt;- ivreg(log(wage)~educ|fatheduc, data=df)\ncoef(fm)\n## (Intercept)        educ \n##  0.44110339  0.05917348\n\n傾きの推定値は操作変数推定量の公式を用いて直接計算することもできる. 具体的には, 被説明変数と操作変数の共分散を内生変数と操作変数の共分散で割ることで得られる. 以下のコマンドで cov 関数を用いて共分散を計算し, 同じ推定値が得られることを確認する.\n\nwith(df, cov(log(wage),fatheduc)/cov(educ,fatheduc))\n## [1] 0.05917348",
    "crumbs": [
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>操作変数法</span>"
    ]
  },
  {
    "objectID": "09-ivreg.html#段階最小二乗法",
    "href": "09-ivreg.html#段階最小二乗法",
    "title": "10  操作変数法",
    "section": "10.3 2段階最小二乗法",
    "text": "10.3 2段階最小二乗法\n複数の説明変数あり, 操作変数の数が内生変数の数以上のとき, 係数の一致推定量を得るには二段階最小自乗法を用いる. 二段階最小二乗法は次の手順で実行される:\n\nそれぞれの内生変数を外生変数と操作変数に回帰させて, その予測値を得る.\n被説明変数を外生変数と内生変数の予測値に回帰させて, その係数を得る.\n\nこの係数が一致推定量になるための条件は以下である.\n\n母集団が線形モデル\n標本が無作為抽出\n誤差項が平均ゼロで操作変数と外生変数に対して独立.\n操作変数は内生変数と相関をもつ.\n外生変数と内生変数の予測値に多重共線性が存在しない`\n\nR においては ivreg コマンドを用いて二段階最小二乗法を実行する. 複数の説明変数がある場合の書式は ivreg(被説明変数 ~ 内生変数 + 外生変数 | 外生変数 + 操作変数, data=データフレーム) である. ここで被説明変数は log(wage), 内生変数は educ, 外生変数は exper, I(exper^2), 操作変数は motheduc, fatheduc である. 注意点として, パイプ記号 | の右側には外生変数も含める必要がある.\n以下のコマンドで二段階最小二乗法を実行し, summary コマンドで推定結果の要約を表示する.\n\nfm  &lt;- ivreg(log(wage)~educ+exper+I(exper^2)|\n            exper+I(exper^2)+motheduc+fatheduc,\n            data=df)\nsummary(fm)\n## \n## Call:\n## ivreg(formula = log(wage) ~ educ + exper + I(exper^2) | exper + \n##     I(exper^2) + motheduc + fatheduc, data = df)\n## \n## Residuals:\n##     Min      1Q  Median      3Q     Max \n## -3.0986 -0.3196  0.0551  0.3689  2.3493 \n## \n## Coefficients:\n##               Estimate Std. Error t value Pr(&gt;|t|)   \n## (Intercept)  0.0481003  0.4003281   0.120  0.90442   \n## educ         0.0613966  0.0314367   1.953  0.05147 . \n## exper        0.0441704  0.0134325   3.288  0.00109 **\n## I(exper^2)  -0.0008990  0.0004017  -2.238  0.02574 * \n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n## \n## Residual standard error: 0.6747 on 424 degrees of freedom\n## Multiple R-Squared: 0.1357,  Adjusted R-squared: 0.1296 \n## Wald test: 8.141 on 3 and 424 DF,  p-value: 2.787e-05\n\n二段階最小二乗法の手順を lm コマンドを用いて手動で実行し, 同じ係数推定値が得られることを確認できる. ただし標準誤差の値が異なっている. なぜなら残差は内生変数および外生変数から算出させる必要があるが, 以下のやりかただと内生変数の予測値および外生変数から算出するためである.\n以下では第一段階として lm コマンドで内生変数 educ を外生変数と操作変数に回帰し, fitted コマンドで予測値を取得する. 第二段階として被説明変数を外生変数と内生変数の予測値に回帰する.\n\nols1 &lt;- lm(educ~exper+I(exper^2)+motheduc+fatheduc,  data = df)\nols2 &lt;- lm(log(wage)~fitted(ols1)+exper+I(exper^2),  data = df)\nsummary(ols2)\n## \n## Call:\n## lm(formula = log(wage) ~ fitted(ols1) + exper + I(exper^2), data = df)\n## \n## Residuals:\n##     Min      1Q  Median      3Q     Max \n## -3.1631 -0.3539  0.0326  0.3818  2.3727 \n## \n## Coefficients:\n##                Estimate Std. Error t value Pr(&gt;|t|)   \n## (Intercept)   0.0481003  0.4197565   0.115  0.90882   \n## fitted(ols1)  0.0613966  0.0329624   1.863  0.06321 . \n## exper         0.0441704  0.0140844   3.136  0.00183 **\n## I(exper^2)   -0.0008990  0.0004212  -2.134  0.03338 * \n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n## \n## Residual standard error: 0.7075 on 424 degrees of freedom\n## Multiple R-squared:  0.04978,    Adjusted R-squared:  0.04306 \n## F-statistic: 7.405 on 3 and 424 DF,  p-value: 7.615e-05\n\n\n10.3.1 複数制約の検定\n帰無仮説が複数の係数制約を課す場合のワルド検定を実施する. 例えば, 2つの外生変数 exper と I(exper^2) の係数がともにゼロであるという仮説を検定する.\nまず ivreg コマンドで制約モデル（外生変数を含まないモデル）を推定し, waldtest コマンドで制約なしモデルと比較する. waldtest コマンドは2つのモデルを引数にとり, ワルド検定を実行する.\n\nfm0 &lt;- ivreg(log(wage)~educ|motheduc+fatheduc,data=df)\nwaldtest(fm0,fm)\n## Wald test\n## \n## Model 1: log(wage) ~ educ | motheduc + fatheduc\n## Model 2: log(wage) ~ educ + exper + I(exper^2) | exper + I(exper^2) + \n##     motheduc + fatheduc\n##   Res.Df Df  Chisq Pr(&gt;Chisq)    \n## 1    426                         \n## 2    424  2 19.639  5.439e-05 ***\n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nLM検定（ラグランジュ乗数検定）も実行可能である. まず resid コマンドで制約モデルの残差を取得し, その残差を制約される説明変数に回帰する. nrow コマンドで観測数を取得し, 決定係数 r.squared を乗じてLM統計量を計算する. 最後に pchisq コマンドでカイ二乗分布のP値を計算する（自由度は制約の数3）.\n\nlmt &lt;- lm(resid(fm0)~educ + exper + I(exper^2) ,data=df)\n(lmt &lt;- nrow(df)*summary(lmt)$r.squared)\n## [1] 33.97987\n1-pchisq(lmt,df=3)\n## [1] 2.000665e-07",
    "crumbs": [
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>操作変数法</span>"
    ]
  },
  {
    "objectID": "09-ivreg.html#特定化検定",
    "href": "09-ivreg.html#特定化検定",
    "title": "10  操作変数法",
    "section": "10.4 特定化検定",
    "text": "10.4 特定化検定\n操作変数法が妥当かどうかを検証するために, 複数の特定化検定を実施する. summary コマンドにオプション diagnostics = TRUE を追加すると, 弱操作変数検定（Weak instruments）, Wu-Hausman検定, Sargan検定を一度に実行できる. これらの検定結果から, 操作変数の妥当性, 内生性の有無, 操作変数の外生性を確認できる.\n\nsummary(fm, diagnostics = TRUE)\n## \n## Call:\n## ivreg(formula = log(wage) ~ educ + exper + I(exper^2) | exper + \n##     I(exper^2) + motheduc + fatheduc, data = df)\n## \n## Residuals:\n##     Min      1Q  Median      3Q     Max \n## -3.0986 -0.3196  0.0551  0.3689  2.3493 \n## \n## Coefficients:\n##               Estimate Std. Error t value Pr(&gt;|t|)   \n## (Intercept)  0.0481003  0.4003281   0.120  0.90442   \n## educ         0.0613966  0.0314367   1.953  0.05147 . \n## exper        0.0441704  0.0134325   3.288  0.00109 **\n## I(exper^2)  -0.0008990  0.0004017  -2.238  0.02574 * \n## \n## Diagnostic tests:\n##                  df1 df2 statistic p-value    \n## Weak instruments   2 423    55.400  &lt;2e-16 ***\n## Wu-Hausman         1 423     2.793  0.0954 .  \n## Sargan             1  NA     0.378  0.5386    \n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n## \n## Residual standard error: 0.6747 on 424 degrees of freedom\n## Multiple R-Squared: 0.1357,  Adjusted R-squared: 0.1296 \n## Wald test: 8.141 on 3 and 424 DF,  p-value: 2.787e-05\n\n\n10.4.1 Weak instruments\n操作変数が内生変数と弱い相関関係しかない場合, 弱操作変数という. 弱操作変数の場合, 推定量の性質が悪化するため, 操作変数が十分に強い相関を持つかを検定する必要がある.\n検定手順は以下の通りである: それぞれの内生変数に対して, 帰無仮説を内生変数を外生変数のみに回帰させたモデルとし, 対立仮説を内生変数を外生変数および操作変数に回帰させたモデルとし, F検定を実施する.\n以下のコマンドで lm による制約モデルを推定し, anova コマンドで第一段階の回帰モデル ols1 と比較してF検定を実行する. この結果が先の diagnostics = TRUE で得られた弱操作変数検定と同じであることを確認されたい.\n\nols0 &lt;- lm(educ ~ exper + I(exper^2), data = df)\nanova(ols0, ols1)\n## Analysis of Variance Table\n## \n## Model 1: educ ~ exper + I(exper^2)\n## Model 2: educ ~ exper + I(exper^2) + motheduc + fatheduc\n##   Res.Df    RSS Df Sum of Sq    F    Pr(&gt;F)    \n## 1    425 2219.2                                \n## 2    423 1758.6  2    460.64 55.4 &lt; 2.2e-16 ***\n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\n10.4.2 Wu-Hausman 検定\nWu-Hausman 検定は 帰無仮説が誤差項と説明変数が無相関, 対立仮説が誤差項と説明変数が相関ありの検定をおこなう. 帰無仮説のもとでは, OLSも2SLSも一致推定量であるが, OLSの方が効率的である. よって検定統計量のP値が十分小さいなら帰無仮説は棄却され, 内生性があることになり操作変数法（2SLS）を選択する. そうでなければより効率的な最小二乗法（OLS）を実施する.\n具体的には以下のF検定を実施する:\n\nlm コマンドでそれぞれの内生変数を外生変数に回帰し, resid コマンドで残差を得る (resid(ols1))\nlm コマンドで被説明変数を説明変数に回帰する (ols3)\nupdate コマンドで被説明変数を説明変数および先程の残差に回帰する (ols4)\nanova コマンドでこれらの残差の係数はゼロであるという帰無仮説のもとF検定を実施する\n\n以下のコマンドが先の diagnostics = TRUE で得られたWu-Hausman検定と同じであることを確認されたい.\n\nols3 &lt;- lm(log(wage) ~ educ  + exper + I(exper^2), data = df)\nols4 &lt;- update(ols3, . ~ . + resid(ols1))\nanova(ols3,ols4)\n## Analysis of Variance Table\n## \n## Model 1: log(wage) ~ educ + exper + I(exper^2)\n## Model 2: log(wage) ~ educ + exper + I(exper^2) + resid(ols1)\n##   Res.Df    RSS Df Sum of Sq      F  Pr(&gt;F)  \n## 1    424 188.31                              \n## 2    423 187.07  1     1.235 2.7926 0.09544 .\n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\n10.4.3 Sargan 検定\nSargan 検定は 誤差項が操作変数 (および外生変数) と相関しているかどうかを検定する. 帰無仮説は操作変数が外生的である（相関が無い）場合で, 対立仮説は操作変数が内生的である（相関がある）場合である. この検定は操作変数が過剰識別されている（操作変数の数が内生変数の数より多い）場合にのみ実施可能である.\nLM検定（ラグランジュ乗数検定）を以下の手順で実施する:\n\nresid コマンドで二段階最小二乗法を実施したときの残差を得る (resid(fm))\nlm コマンドで残差を外生変数および操作変数に回帰する\nnrow コマンドで観測数を取得し, 回帰の決定係数 r.squared を乗じたLM統計量を得る\npchisq コマンドで検定統計量のP値を計算する. 検定統計量は帰無仮説のもと, 操作変数の数から内生変数の数を差し引いた自由度（この例では1）のカイ二乗分布にしたがう\n\n以下のコマンドが先の diagnostics = TRUE で得られたSargan検定と同じであることを確認されたい.\n\njt &lt;- lm(resid(fm)~exper+I(exper^2)+motheduc+fatheduc,data=df)\n(jt &lt;- nrow(df)*summary(jt)$r.squared)\n## [1] 0.3780714\n1-pchisq(jt,df=1)\n## [1] 0.5386372",
    "crumbs": [
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>操作変数法</span>"
    ]
  },
  {
    "objectID": "09-ivreg.html#ロバスト分散",
    "href": "09-ivreg.html#ロバスト分散",
    "title": "10  操作変数法",
    "section": "10.5 ロバスト分散",
    "text": "10.5 ロバスト分散\n以上の分析は, 誤差項が操作変数と独立かつ均一分散の場合の分析である. 独立でない場合や分散不均一の場合, 推定量の分散が変わりうる. そうした場合に頑健な分散推定量をロバスト分散という.\nロバスト分散にもとづく推定結果を得るには, summary コマンドにオプション vcov = vcovHC を追加する. vcovHC は不均一分散に頑健な分散共分散行列を計算する関数である. オプション df = Inf は自由度を無限大とし, t分布ではなく正規分布を用いて検定を行う.\n\nsummary(fm, vcov = vcovHC, df = Inf)\n## \n## Call:\n## ivreg(formula = log(wage) ~ educ + exper + I(exper^2) | exper + \n##     I(exper^2) + motheduc + fatheduc, data = df)\n## \n## Residuals:\n##     Min      1Q  Median      3Q     Max \n## -3.0986 -0.3196  0.0551  0.3689  2.3493 \n## \n## Coefficients:\n##               Estimate Std. Error z value Pr(&gt;|z|)   \n## (Intercept)  0.0481003  0.4337795   0.111  0.91171   \n## educ         0.0613966  0.0336597   1.824  0.06815 . \n## exper        0.0441704  0.0157661   2.802  0.00508 **\n## I(exper^2)  -0.0008990  0.0004391  -2.047  0.04062 * \n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n## \n## Residual standard error: 0.6747 on Inf degrees of freedom\n## Multiple R-Squared: 0.1357,  Adjusted R-squared: 0.1296 \n## Wald test: 18.11 on 3 DF,  p-value: 0.0004168\n\n係数の検定結果のみを表示したい場合は, coeftest コマンドを用いる. このコマンドは推定されたモデルオブジェクトと分散共分散行列を引数にとり, 係数のt検定結果を表示する.\n\ncoeftest(fm, vcov=vcovHC)\n## \n## t test of coefficients:\n## \n##                Estimate  Std. Error t value Pr(&gt;|t|)   \n## (Intercept)  0.04810030  0.43377952  0.1109 0.911759   \n## educ         0.06139663  0.03365975  1.8240 0.068850 . \n## exper        0.04417039  0.01576605  2.8016 0.005318 **\n## I(exper^2)  -0.00089897  0.00043908 -2.0474 0.041233 * \n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nロバスト分散のもとでの複数制約のワルド検定を実施するには, waldtest コマンドにオプション vcov=vcovHC を追加する.\n\nwaldtest(fm0,fm, vcov=vcovHC)\n## Wald test\n## \n## Model 1: log(wage) ~ educ | motheduc + fatheduc\n## Model 2: log(wage) ~ educ + exper + I(exper^2) | exper + I(exper^2) + \n##     motheduc + fatheduc\n##   Res.Df Df  Chisq Pr(&gt;Chisq)    \n## 1    426                         \n## 2    424  2 14.582  0.0006816 ***\n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n最近開発されたパッケージ estimatr のコマンド iv_robust を用いるとロバスト分散のもとの推定値が簡単に計算できる. このコマンドはデフォルトでロバスト標準誤差（HC2型）を計算し, オプション diagnostics = TRUE で特定化検定も同時に実行できる. 書式は ivreg と同じである.\n以下のコマンドで iv_robust による推定を実行し, summary コマンドで結果を表示する.\n\nfm2 &lt;- iv_robust(log(wage)~educ+exper+I(exper^2)|\n            exper+I(exper^2)+motheduc+fatheduc,\n            data=df,diagnostics =TRUE)\nsummary(fm2)\n## \n## Call:\n## iv_robust(formula = log(wage) ~ educ + exper + I(exper^2) | exper + \n##     I(exper^2) + motheduc + fatheduc, data = df, diagnostics = TRUE)\n## \n## Standard error type:  HC2 \n## \n## Coefficients:\n##              Estimate Std. Error t value Pr(&gt;|t|)  CI Lower   CI Upper  DF\n## (Intercept)  0.048100  0.4307514  0.1117 0.911141 -0.798574  8.948e-01 424\n## educ         0.061397  0.0334146  1.8374 0.066848 -0.004282  1.271e-01 424\n## exper        0.044170  0.0156233  2.8272 0.004918  0.013462  7.488e-02 424\n## I(exper^2)  -0.000899  0.0004337 -2.0730 0.038777 -0.001751 -4.658e-05 424\n## \n## Multiple R-squared:  0.1357 ,    Adjusted R-squared:  0.1296 \n## F-statistic: 6.117 on 3 and 424 DF,  p-value: 0.0004426\n## \n## Diagnostics:\n##                  numdf dendf  value p.value    \n## Weak instruments     2   423 49.374  &lt;2e-16 ***\n## Wu-Hausman           1   423  2.535   0.112    \n## Overidentifying      1    NA  0.443   0.505    \n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nオプション se_type = \"stata\" を用いればSTATAと同じ標準誤差の計算が可能である. また, ロバスト分散のもとで特定化検定（弱操作変数検定, Wu-Hausman検定, Sargan検定）が実行される.\n分散均一性を仮定した古典的な標準誤差を計算したい場合は, オプション se_type = \"classical\" を追加する.\n\nfm3 &lt;- iv_robust(log(wage)~educ+exper+I(exper^2)|\n            exper+I(exper^2)+motheduc+fatheduc,\n            data=df,diagnostics =TRUE,se_type = \"classical\")\nsummary(fm3)\n## \n## Call:\n## iv_robust(formula = log(wage) ~ educ + exper + I(exper^2) | exper + \n##     I(exper^2) + motheduc + fatheduc, data = df, se_type = \"classical\", \n##     diagnostics = TRUE)\n## \n## Standard error type:  classical \n## \n## Coefficients:\n##              Estimate Std. Error t value Pr(&gt;|t|)   CI Lower   CI Upper  DF\n## (Intercept)  0.048100  0.4003281  0.1202 0.904419 -0.7387744  0.8349750 424\n## educ         0.061397  0.0314367  1.9530 0.051474 -0.0003945  0.1231878 424\n## exper        0.044170  0.0134325  3.2883 0.001092  0.0177679  0.0705729 424\n## I(exper^2)  -0.000899  0.0004017 -2.2380 0.025740 -0.0016885 -0.0001094 424\n## \n## Multiple R-squared:  0.1357 ,    Adjusted R-squared:  0.1296 \n## F-statistic: 8.141 on 3 and 424 DF,  p-value: 2.787e-05\n## \n## Diagnostics:\n##                  numdf dendf  value p.value    \n## Weak instruments     2   423 55.400  &lt;2e-16 ***\n## Wu-Hausman           1   423  2.793  0.0954 .  \n## Overidentifying      1    NA  0.378  0.5386    \n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n10.5.1 分散不均一の検定\n誤差項が操作変数と独立なら条件付き分散は操作変数に無関係で均一である. これを利用して分散均一を帰無仮説に, 分散不均一を対立仮説にしたBP検定（Breusch-Pagan検定）が実行可能である. ただし, 通常のコマンド bptest では正しく実行できないので, 手動で実行する必要がある.\n以下の手順でBP検定を実行する:\n\nI 関数と resid コマンドを用いて二段階最小二乗法の残差の二乗を計算する (I(resid(fm)^2))\nlm コマンドで残差の二乗を外生変数および操作変数に回帰する\nnrow コマンドで観測数を取得し, 決定係数 r.squared を乗じてLM統計量を得る\npchisq コマンドで検定統計量のP値を計算する. 検定統計量は帰無仮説のもと, 説明変数の数（この例では4）の自由度のカイ二乗分布にしたがう\n\n\nbpt &lt;- lm(I(resid(fm)^2)~exper + I(exper^2) + motheduc + fatheduc,data=df)\n(bpt &lt;- nrow(df)*summary(bpt)$r.squared)\n## [1] 12.41758\n1-pchisq(bpt,df=4)\n## [1] 0.01450172",
    "crumbs": [
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>操作変数法</span>"
    ]
  },
  {
    "objectID": "10-panel.html",
    "href": "10-panel.html",
    "title": "11  パネル分析",
    "section": "",
    "text": "11.1 データ\nパネル分析に必要なパッケージを読み込み, データセットを準備する. library(AER) コマンドで AER パッケージを, library(plm) コマンドで plm パッケージを読み込む. 次に data(\"Grunfeld\", package = \"plm\") コマンドで Grunfeld データセットを読み込む. Grunfeld データは企業の投資, 企業価値, 資本ストックに関するパネルデータである. head(Grunfeld) コマンドでデータの最初の数行を表示する.\nlibrary(AER)\nlibrary(plm)\ndata(\"Grunfeld\", package = \"plm\")\nhead(Grunfeld)\n##   firm year   inv  value capital\n## 1    1 1935 317.6 3078.5     2.8\n## 2    1 1936 391.8 4661.7    52.6\n## 3    1 1937 410.6 5387.1   156.9\n## 4    1 1938 257.7 2792.2   209.2\n## 5    1 1939 330.8 4313.2   203.4\n## 6    1 1940 461.2 4643.9   207.2\n次にパネルデータとして扱うために, pdata.frame() 関数を使用する. pdata.frame(Grunfeld, index = c(\"firm\", \"year\")) コマンドで, firm (企業) と year (年) をインデックスとしてパネルデータフレームを作成し, pdata に格納する. pdim(pdata) コマンドでパネルデータの次元 (企業数, 時間数, 総観測数) を確認する.\npdata &lt;- pdata.frame(Grunfeld, index = c(\"firm\", \"year\"))\npdim(pdata)\n## Balanced Panel: n = 10, T = 20, N = 200",
    "crumbs": [
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>パネル分析</span>"
    ]
  },
  {
    "objectID": "10-panel.html#プーリングols",
    "href": "10-panel.html#プーリングols",
    "title": "11  パネル分析",
    "section": "11.2 プーリングOLS",
    "text": "11.2 プーリングOLS\n次の重回帰モデルを考える.\n\\[\ninv_{it} = \\beta_0 + \\beta_1 value_{it} + \\beta_2 capital_{it} + u_{it}\n\\]\n誤差項 \\(u_{it}\\) は \\(i\\) についても \\(t\\) についても独立同一分布と仮定する. さらに誤差項は説明変数と独立である. この時、パネルデータにおいてもOLS推定法でパラメータは不偏である. ここでの重回帰モデルをプーリングOLSモデルと呼ぶことにする.\nプーリングOLS推定を実行するには, plm() 関数で model = \"pooling\" を指定する. plm(inv ~ value + capital, data = pdata, model = \"pooling\") コマンドで, inv を被説明変数, value と capital を説明変数としてプーリングOLS推定を行い, 結果を gp に格納する. summary(gp) コマンドで推定結果の詳細を表示する.\n\ngp &lt;- plm(inv ~ value + capital, data = pdata, model = \"pooling\")\nsummary(gp)\n## Pooling Model\n## \n## Call:\n## plm(formula = inv ~ value + capital, data = pdata, model = \"pooling\")\n## \n## Balanced Panel: n = 10, T = 20, N = 200\n## \n## Residuals:\n##      Min.   1st Qu.    Median   3rd Qu.      Max. \n## -291.6757  -30.0137    5.3033   34.8293  369.4464 \n## \n## Coefficients:\n##                Estimate  Std. Error t-value  Pr(&gt;|t|)    \n## (Intercept) -42.7143694   9.5116760 -4.4907 1.207e-05 ***\n## value         0.1155622   0.0058357 19.8026 &lt; 2.2e-16 ***\n## capital       0.2306785   0.0254758  9.0548 &lt; 2.2e-16 ***\n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n## \n## Total Sum of Squares:    9359900\n## Residual Sum of Squares: 1755900\n## R-Squared:      0.81241\n## Adj. R-Squared: 0.8105\n## F-statistic: 426.576 on 2 and 197 DF, p-value: &lt; 2.22e-16\n\nこのプーリングOLS推定は, 通常の lm() 関数を使った回帰分析と同じ結果を得る. lm(inv ~ value + capital, data = pdata) コマンドで通常のOLS推定を行い, summary() コマンドで結果を表示すると, 上記の plm() による結果と同一であることが確認できる.\n\nsummary(lm(inv ~ value + capital, data = pdata))\n## \n## Call:\n## lm(formula = inv ~ value + capital, data = pdata)\n## \n## Residuals:\n##     Min      1Q  Median      3Q     Max \n## -291.68  -30.01    5.30   34.83  369.45 \n## \n## Coefficients:\n##               Estimate Std. Error t value Pr(&gt;|t|)    \n## (Intercept) -42.714369   9.511676  -4.491 1.21e-05 ***\n## value         0.115562   0.005836  19.803  &lt; 2e-16 ***\n## capital       0.230678   0.025476   9.055  &lt; 2e-16 ***\n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n## \n## Residual standard error: 94.41 on 197 degrees of freedom\n## Multiple R-squared:  0.8124, Adjusted R-squared:  0.8105 \n## F-statistic: 426.6 on 2 and 197 DF,  p-value: &lt; 2.2e-16",
    "crumbs": [
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>パネル分析</span>"
    ]
  },
  {
    "objectID": "10-panel.html#固定効果-平均差分法",
    "href": "10-panel.html#固定効果-平均差分法",
    "title": "11  パネル分析",
    "section": "11.3 固定効果 (平均差分法)",
    "text": "11.3 固定効果 (平均差分法)\n次の重回帰モデルを考える. \\[\ninv_{it} = \\beta_1 value_{it} + \\beta_2 capital_{it} +\\alpha_i + u_{it}\n\\] この \\(\\alpha_i\\) は個別固定効果と呼ばれている. \\(\\alpha_i\\) は時間 \\(t\\) に対して一定である. \\(\\alpha_i\\) は誤差項と相関があるもしれない. この個別固定効果を持つ重回帰モデルを固定効果モデルと呼ぶことにする.\nそれぞれの時間平均をとれば以下になる. \\[\n\\bar{inv}_{i} = \\beta_1 \\bar{value}_{i} + \\beta_2 \\bar{capital}_{i} +\\alpha_i  + \\bar{u}_{i}\n\\]\nそして，それぞれの観測値を時間平均で差し引けば以下のように \\(\\alpha_i\\) は消去される. \\[\ninv_{it}-\\overline{inv}_{i} = \\beta_1 (value_{it}-\\overline{value}_{i}) + \\beta_2 (capital_{it}-\\overline{capital}_{i})  + \\bar{u}_{i} -\\bar{u}_{i}\n\\] このように変換して回帰分析すれば \\(\\alpha_i\\) は誤差項と相関があっても一致推定量である. このような推定方法を平均差分法という.\n固定効果モデルを平均差分法で推定するには, plm() 関数で model = \"within\" を指定する. plm(inv ~ value + capital, data = pdata, model = \"within\") コマンドで固定効果推定を行い, 結果を gi に格納する. summary(gi) コマンドで推定結果の詳細を表示する.\n\ngi &lt;- plm(inv ~ value + capital, data = pdata, model = \"within\")\nsummary(gi)\n## Oneway (individual) effect Within Model\n## \n## Call:\n## plm(formula = inv ~ value + capital, data = pdata, model = \"within\")\n## \n## Balanced Panel: n = 10, T = 20, N = 200\n## \n## Residuals:\n##       Min.    1st Qu.     Median    3rd Qu.       Max. \n## -184.00857  -17.64316    0.56337   19.19222  250.70974 \n## \n## Coefficients:\n##         Estimate Std. Error t-value  Pr(&gt;|t|)    \n## value   0.110124   0.011857  9.2879 &lt; 2.2e-16 ***\n## capital 0.310065   0.017355 17.8666 &lt; 2.2e-16 ***\n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n## \n## Total Sum of Squares:    2244400\n## Residual Sum of Squares: 523480\n## R-Squared:      0.76676\n## Adj. R-Squared: 0.75311\n## F-statistic: 309.014 on 2 and 188 DF, p-value: &lt; 2.22e-16\n\n推定された個別固定効果 \\(\\alpha_i\\) の値を確認するには, fixef() 関数を使用する. fixef(gi) コマンドで各企業の固定効果の推定値を表示する.\n\nfixef(gi)\n##         1         2         3         4         5         6         7         8 \n##  -70.2967  101.9058 -235.5718  -27.8093 -114.6168  -23.1613  -66.5535  -57.5457 \n##         9        10 \n##  -87.2223   -6.5678\n\nこの固定効果推定は, lm() 関数で企業ダミーを含めた回帰分析と同等である. lm(inv ~ value + capital+0+factor(firm), data = pdata) コマンドで, 定数項を除外 (+0) し企業ダミー (factor(firm)) を含めた推定を行い, summary() コマンドで結果を表示する. 係数の推定値は同じであるが, 決定係数が大きく異なっていることに注意されたい.\n\nsummary(lm(inv ~ value + capital+0+factor(firm), data = pdata))\n## \n## Call:\n## lm(formula = inv ~ value + capital + 0 + factor(firm), data = pdata)\n## \n## Residuals:\n##      Min       1Q   Median       3Q      Max \n## -184.009  -17.643    0.563   19.192  250.710 \n## \n## Coefficients:\n##                  Estimate Std. Error t value Pr(&gt;|t|)    \n## value             0.11012    0.01186   9.288  &lt; 2e-16 ***\n## capital           0.31007    0.01735  17.867  &lt; 2e-16 ***\n## factor(firm)1   -70.29672   49.70796  -1.414   0.1590    \n## factor(firm)2   101.90581   24.93832   4.086 6.49e-05 ***\n## factor(firm)3  -235.57184   24.43162  -9.642  &lt; 2e-16 ***\n## factor(firm)4   -27.80929   14.07775  -1.975   0.0497 *  \n## factor(firm)5  -114.61681   14.16543  -8.091 7.14e-14 ***\n## factor(firm)6   -23.16130   12.66874  -1.828   0.0691 .  \n## factor(firm)7   -66.55347   12.84297  -5.182 5.63e-07 ***\n## factor(firm)8   -57.54566   13.99315  -4.112 5.85e-05 ***\n## factor(firm)9   -87.22227   12.89189  -6.766 1.63e-10 ***\n## factor(firm)10   -6.56784   11.82689  -0.555   0.5793    \n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n## \n## Residual standard error: 52.77 on 188 degrees of freedom\n## Multiple R-squared:  0.9616, Adjusted R-squared:  0.9591 \n## F-statistic:   392 on 12 and 188 DF,  p-value: &lt; 2.2e-16\n\n個別固定効果が統計的に有効かどうか (すなわち, 固定効果モデルとプーリングOLSモデルのどちらが適切か) を検定するには, F検定を実施する. pFtest(gi,gp) コマンドで, 固定効果モデル (gi) とプーリングOLSモデル (gp) を比較するF検定を実行する.\n\npFtest(gi,gp)\n## \n##  F test for individual effects\n## \n## data:  inv ~ value + capital\n## F = 49.177, df1 = 9, df2 = 188, p-value &lt; 2.2e-16\n## alternative hypothesis: significant effects\n\n\n11.3.1 時間効果モデル\n次のモデルを考える. \\[\ninv_{it} = \\beta_1 value_{it} + \\beta_2 capital_{it}+ \\gamma_t +\\alpha_i + u_{it}\n\\] この \\(\\gamma_t\\) は時間固定効果と呼ばれている. ここでは個別固定効果と時間固定効果の2つの固定効果を持つ重回帰モデルを時間効果モデルと呼ぶことにする.\n時間効果モデルを推定するには, plm() 関数で effect=\"twoways\" と model = \"within\" を指定する. plm(inv ~ value + capital, data = pdata, effect=\"twoways\", model = \"within\") コマンドで, 個別固定効果と時間固定効果の両方を含むモデルを推定し, 結果を gi2 に格納する. summary(gi2) コマンドで推定結果の詳細を表示する.\n\ngi2 &lt;- plm(inv ~ value + capital, data = pdata, effect=\"twoways\",model = \"within\")\nsummary(gi2)\n## Twoways effects Within Model\n## \n## Call:\n## plm(formula = inv ~ value + capital, data = pdata, effect = \"twoways\", \n##     model = \"within\")\n## \n## Balanced Panel: n = 10, T = 20, N = 200\n## \n## Residuals:\n##      Min.   1st Qu.    Median   3rd Qu.      Max. \n## -162.6094  -19.4710   -1.2669   19.1277  211.8420 \n## \n## Coefficients:\n##         Estimate Std. Error t-value  Pr(&gt;|t|)    \n## value   0.117716   0.013751  8.5604 6.653e-15 ***\n## capital 0.357916   0.022719 15.7540 &lt; 2.2e-16 ***\n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n## \n## Total Sum of Squares:    1615600\n## Residual Sum of Squares: 452150\n## R-Squared:      0.72015\n## Adj. R-Squared: 0.67047\n## F-statistic: 217.442 on 2 and 169 DF, p-value: &lt; 2.22e-16\n\n推定された個別固定効果と時間固定効果をそれぞれ確認するには, fixef() 関数で effect 引数を指定する. fixef(gi2, effect = \"individual\") コマンドで各企業の固定効果を, fixef(gi2, effect = \"time\") コマンドで各年の固定効果を表示する.\n\nfixef(gi2, effect = \"individual\")\n##         1         2         3         4         5         6         7         8 \n##  -86.9002  120.1540 -222.1310    8.4536  -92.3388   15.9884  -35.4336  -19.4097 \n##         9        10 \n##  -56.6827   39.9369\nfixef(gi2, effect = \"time\")\n##    1935    1936    1937    1938    1939    1940    1941    1942    1943    1944 \n##  -86.90 -106.10 -127.59 -126.13 -156.37 -131.14 -105.70 -108.04 -129.88 -130.00 \n##    1945    1946    1947    1948    1949    1950    1951    1952    1953    1954 \n## -142.58 -118.07 -126.29 -130.62 -160.40 -162.80 -149.38 -151.53 -154.62 -180.43\n\nこの時間効果モデルの推定は, lm() 関数で企業ダミーと年ダミーの両方を含めた回帰分析と同等である. lm(inv ~ value + capital+0+factor(firm)+factor(year), data = pdata) コマンドで, 定数項を除外し企業ダミーと年ダミーを含めた推定を行い, summary() コマンドで結果を表示する. 係数の推定値は同じであるが, 決定係数が大きく異なっていることに注意されたい.\n\nsummary(lm(inv ~ value + capital+0+factor(firm)+factor(year), data = pdata))\n## \n## Call:\n## lm(formula = inv ~ value + capital + 0 + factor(firm) + factor(year), \n##     data = pdata)\n## \n## Residuals:\n##      Min       1Q   Median       3Q      Max \n## -162.609  -19.471   -1.267   19.128  211.842 \n## \n## Coefficients:\n##                    Estimate Std. Error t value Pr(&gt;|t|)    \n## value               0.11772    0.01375   8.560 6.65e-15 ***\n## capital             0.35792    0.02272  15.754  &lt; 2e-16 ***\n## factor(firm)1     -86.90023   56.04663  -1.550 0.122893    \n## factor(firm)2     120.15401   29.16688   4.120 5.93e-05 ***\n## factor(firm)3    -222.13103   28.59744  -7.768 7.37e-13 ***\n## factor(firm)4       8.45361   20.41784   0.414 0.679377    \n## factor(firm)5     -92.33883   20.91106  -4.416 1.79e-05 ***\n## factor(firm)6      15.98841   19.88487   0.804 0.422498    \n## factor(firm)7     -35.43362   20.17003  -1.757 0.080772 .  \n## factor(firm)8     -19.40972   20.49076  -0.947 0.344868    \n## factor(firm)9     -56.68267   19.81211  -2.861 0.004756 ** \n## factor(firm)10     39.93689   20.40337   1.957 0.051951 .  \n## factor(year)1936  -19.19741   23.67586  -0.811 0.418596    \n## factor(year)1937  -40.69001   24.69541  -1.648 0.101277    \n## factor(year)1938  -39.22640   23.23594  -1.688 0.093221 .  \n## factor(year)1939  -69.47029   23.65607  -2.937 0.003780 ** \n## factor(year)1940  -44.23508   23.80979  -1.858 0.064930 .  \n## factor(year)1941  -18.80446   23.69400  -0.794 0.428519    \n## factor(year)1942  -21.13979   23.38163  -0.904 0.367219    \n## factor(year)1943  -42.97762   23.55287  -1.825 0.069808 .  \n## factor(year)1944  -43.09877   23.61020  -1.825 0.069701 .  \n## factor(year)1945  -55.68304   23.89562  -2.330 0.020974 *  \n## factor(year)1946  -31.16928   24.11598  -1.292 0.197957    \n## factor(year)1947  -39.39224   23.78368  -1.656 0.099522 .  \n## factor(year)1948  -43.71651   23.96965  -1.824 0.069945 .  \n## factor(year)1949  -73.49510   24.18292  -3.039 0.002750 ** \n## factor(year)1950  -75.89611   24.34553  -3.117 0.002144 ** \n## factor(year)1951  -62.48091   24.86425  -2.513 0.012911 *  \n## factor(year)1952  -64.63234   25.34950  -2.550 0.011672 *  \n## factor(year)1953  -67.71797   26.61108  -2.545 0.011832 *  \n## factor(year)1954  -93.52622   27.10786  -3.450 0.000708 ***\n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n## \n## Residual standard error: 51.72 on 169 degrees of freedom\n## Multiple R-squared:  0.9668, Adjusted R-squared:  0.9607 \n## F-statistic: 158.8 on 31 and 169 DF,  p-value: &lt; 2.2e-16\n\n時間固定効果が統計的に有効かどうか (すなわち, 時間効果モデルと個別固定効果のみのモデルのどちらが適切か) を検定するには, F検定を実施する. pFtest(gi2, gi) コマンドで, 時間効果モデル (gi2) と個別固定効果のみのモデル (gi) を比較するF検定を実行する.\n\npFtest(gi2, gi)\n## \n##  F test for twoways effects\n## \n## data:  inv ~ value + capital\n## F = 1.4032, df1 = 19, df2 = 169, p-value = 0.1309\n## alternative hypothesis: significant effects",
    "crumbs": [
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>パネル分析</span>"
    ]
  },
  {
    "objectID": "10-panel.html#固定効果-一階差分法",
    "href": "10-panel.html#固定効果-一階差分法",
    "title": "11  パネル分析",
    "section": "11.4 固定効果 (一階差分法)",
    "text": "11.4 固定効果 (一階差分法)\n次のモデルを考える. \\[\ninv_{it} = \\beta_1 value_{it} + \\beta_2 capital_{it} +\\alpha_i + u_{it}\n\\] この \\(\\alpha_i\\) は固定効果と呼ばれている. \\(\\alpha_i\\) は時間 \\(t\\) に対して一定である. \\(\\alpha_i\\) は誤差項と相関があるもしれない.\nそれぞれの階差をとれば \\(\\alpha_i\\) は消去できる. \\[\n\\Delta inv_{it} = \\beta_1 \\Delta value_{it} + \\beta_2 \\Delta capital_{it} + \\Delta u_{it}\n\\]\nこのように変換して回帰分析すれば \\(\\alpha_i\\) は誤差項と相関があっても一致推定量である.\n一階差分法による固定効果推定を実行するには, plm() 関数で model = \"fd\" を指定する. plm(inv ~ value + capital+0, data = pdata, model = \"fd\") コマンドで, 定数項を除外 (+0) して一階差分推定を行い, 結果を gf に格納する. summary(gf) コマンドで推定結果の詳細を表示する.\n\ngf &lt;- plm(inv ~ value + capital+0, data = pdata, model = \"fd\")\nsummary(gf)\n## Oneway (individual) effect First-Difference Model\n## \n## Call:\n## plm(formula = inv ~ value + capital + 0, data = pdata, model = \"fd\")\n## \n## Balanced Panel: n = 10, T = 20, N = 200\n## Observations used in estimation: 190\n## \n## Residuals:\n##    Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n## -202.05  -15.23   -1.76   -1.39    7.95  199.27 \n## \n## Coefficients:\n##          Estimate Std. Error t-value  Pr(&gt;|t|)    \n## value   0.0890628  0.0082341  10.816 &lt; 2.2e-16 ***\n## capital 0.2786940  0.0471564   5.910  1.58e-08 ***\n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n## \n## Total Sum of Squares:    584410\n## Residual Sum of Squares: 345940\n## R-Squared:      0.40876\n## Adj. R-Squared: 0.40561\n## F-statistic: 70.5784 on 2 and 188 DF, p-value: &lt; 2.22e-16\n\n時間固定効果を含む一階差分モデルを推定する場合は, 年ダミーを追加する. plm(inv ~ value + capital+0+factor(year), data = pdata, model = \"fd\") コマンドで, 年ダミー (factor(year)) を含む一階差分推定を行い, 結果を gf2 に格納する. summary(gf2) コマンドで推定結果の詳細を表示する.\n\ngf2 &lt;-plm(inv ~ value + capital+0+factor(year), data = pdata, model = \"fd\")\nsummary(gf2)\n## Oneway (individual) effect First-Difference Model\n## \n## Call:\n## plm(formula = inv ~ value + capital + 0 + factor(year), data = pdata, \n##     model = \"fd\")\n## \n## Balanced Panel: n = 10, T = 20, N = 200\n## Observations used in estimation: 190\n## \n## Residuals:\n##       Min.    1st Qu.     Median    3rd Qu.       Max. \n## -179.69353  -18.68501    0.49555   14.27860  179.03692 \n## \n## Coefficients: (1 dropped because of singularities)\n##                    Estimate Std. Error t-value  Pr(&gt;|t|)    \n## value             0.0875445  0.0095107  9.2048 &lt; 2.2e-16 ***\n## capital           0.3246777  0.0571472  5.6814 5.727e-08 ***\n## factor(year)1935 52.1173697 67.1610018  0.7760   0.43883    \n## factor(year)1936 44.5420725 65.0001486  0.6853   0.49412    \n## factor(year)1937 32.2308400 62.5656219  0.5152   0.60712    \n## factor(year)1938 19.6675926 60.6802571  0.3241   0.74625    \n## factor(year)1939 -3.0067716 58.4729853 -0.0514   0.95905    \n## factor(year)1940 23.9596588 56.8175845  0.4217   0.67378    \n## factor(year)1941 48.5989734 54.8059164  0.8867   0.37648    \n## factor(year)1942 40.9122279 52.7118790  0.7761   0.43875    \n## factor(year)1943 22.8491024 50.5894648  0.4517   0.65209    \n## factor(year)1944 23.6577035 48.8480758  0.4843   0.62879    \n## factor(year)1945 14.7036587 46.6708001  0.3151   0.75311    \n## factor(year)1946 41.6241613 44.2490709  0.9407   0.34821    \n## factor(year)1947 27.5209677 40.4024259  0.6812   0.49670    \n## factor(year)1948 23.6476936 37.0841079  0.6377   0.52455    \n## factor(year)1949 -4.3351290 33.6481639 -0.1288   0.89764    \n## factor(year)1950 -4.2709916 30.2836724 -0.1410   0.88801    \n## factor(year)1951 16.8493484 26.2244634  0.6425   0.52142    \n## factor(year)1952 18.0590591 20.8995024  0.8641   0.38876    \n## factor(year)1953 24.3453549 13.9307034  1.7476   0.08235 .  \n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n## \n## Total Sum of Squares:    584410\n## Residual Sum of Squares: 293000\n## R-Squared:      0.49864\n## Adj. R-Squared: 0.4393\n## F-statistic: 8.5881 on 21 and 169 DF, p-value: &lt; 2.22e-16\n\n時間固定効果が統計的に有効かどうかを検定するには, F検定を実施する. pFtest(gf2,gf) コマンドで, 時間効果を含むモデル (gf2) と含まないモデル (gf) を比較するF検定を実行する.\n\npFtest(gf2,gf)\n## \n##  F test for individual effects\n## \n## data:  inv ~ value + capital + 0 + factor(year)\n## F = 1.607, df1 = 19, df2 = 169, p-value = 0.05928\n## alternative hypothesis: significant effects\n\n\n11.4.1 平均差分法と一階差分法\n平均差分法と一階差分法は誤差項の仮定をどのようにおくかによって変わってくる. 誤差項の階差をとることによって時間を通じて無相関になるなら一階差分法が望ましいであろう. しかしながら, 固定効果, 時間効果の値がきちんと計算して, それが経済学的解釈が可能なら, 平均差分法が望ましい. さらに他のプーリングOLSの仮定と変量効果モデルとの比較の意味でも平均差分法がよく使われる.\nなお時間が2期間のパネルデータのとき, 平均差分法も一階差分法も計算値は同じである. たとえば \\(t=2\\)のときの変数 \\(x_{it}\\) の平均差分値は \\[\nx_{2t}-\\bar{x}_i=x_{2t}-\\frac{x_{i1}+x_{i2}}{2}=\\frac{x_{i2}-x_{i1}}{2}\n\\] となる.",
    "crumbs": [
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>パネル分析</span>"
    ]
  },
  {
    "objectID": "10-panel.html#変量効果",
    "href": "10-panel.html#変量効果",
    "title": "11  パネル分析",
    "section": "11.5 変量効果",
    "text": "11.5 変量効果\n次のモデルを考える. \\[\ninv_{it} = \\beta_1 value_{it} + \\beta_2 capital_{it} +\\alpha_i + u_{it}\n\\] この \\(\\alpha_i\\) は時間 \\(t\\) について一定であるが, \\(i\\) について独立同一分布の確率変数にしたがう. さらに \\(\\alpha_i\\) は説明変数と無相関である時, この \\(\\alpha_i\\) は個別変量効果と呼ばれている. 個別固定効果は説明変数と無相関を仮定していない. この個別変量効果を持つ重回帰モデルを変量効果モデルと呼ぶことにする.\n変量効果モデルを推定するには, plm() 関数で model = \"random\" を指定する. plm(inv ~ value + capital, data = pdata, model = \"random\") コマンドで変量効果推定を行い, 結果を gr に格納する. summary(gr) コマンドで推定結果の詳細を表示する.\n\ngr &lt;- plm(inv ~ value + capital, data = pdata, model = \"random\")\nsummary(gr)\n## Oneway (individual) effect Random Effect Model \n##    (Swamy-Arora's transformation)\n## \n## Call:\n## plm(formula = inv ~ value + capital, data = pdata, model = \"random\")\n## \n## Balanced Panel: n = 10, T = 20, N = 200\n## \n## Effects:\n##                   var std.dev share\n## idiosyncratic 2784.46   52.77 0.282\n## individual    7089.80   84.20 0.718\n## theta: 0.8612\n## \n## Residuals:\n##      Min.   1st Qu.    Median   3rd Qu.      Max. \n## -177.6063  -19.7350    4.6851   19.5105  252.8743 \n## \n## Coefficients:\n##               Estimate Std. Error z-value Pr(&gt;|z|)    \n## (Intercept) -57.834415  28.898935 -2.0013  0.04536 *  \n## value         0.109781   0.010493 10.4627  &lt; 2e-16 ***\n## capital       0.308113   0.017180 17.9339  &lt; 2e-16 ***\n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n## \n## Total Sum of Squares:    2381400\n## Residual Sum of Squares: 548900\n## R-Squared:      0.7695\n## Adj. R-Squared: 0.76716\n## Chisq: 657.674 on 2 DF, p-value: &lt; 2.22e-16\n\n推定された変量効果の値を確認するには, ranef() 関数を使用する. ranef(gr) コマンドで各企業の変量効果の推定値を表示する.\n\nranef(gr)\n##            1            2            3            4            5            6 \n##   -9.5242955  157.8910235 -172.8958044   29.9119801  -54.6790089   34.3461316 \n##            7            8            9           10 \n##   -7.8977584    0.6726376  -28.1393497   50.3144442\n\n\n11.5.1 ハウスマン検定\n帰無仮説が変量効果モデル, 対立仮説が固定効果モデルの検定はハウスマン検定を実施する. ハウスマン検定では, 変量効果モデルと固定効果モデルの係数の差が統計的に有意かどうかを検定する. phtest(gi,gr) コマンドで, 固定効果モデル (gi) と変量効果モデル (gr) のハウスマン検定を実行する.\n\nphtest(gi,gr)\n## \n##  Hausman Test\n## \n## data:  inv ~ value + capital\n## chisq = 2.3304, df = 2, p-value = 0.3119\n## alternative hypothesis: one model is inconsistent",
    "crumbs": [
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>パネル分析</span>"
    ]
  },
  {
    "objectID": "10-panel.html#クラスターロバスト分散",
    "href": "10-panel.html#クラスターロバスト分散",
    "title": "11  パネル分析",
    "section": "11.6 クラスターロバスト分散",
    "text": "11.6 クラスターロバスト分散\n固定効果モデルにおいて, 分散不均一が疑われる場合, クラスターロバスト分散を用いる. 時間効果がない固定効果モデル (gi) について, クラスターロバスト標準誤差を計算するには, coeftest() 関数と vcovHC() 関数を組み合わせて使用する. coeftest(gi, vcov=vcovHC(gi, type=\"sss\")) コマンドで, type=\"sss\" を指定したクラスターロバスト分散を用いた係数検定を実行する.\n\ncoeftest(gi,vcov=vcovHC(gi,type=\"sss\"))\n## \n## t test of coefficients:\n## \n##         Estimate Std. Error t value  Pr(&gt;|t|)    \n## value   0.110124   0.015156  7.2660 9.596e-12 ***\n## capital 0.310065   0.052618  5.8927 1.726e-08 ***\n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n時間効果モデル (gi2) についても同様に, クラスターロバスト標準誤差を計算できる. coeftest(gi2, vcov=vcovHC(gi2, type=\"sss\")) コマンドで, 時間効果モデルにおけるクラスターロバスト分散を用いた係数検定を実行する.\n\ncoeftest(gi2,vcov=vcovHC(gi2,type=\"sss\"))\n## \n## t test of coefficients:\n## \n##         Estimate Std. Error t value  Pr(&gt;|t|)    \n## value   0.117716   0.010263 11.4697 &lt; 2.2e-16 ***\n## capital 0.357916   0.045367  7.8893  3.62e-13 ***\n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nSTATA の計算結果に合わせるには, 個別固定効果モデルに年ダミーを明示的に追加する必要がある. update(gi, .~. + factor(year)) コマンドで, モデル gi に年ダミーを追加して更新し, git に格納する. その後 coeftest(git, vcov=vcovHC(git, type=\"sss\")) コマンドで, クラスターロバスト分散を用いた係数検定を実行する. gi2 と git のどちらを採用するかによって結果が変わってしまうので注意されたい.\n\ngit &lt;- update(gi, .~. + factor(year))\ncoeftest(git,vcov=vcovHC(git,type=\"sss\"))\n## \n## t test of coefficients:\n## \n##                    Estimate Std. Error t value  Pr(&gt;|t|)    \n## value              0.117716   0.010794 10.9055 &lt; 2.2e-16 ***\n## capital            0.357916   0.047715  7.5012 3.424e-12 ***\n## factor(year)1936 -19.197405  20.640669 -0.9301 0.3536580    \n## factor(year)1937 -40.690009  33.190087 -1.2260 0.2219160    \n## factor(year)1938 -39.226404  15.692472 -2.4997 0.0133837 *  \n## factor(year)1939 -69.470288  26.923231 -2.5803 0.0107211 *  \n## factor(year)1940 -44.235085  17.323706 -2.5534 0.0115505 *  \n## factor(year)1941 -18.804463  17.797543 -1.0566 0.2922130    \n## factor(year)1942 -21.139792  14.125147 -1.4966 0.1363608    \n## factor(year)1943 -42.977623  12.509017 -3.4357 0.0007437 ***\n## factor(year)1944 -43.098772  10.965103 -3.9305 0.0001234 ***\n## factor(year)1945 -55.683040  15.159383 -3.6732 0.0003212 ***\n## factor(year)1946 -31.169284  20.858408 -1.4943 0.1369549    \n## factor(year)1947 -39.392242  26.363118 -1.4942 0.1369835    \n## factor(year)1948 -43.716514  38.769856 -1.1276 0.2610913    \n## factor(year)1949 -73.495099  38.147491 -1.9266 0.0557069 .  \n## factor(year)1950 -75.896112  36.695524 -2.0683 0.0401383 *  \n## factor(year)1951 -62.480912  49.279892 -1.2679 0.2065854    \n## factor(year)1952 -64.632341  51.417852 -1.2570 0.2104874    \n## factor(year)1953 -67.717966  43.622288 -1.5524 0.1224442    \n## factor(year)1954 -93.526221  31.637576 -2.9562 0.0035603 ** \n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n11.6.1 分散不均一の検定\n固定効果モデルにおいて, 分散不均一かどうかを検定するには, Breusch-Pagan 検定を実施する. bptest() 関数を使用して, 企業ダミーを含むモデルで検定を行う. bptest(inv ~ value + capital + factor(firm), data=pdata) コマンドで, 個別固定効果モデルの分散不均一性を検定する.\n\nbptest(inv ~ value + capital + factor(firm), data=pdata)\n## \n##  studentized Breusch-Pagan test\n## \n## data:  inv ~ value + capital + factor(firm)\n## BP = 85.836, df = 11, p-value = 1.086e-13\n\n時間効果モデルの場合, 企業ダミーと年ダミーの両方を含めて検定を行う. bptest(inv ~ value + capital + factor(firm) + factor(year), data=pdata) コマンドで, 時間効果モデルの分散不均一性を検定する.\n\nbptest(inv ~ value + capital + factor(firm) + factor(year),data=pdata)\n## \n##  studentized Breusch-Pagan test\n## \n## data:  inv ~ value + capital + factor(firm) + factor(year)\n## BP = 97.357, df = 30, p-value = 4.833e-09",
    "crumbs": [
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>パネル分析</span>"
    ]
  },
  {
    "objectID": "02-rstudio.html",
    "href": "02-rstudio.html",
    "title": "3  RStudio",
    "section": "",
    "text": "3.1 RStudio とは\nRStudio は R の統合開発環境 (IDE, Integrated Development Enviroment) の一つである. オープンソース版が存在する.\nhttps://ja.wikipedia.org/wiki/R-Studio",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>RStudio</span>"
    ]
  },
  {
    "objectID": "02-rstudio.html#rstudio-のインストール",
    "href": "02-rstudio.html#rstudio-のインストール",
    "title": "3  RStudio",
    "section": "3.2 RStudio のインストール",
    "text": "3.2 RStudio のインストール\nオープンソース版のRStudio のインストールは\nhttps://www.rstudio.com/products/rstudio/download/\nにいき, 該当機種のファイルをダウンロードする. ダウンロードしたあとに実行すればインストールされる.\nUbuntu ならサーバー版を導入するとよい.\nhttps://www.rstudio.com/products/rstudio/download-server/",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>RStudio</span>"
    ]
  },
  {
    "objectID": "02-rstudio.html#rstudio-の設定",
    "href": "02-rstudio.html#rstudio-の設定",
    "title": "3  RStudio",
    "section": "3.3 RStudio の設定",
    "text": "3.3 RStudio の設定\nメニューバーの [Tools] から [Global Options…] を選択することで設定を変更できる.\n[General] で以下のように [Restore .RData …] のチェックを外していいて, その下を Never にしている. これは, 立ち上げたきに環境をクリーンし, 終了時に, データの保存を聞かれないようにするためである.\n\n\n\n\n\n\n\n\n\n次に, [Code] の タブ [Saving] で. [Default text encoding] を UTF-8 とする. Windows 以外だとOSのシステムフォントが同じなので問題ない. しかし Windows は SJIS を拡張した CP932 なので, 注意が必要である.\nWindows のRは UTF-8 を選択してもR自身はCP932処理している. ただ, 他のOSとの併用の場合, UTF-8 にしたほうがよいだろう. またHTMLファイルは UTF-8 でのファイルが前提になりつつあるので, HTML として出力を考えているなら, UTF-8 としたほうが無難である.\nまたインターネットで公開されている日本語のRファイルは Windows の使用が前提となっているため, 文字コードが CP932 であることが多い. Windows 以外を使っている場合, 一時的に文字コードを SJIS を選択する必要がある.\n\n\n\n\n\n\n\n\n\nあと, [R Markdown] で 真ん中あたりの [Show output preview in:] を View Pane に変更する",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>RStudio</span>"
    ]
  },
  {
    "objectID": "02-rstudio.html#rstudio-の使い方",
    "href": "02-rstudio.html#rstudio-の使い方",
    "title": "3  RStudio",
    "section": "3.4 RStudio の使い方",
    "text": "3.4 RStudio の使い方\nRStudio の使い方として日本語版のチートシートがある.\nhttps://github.com/rstudio/cheatsheets/raw/master/translations/japanese/rstudio-IDE-cheatsheet_ja.pdf\n英語であるがこの動画も有益である. 第一章だけ公開されている.\nhttps://www.datacamp.com/courses/working-with-the-rstudio-ide-part-1\nRStudio プロジェクト単位で複数のソースコードを管理するのことが推奨される. そうするとプロジェクトごとに作業ディレクトリが設定される. プロジェクトはメニューバー の [File] から [New Project] を選択する. そうすると新たに新たにディレクトリを作成するか, 既存のディレクトリを採用するかなどが選べる. また, バージョン管理ソフトを導入していればそこから取り入れることも可能となる.\n\n\n\n\n\n\n\n\n\nプロジェクトを立ち上げると左にコンソールペイン (Console Pane) が, 右側に上下に二分割されたペインが現れる. この配置は メニューバーの [Tools] から [Project Options -&gt; Pane Layout] を選べば変更可能である. コンソールペインにコマンドを入力するとその結果が直下に返される. 何か入力した後に, Ctrl + l (Cmd + l) を押すと, 画面が更新される. 上下の矢印キーで過去に実行したコマンドを選択できる.\nメニューバー の [File] から [New File -&gt; RScript] を選択するか, Ctrl + Shift + n (Cmd + Shift + n) と入力するか, メニューバー下の一番左の白紙のアイコンをクリックすると, Rのスクリプトファイルが新規に作られる. スクリプフォファイルを開くと左側のコンソール画面の上にソースペインが登場する. ここにソースコードを書く.\nソースペインで何かコマンドを書いていきながら, ソースコードの該当行で Ctrl + Enter (Cmd + Return) と入力するか, ソースペインの上側の右に並んでいるアイコンのうち, 左側のRunと書かれたアイコンをクリックすると, 該当行がコンソール画面で実行される. 複数行選択した後に, メニューバー の [Code] から [Run Selected line(s)] を選ぶか, Ctrl + Shift + Enter (Cmd + Shift + Enter) と入力すると複数行をまとめて実行させることも可能である.\nメニューバー の [File] から [Save] を選択するか, Ctrl + s (Cmd + s) と入力するか, メニューバー下の左から3番目のフロッピーディスクアイコンをクリック すると, スクリプトファイルを保存することができる. またメニューバー の [File] から [Open] を選択するか, Ctrl + o (Cmd + o) と入力するか, メニューバー下の左から2番めのフォルダを開くアイコンをクリックすると, 既存のスクリプトファイルを開くことができる.\n\n\n\n\n\n\n\n\n\n右上のペインには Environment と History のタブがある. Environment は現在使っているオブジェクトが表示される. 最初は空白である. 変数に数値を代入 (R の言い方ではオブジェクトに付値) することによって, 値が付け加わっている. History はこれまでの履歴が記録される. 履歴の一部ををエディトペインかコンソールペインに挿入することができる.\n右下のペインには Files, Plots, Packages, Help, Viewer のタブがある. Files ペインはWindowsではエクスプローラーのようなもので, Mac はFinder のようなもので, ファイル管理をおこなう. ファイル管理として新たなフォルダを作成したり, ファイルを削除したり, ファイル名を変更したりする.\nまたワーキングディレクトリを直感的に設定することもできる. ワーキングを設定したい場所に移動して, Files ペインの上に並んでいるアイコンのうち, Moreをクリックし, [Set As Working Directory] をクリックすればよい.\nPlots ペインはコンソール画面で作図をコマンドの実行したら, 表示されるペインである. そこで作成した図をコマンドを使わずに保存したりすることができる. Packages ペインは現在Rに導入されているパッケージリストが表示される. そこに無いパッケージはメニューバーの [Tools] から [Install Packages…] を選択して実行すればよい. すでにあるパッケージは, パッケージ名の左側のボックスをチェックすれば, ライブライリ名を付けずにコマンドを実行させることができる.\nHelp ペインはその名の通り, ヘルプ画面が表示される. コンソールペインから help (コマンド) もしくは ?コマンド と入力するとそのコマンドのヘルプがこのペインに表示される. R ではソースペインやコンソールペインで, コマンド入力していると, コマンドの後補があらわてくる. [TAB] でコマンドを補完できる. さらにそのコマンドでどのような引数が使われるのかも示される. さらに [TAB] を押せば, 引数を選べるだけでなく, 簡単なコマンドの説明がある. そのときに [F1] を押せば, より詳細なヘルプが立ち上がる. また Packages パインから該当パッケージをクリックするとそのパッケージのコマンド一覧が Help ペインに表示される.\n\n\n\n\n\n\n\n\n\n最後のViewer ペインは R Markdown で作成したファイルを HTMLで出力したときに表示されるペインである. 最初の設定だと別のウィンドウ画面として結果が表示される. このペインに出力されるためには [Tools -&gt; R Markdown] にいき, 真ん中あたりの [Show output preview in:] を View Pane に変更する必要がある. その上でソースペインから [Ctrl + Shift + k] とするか, ソースペインの左側のアイコン群の一番右側のノートのアイコンをクリックすると, 確認画面が現れるので HTML を押す. そうするとそのコードがすべて実行されて, 実行結果が作図も含めてHTMLファイルに出力される. もしくはメニューバーの [File] から [Knit Document…] としを選択するとよい.\n\n\n\n\n\n\n\n\n\nこれは knitr と rmarkdown いわれるパッケージを利用したもので, Rのコードを埋め込んだマークダウンファイルを作成し, そこからHTMLファイルを作成する. 他にも word ファイル や pdf ファイル生成することも適切に設定していれば可能である. ソースコードだけでなく, マークダウンファイルに R コマンドを埋め込んだ Rmd ファイルを作成することができる それは新規作成でRスクリプトでなく, R Notebook や R Markdown を選択すればよい.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>RStudio</span>"
    ]
  },
  {
    "objectID": "04-dataframe.html",
    "href": "04-dataframe.html",
    "title": "5  データ構造",
    "section": "",
    "text": "5.1 リスト\n複数のオブジェクト（ベクトルや別のリストなど）をまとめたものがリストである。 型の異なるベクトルでも list() に渡すことで 1 つのリストにまとめられる。\nリストにも長さという属性があり、length() で要素数を確認できる。\n(lst &lt;- list(\"a\",c(3,3,2)))\n## [[1]]\n## [1] \"a\"\n## \n## [[2]]\n## [1] 3 3 2\ntypeof(lst)\n## [1] \"list\"\nlength(lst)\n## [1] 2\nclass() でオブジェクトのクラスを、str() で内部構造を確認できる。\nclass(lst)\n## [1] \"list\"\nstr(lst)\n## List of 2\n##  $ : chr \"a\"\n##  $ : num [1:3] 3 3 2\nリストは入れ子にすることもできる。これは単一の型しか持てないベクトルとの大きな違いである。\ntypeof(list(\"b\",lst))\n## [1] \"list\"\nリストをベクトルに変換するには unlist() を使う。構成要素の型が異なる場合は、ベクトルに変換できるように強制変換が行われる。\nlst&lt;-list(1:3,2:6)\nlst\n## [[1]]\n## [1] 1 2 3\n## \n## [[2]]\n## [1] 2 3 4 5 6\nunlist(lst)\n## [1] 1 2 3 2 3 4 5 6\nunlist(list(\"a\",1:4))\n## [1] \"a\" \"1\" \"2\" \"3\" \"4\"\n個々の要素の長さを調べたいときは lengths(lst) が便利で、各要素に同じ処理を施す場合は lapply() や sapply() を組み合わせるとよい。",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>データ構造</span>"
    ]
  },
  {
    "objectID": "04-dataframe.html#ベクトル",
    "href": "04-dataframe.html#ベクトル",
    "title": "5  データ構造",
    "section": "",
    "text": "5.1.1 ベクトルのアクセス\nベクトルの要素は角括弧 [] にインデックスを指定して取り出す。たとえば 3 番目の要素を取得するには次のようにする。\n\nnum &lt;- c(2,3,7,9)\nnum[3]\n## [1] 7\n\nベクトルには名前属性を付与することもできる。\n\nvec &lt;- c(x= 3, y =3, z = 4)\nvec\n## x y z \n## 3 3 4\nnames(vec)\n## [1] \"x\" \"y\" \"z\"\n\n既存のベクトルに後から名前を設定する場合は次のようにする。\n\nnames(num) &lt;- letters[1:4]\nnum\n## a b c d \n## 2 3 7 9\n\n名前付きベクトルでは、文字列で要素を参照できる。\n\nvec[\"x\"]\n## x \n## 3\nnum[\"d\"]\n## d \n## 9",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>データ構造</span>"
    ]
  },
  {
    "objectID": "04-dataframe.html#リスト",
    "href": "04-dataframe.html#リスト",
    "title": "5  データ構造",
    "section": "",
    "text": "5.1.1 リストのアクセス\nリストの要素も角括弧を用いて参照する。単一の角括弧 [] を使うと、要素を取り出してもリストのまま返る。以下は最初の要素（＝ 1 番目のリスト）を取得する例である。\n\nlst[1]\n## [[1]]\n## [1] 1 2 3\n\n名前属性を付けたリストであれば、文字列でアクセスできる。\n\n(lst &lt;- list(name=\"a\",num=c(3,3,2)))\n## $name\n## [1] \"a\"\n## \n## $num\n## [1] 3 3 2\nnames(lst)\n## [1] \"name\" \"num\"\n\nこの状態で次のように書けば 2 番目の要素を取り出せる。\n\nlst[\"num\"]\n## $num\n## [1] 3 3 2\n\nいずれの場合も [] で取り出した結果はリストである点に注意する。\n\ntypeof(lst[1])\n## [1] \"list\"\ntypeof(lst[\"num\"])\n## [1] \"list\"\n\nベクトルとして取り出したい場合は二重角括弧 [[ ]] を使う。これによりリスト要素の中身がそのまま返る。\n\nlst[[2]]\n## [1] 3 3 2\ntypeof(lst[[2]])\n## [1] \"double\"\n\n名前付きの場合は次のように書くこともできる。\n\nlst[[\"num\"]]\n## [1] 3 3 2\nlst$num\n## [1] 3 3 2\n\nリスト内のベクトルに対して関数を適用したいときは、二重括弧か $ 記法でベクトルを取り出してから利用する。次の例では $ 記法を使っているが、コメント行で示したように二重括弧を使っても結果は同じである。\n\n## mean(lst[[2]])\n## mean(lst[[\"num\"]])\nmean(lst$num)\n## [1] 2.666667\n\nwith() を使えば、リスト内の要素を名前だけで参照できる。\n\nwith(lst, mean(num))\n## [1] 2.666667\n\nリストの要素を削除したいときは、該当要素に NULL を代入する。\n\nlst$num &lt;- NULL\nlst\n## $name\n## [1] \"a\"",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>データ構造</span>"
    ]
  },
  {
    "objectID": "04-dataframe.html#因子ベクトル",
    "href": "04-dataframe.html#因子ベクトル",
    "title": "5  データ構造",
    "section": "5.2 因子ベクトル",
    "text": "5.2 因子ベクトル\n\n5.2.1 factor\n文字列ベクトルを factor() に渡すと、カテゴリ情報を持つ因子 (factor) ベクトルを作成できる。\n\n(x &lt;- c(\"L\",\"S\",\"M\",\"M\",\"L\"))\n## [1] \"L\" \"S\" \"M\" \"M\" \"L\"\n(x.fac &lt;- factor(x))\n## [1] L S M M L\n## Levels: L M S\n\n因子ベクトルの実体は、levels という属性を持つ整数ベクトルである。値そのものではなく水準の位置を保持している点に注意する。\n\ntypeof(x.fac)\n## [1] \"integer\"\nlength(x.fac)\n## [1] 5\nlevels(x.fac)\n## [1] \"L\" \"M\" \"S\"\n\nclass() で因子であることを確認し、str() で水準情報などの属性を詳しく確認できる。\n\nclass(x.fac)\n## [1] \"factor\"\nstr(x.fac)\n##  Factor w/ 3 levels \"L\",\"M\",\"S\": 1 3 2 2 1\n\n水準の表示順は既定ではアルファベット順に並ぶが、levels 引数を指定すれば任意の順に設定できる。\n\n(x.factor &lt;- factor(x,levels=c(\"S\",\"M\",\"L\")))\n## [1] L S M M L\n## Levels: S M L\n\nさらに ordered() を使うと、水準に大小関係（順序）を持たせた因子を作れる。\n\n(x.order &lt;- ordered(x,levels=c(\"S\",\"M\",\"L\")))\n## [1] L S M M L\n## Levels: S &lt; M &lt; L\n\n分析の途中で未使用の水準を落としたいときは droplevels(x.factor) を利用する。\n\n\n5.2.2 cut\n連続値を区間ごとに区分して因子化したい場合は cut() を用いる。まず 0 から 10 までの値を乱数で生成する。\n\nx &lt;- runif(10,0,10)\nx\n##  [1] 4.1585731 5.8646042 7.7025480 3.5495058 0.5170076 5.5413017 1.3172061\n##  [8] 1.6155902 9.7999084 6.7534222\n\nbreaks に分割数を指定すると、最小値から最大値までを等間隔に区切る。\n\ncut(x, breaks=5)\n##  [1] (2.37,4.23]  (4.23,6.09]  (6.09,7.94]  (2.37,4.23]  (0.508,2.37]\n##  [6] (4.23,6.09]  (0.508,2.37] (0.508,2.37] (7.94,9.81]  (6.09,7.94] \n## Levels: (0.508,2.37] (2.37,4.23] (4.23,6.09] (6.09,7.94] (7.94,9.81]\n\nこれは観測値の最小値から最大値までの区間を 5 等分した結果を返している。\n区間境界を自分で指定したい場合は、breaks に数値ベクトルを渡す。\n\ncut(x,breaks=c(0,2,4,6,8,10))\n##  [1] (4,6]  (4,6]  (6,8]  (2,4]  (0,2]  (4,6]  (0,2]  (0,2]  (8,10] (6,8] \n## Levels: (0,2] (2,4] (4,6] (6,8] (8,10]\n\n0 より大きく 2 以下、2 より大きく 4 以下、… のように区切られている。\n最初の区間に最小値を含めたいときは include.lowest = TRUE を指定する。\n\ncut(x, breaks=seq(0,10,2),include.lowest=TRUE)\n##  [1] (4,6]  (4,6]  (6,8]  (2,4]  [0,2]  (4,6]  [0,2]  [0,2]  (8,10] (6,8] \n## Levels: [0,2] (2,4] (4,6] (6,8] (8,10]\n\n区間の右端を含めたくない場合（例: 0 以上 2 未満、2 以上 4 未満、…）は right = FALSE を指定する。\n\ncut(x, breaks=seq(0,10,2),right=FALSE,include.lowest=TRUE)\n##  [1] [4,6)  [4,6)  [6,8)  [2,4)  [0,2)  [4,6)  [0,2)  [0,2)  [8,10] [6,8) \n## Levels: [0,2) [2,4) [4,6) [6,8) [8,10]\n\nこのときの include.lowest = TRUE は最大値を最後の区間に含める指定となる。\n水準名をわかりやすいラベルに変えたいときは labels 引数で指定する。\n\ncut(\n  x,\n  breaks = seq(0, 10, 2),\n  right = FALSE,\n  include.lowest = TRUE,\n  labels = c(\"A\", \"B\", \"C\", \"D\", \"E\")\n)\n##  [1] C C D B A C A A E D\n## Levels: A B C D E",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>データ構造</span>"
    ]
  },
  {
    "objectID": "04-dataframe.html#行列",
    "href": "04-dataframe.html#行列",
    "title": "5  データ構造",
    "section": "5.3 行列",
    "text": "5.3 行列\nベクトルに縦横の次元情報を与えることで行列 (matrix) を作成できる。\n\nmat &lt;- matrix(1:10, nrow=2,ncol=5)\nmat\n##      [,1] [,2] [,3] [,4] [,5]\n## [1,]    1    3    5    7    9\n## [2,]    2    4    6    8   10\n\nmatrix() は既定では列方向にデータを埋めていくため、1 列目が 1, 2、2 列目が 3, 4… のように配置される。\nbyrow = TRUE を指定すると、行方向にデータを埋めていく。\n\nmatrix(1:10, nrow=2,ncol=5,byrow = TRUE)\n##      [,1] [,2] [,3] [,4] [,5]\n## [1,]    1    2    3    4    5\n## [2,]    6    7    8    9   10\n\n行列は dim 属性を持つ数値ベクトルとして表現されている。\n\ntypeof(mat)\n## [1] \"integer\"\nlength(mat)\n## [1] 10\ndim(mat)\n## [1] 2 5\n\n行数・列数は nrow()、ncol() で取得できる。\n\nnrow(mat)\n## [1] 2\nncol(mat)\n## [1] 5\n\nclass() や str() を使えば、クラス名や内部構造を確認できる。\n\nclass(mat)\n## [1] \"matrix\" \"array\"\nstr(mat)\n##  int [1:2, 1:5] 1 2 3 4 5 6 7 8 9 10\n\n\n5.3.1 行列の演算\n行方向に結合するには rbind() を用いる。\n\nmata&lt;-matrix(1:5,nrow=1,ncol=5)\nrbind(mat,mata)\n##      [,1] [,2] [,3] [,4] [,5]\n## [1,]    1    3    5    7    9\n## [2,]    2    4    6    8   10\n## [3,]    1    2    3    4    5\n\n列方向に結合するには cbind() を用いる。\n\nmatb&lt;-matrix(1:4,nrow=2,ncol=2)\ncbind(mat,matb)\n##      [,1] [,2] [,3] [,4] [,5] [,6] [,7]\n## [1,]    1    3    5    7    9    1    3\n## [2,]    2    4    6    8   10    2    4\n\n転置行列は t() で得られる。\n\nt(mat)\n##      [,1] [,2]\n## [1,]    1    2\n## [2,]    3    4\n## [3,]    5    6\n## [4,]    7    8\n## [5,]    9   10\n\n* 演算子は要素ごとの積を計算する。線形代数で使う行列積を計算したい場合は %*% を使う。\n\nmatb %*% mat\n##      [,1] [,2] [,3] [,4] [,5]\n## [1,]    7   15   23   31   39\n## [2,]   10   22   34   46   58\n\nこのとき、行列の次元（内積をとる側の列数と行数）が一致している必要がある。\n列ごとの合計は colSums()、行ごとの合計は rowSums() が利用できる。\n\ncolSums(mat)\n## [1]  3  7 11 15 19\nrowSums(mat)\n## [1] 25 30\n\n返り値はいずれもベクトルである。行列全体の総和を求める場合は sum() を使えばよい。\n\nsum(mat)\n## [1] 55\n\n平均値についても同様に colMeans()、rowMeans() を使える。\n\ncolMeans(mat)\n## [1] 1.5 3.5 5.5 7.5 9.5\nrowMeans(mat)\n## [1] 5 6\n\n\n\n5.3.2 行列のアクセス\n行列から行や列を取り出すときも角括弧 [] を用いる。次の例では 2 行目を抽出している。\n\nmat[2,]\n## [1]  2  4  6  8 10\n\nこのままだとベクトルとして返されるが、drop = FALSE を指定すれば行列の形を保ったまま取り出せる。\n\nmat[, 3, drop=FALSE]\n##      [,1]\n## [1,]    5\n## [2,]    6\n\n連続した列を取り出す場合は、特に drop を指定しなくても行列として返される。\n\nmat[,2:3]\n##      [,1] [,2]\n## [1,]    3    5\n## [2,]    4    6\n\n特定の要素を取り出すには行番号と列番号を指定する。\n\nmat[2,3]\n## [1] 6\n\n行・列に名前を付けることもできる。\n\nrownames(mat) &lt;- letters[1:2]\ncolnames(mat) &lt;- 1:5\nmat\n##   1 2 3 4  5\n## a 1 3 5 7  9\n## b 2 4 6 8 10\n\n名前を付けると、名前でアクセスできるようになる。\n\nmat[\"a\",\"3\"]\n## [1] 5\n\ndimnames() を使えば、行名と列名をまとめて設定・上書きできる。\n\ndimnames(mat) &lt;- list(LETTERS[1:2],2:6)\nmat\n##   2 3 4 5  6\n## A 1 3 5 7  9\n## B 2 4 6 8 10",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>データ構造</span>"
    ]
  },
  {
    "objectID": "04-dataframe.html#データフレイム",
    "href": "04-dataframe.html#データフレイム",
    "title": "5  データ構造",
    "section": "5.4 データフレイム",
    "text": "5.4 データフレイム\n同じ長さのベクトルを組み合わせたリストがデータフレイム (data frame) である。 次のように data.frame() を使って作成できる。\n\ndf &lt;- data.frame(x = rnorm(10), y = letters[1:10])\n\nここでは letters[1:10] を使って 10 個の小文字アルファベットを列として追加している。 R 4.0 以降は既定で文字列が因子化されないが、古いコードを扱う際は stringsAsFactors = FALSE を明示すると安全な場合がある。\nデータフレイムは大規模になることが多いため、先頭数行だけを確認するには head() を使う。\n\nhead(df)\n##             x y\n## 1  1.61792555 a\n## 2  1.69425654 b\n## 3 -0.14220117 c\n## 4  0.13712237 d\n## 5 -0.07667399 e\n## 6  0.32534619 f\n\n要約統計量を手早く確認したい場合は summary() が便利である。\n\nsummary(df)\n##        x                y            \n##  Min.   :-1.2254   Length:10         \n##  1st Qu.:-0.1258   Class :character  \n##  Median : 0.1057   Mode  :character  \n##  Mean   : 0.3445                     \n##  3rd Qu.: 0.9884                     \n##  Max.   : 1.6943\n\n内部構造や型を調べたいときは str() を使う。\n\nstr(df)\n## 'data.frame':    10 obs. of  2 variables:\n##  $ x: num  1.6179 1.6943 -0.1422 0.1371 -0.0767 ...\n##  $ y: chr  \"a\" \"b\" \"c\" \"d\" ...\n\nデータフレイムの実体はリストである。\n\ntypeof(df)\n## [1] \"list\"\nclass(df)\n## [1] \"data.frame\"\n\nそのため、リスト同様に長さや名前の属性を持つ。\n\nlength(df)\n## [1] 2\nnames(df)\n## [1] \"x\" \"y\"\n\n一方で、行列と同じように次元情報も持っている。\n\ndim(df)\n## [1] 10  2\nncol(df)\n## [1] 2\nnrow(df)\n## [1] 10\n\nここで ncol(df) は length(df) と同じ値を返す。\n行列と同じく、行名・列名も持つ。\n\ndimnames(df)\n## [[1]]\n##  [1] \"1\"  \"2\"  \"3\"  \"4\"  \"5\"  \"6\"  \"7\"  \"8\"  \"9\"  \"10\"\n## \n## [[2]]\n## [1] \"x\" \"y\"\ncolnames(df)\n## [1] \"x\" \"y\"\nrownames(df)\n##  [1] \"1\"  \"2\"  \"3\"  \"4\"  \"5\"  \"6\"  \"7\"  \"8\"  \"9\"  \"10\"\n\ncolnames(df) と names(df) は同一結果になる。\n\n5.4.1 データフレイムの演算\nデータフレイムは内部的にはリストだが、数値・論理値のみで構成されている場合には多くの行列演算をそのまま適用できる。\n\nrbind(df, c(3, \"a\"))\n##                      x y\n## 1     1.61792554756501 a\n## 2     1.69425654447548 b\n## 3    -0.14220117492793 c\n## 4    0.137122371567525 d\n## 5  -0.0766739851210967 e\n## 6    0.325346192304933 f\n## 7   -0.168922917938637 g\n## 8     1.20939431751208 h\n## 9   0.0742907270447723 i\n## 10    -1.2253541717731 j\n## 11                   3 a\n\nこの例では文字列を含めているため、列全体が文字列に変換される点に注意する。 また rbind() では列名が一致している必要があり、行名は自動で連番が振られる（既存の行名と重複すると make.unique() により調整される）。\n\ncbind(df, z = runif(10))\n##              x y          z\n## 1   1.61792555 a 0.35701640\n## 2   1.69425654 b 0.03301447\n## 3  -0.14220117 c 0.78392612\n## 4   0.13712237 d 0.44804446\n## 5  -0.07667399 e 0.68389991\n## 6   0.32534619 f 0.02835733\n## 7  -0.16892292 g 0.41189949\n## 8   1.20939432 h 0.04843612\n## 9   0.07429073 i 0.78371253\n## 10 -1.22535417 j 0.09463352\n\n列方向に結合すると列数が増えるため、追加するベクトルの長さが行数と一致しているか確認しておくと安心である。長さが一致しない場合はリサイクル規則が働くか、条件によっては警告・エラーになる。\n転置をとると行列として出力される。データフレイムに文字列や因子が含まれている場合、すべて文字列に変換される点に注意する。\n\nt(df)\n##   [,1]          [,2]          [,3]          [,4]          [,5]         \n## x \" 1.61792555\" \" 1.69425654\" \"-0.14220117\" \" 0.13712237\" \"-0.07667399\"\n## y \"a\"           \"b\"           \"c\"           \"d\"           \"e\"          \n##   [,6]          [,7]          [,8]          [,9]          [,10]        \n## x \" 0.32534619\" \"-0.16892292\" \" 1.20939432\" \" 0.07429073\" \"-1.22535417\"\n## y \"f\"           \"g\"           \"h\"           \"i\"           \"j\"\n\n構成要素が数値または論理値のみであれば、同じ次元のデータフレイム同士で要素ごとの四則演算が可能となる。ただし、線形代数で使う行列演算を行いたい場合は as.matrix() で行列に変換してから計算する必要がある。\n同様に、列・行ごとの合計や平均も数値・論理値で構成されていれば利用できる。\n\ndff &lt;- data.frame(a = 1:5, b = c(TRUE, TRUE, TRUE, FALSE, FALSE))\ncolSums(dff)\n##  a  b \n## 15  3\nrowSums(dff)\n## [1] 2 3 4 4 5\n\n返り値はベクトルである。全要素の合計を求める場合は sum() を使えばよい。\n\nsum(dff)\n## [1] 18\n\n平均値も同様に計算できる。\n\ncolMeans(dff)\n##   a   b \n## 3.0 0.6\nrowMeans(dff)\n## [1] 1.0 1.5 2.0 2.0 2.5\n\n\n\n5.4.2 データフレイムのアクセス\nデータフレイムに対して 1 つの角括弧でインデックスを指定すると、常にデータフレイムとして戻ってくる。\n\ndf[\"x\"]\n##              x\n## 1   1.61792555\n## 2   1.69425654\n## 3  -0.14220117\n## 4   0.13712237\n## 5  -0.07667399\n## 6   0.32534619\n## 7  -0.16892292\n## 8   1.20939432\n## 9   0.07429073\n## 10 -1.22535417\n\ndf[1] としても同じである。\nベクトルとして取り出したい場合は $ や二重角括弧を使う。\n\ndf$x\n##  [1]  1.61792555  1.69425654 -0.14220117  0.13712237 -0.07667399  0.32534619\n##  [7] -0.16892292  1.20939432  0.07429073 -1.22535417\n\ndf[[\"x\"]]、df[[1]]、df[, \"x\"]、df[, 1] など、さまざまな書き方が選べる。\n変数 x の 5 番目の要素を取り出して別の値 100 を代入するには次のようにする。\n\ndf$x[5] &lt;- 100\n\n同様に df[[\"x\"]][5]、df[[1]][5]、df[5, \"x\"]、df[5, 1] でも操作できる。\nデータフレイム内の変数に関数を適用する例として、平均値を求める場合を示す。\n\nmean(df$x)\n## [1] 10.35219\n\nwith() を使えば、データフレイムを指定したうえで列名だけで参照することもできる。\n\nwith(df, mean(x))\n## [1] 10.35219\n\nなお attach() によってデータフレイムを検索パスに追加する方法もあるが、意図しない変数の上書きにつながるため現在では推奨されない。\n列を削除したい場合は NULL を代入する。\n\ndf$x &lt;- NULL\n\n複雑な条件で行や列を抽出したいときは、subset() や dplyr::filter()／select() といった関数を併用すると記述が読みやすくなる。",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>データ構造</span>"
    ]
  },
  {
    "objectID": "05-datainput.html",
    "href": "05-datainput.html",
    "title": "6  データ入力",
    "section": "",
    "text": "6.1 はじめに\nR においてデータ分析を行うには、まずデータを R に取り込む必要がある。 R や一部のパッケージにはサンプルデータが同梱されているものの、実務では外部ファイルから読み込むケースが主流である。読み込まれたデータは、基本的にデータフレーム (data.frame) として扱われる。\nデータフレームは、同じ長さのベクトルを組み合わせたリストである。たとえば次のように作成できる。\ndf &lt;- data.frame(x = rnorm(10), y = letters[1:10])\nstr(df)\n## 'data.frame':    10 obs. of  2 variables:\n##  $ x: num  -0.186 0.18 -0.287 -1.016 -1.621 ...\n##  $ y: chr  \"a\" \"b\" \"c\" \"d\" ...\nかつての data.frame() は文字列を自動的に因子に変換していた。これを避けるには stringsAsFactors = FALSE を明示する。\ndf &lt;- data.frame(x = rnorm(10), y = letters[1:10], stringsAsFactors= FALSE)\nstr(df)\n## 'data.frame':    10 obs. of  2 variables:\n##  $ x: num  -1.017 0.934 -0.341 2.417 1.558 ...\n##  $ y: chr  \"a\" \"b\" \"c\" \"d\" ...\nあるいは dplyr パッケージの data_frame()（現行では tibble() が推奨）を使えば、オプションなしで文字列を文字列のまま保持できる。\nlibrary(dplyr)\ndf &lt;- data_frame(x = rnorm(10), y = letters[1:10])\nstr(df)\n## tibble [10 × 2] (S3: tbl_df/tbl/data.frame)\n##  $ x: num [1:10] 0.00623 0.33745 0.05577 -0.91672 1.06557 ...\n##  $ y: chr [1:10] \"a\" \"b\" \"c\" \"d\" ...\ntibble() は列名にスペースが含まれていても自動補正せずに扱え、print() 時に一部だけ表示してくれるため大規模データの確認がしやすい。\n以下ではファイル形式ごとに読み込み方法をまとめる。共通して重要なのは、現在のワーキングディレクトリとファイルの所在を正しく把握することだ。\n現在のワーキングディレクトリは以下のコマンドで確認できる.\ngetwd()\nワーキングディレクトリを変更するには setwd() を使う。 プロジェクト内で常に同じ相対パスを使いたい場合は、here パッケージを使ってプロジェクトルートを基準に指定する方法も有効である。\n例えば、現在のワーキングディレクトリが C:/Users/kenji/work/project で、データ data.csv が C:/Users/kenji/work/project/data にあるとする。\ndf &lt;- read.table(\"work/data.csv\", header=TRUE, sep = \",\")\nこのまま読み込むか、先にワーキングディレクトリを目的のフォルダへ変更する必要がある。\nsetwd(\"C:/Users/kenji/work/project/data\")\ndf &lt;- read.table(\"data.csv\", header=TRUE, sep = \",\")\nRStudio ではメニューバーの「File」&gt;「Import Dataset」からウィザード形式でファイルを読み込める。 インポート時に生成されたコードは History ペインから確認できるため、再現性のためにも控えておくとよい。",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>データ入力</span>"
    ]
  },
  {
    "objectID": "05-datainput.html#csv-ファイル",
    "href": "05-datainput.html#csv-ファイル",
    "title": "6  データ入力",
    "section": "6.2 csv ファイル",
    "text": "6.2 csv ファイル\ncsv は comma-separated values の略で、その名の通りカンマ区切りのテキストファイルである。\nvar1, var2, var3\n3, 4,\"text\"\n4, 4, \"text\"\n...\n先頭行に列名が含まれることが多いが、ないケースもあるので事前確認が必要だ。他ソフトで作成したデータを CSV で保存すれば、R から容易に読み込める。\nCSV を読み込む基本的な手段は read.table() を使うこと（スペルに注意）。\n\ndf &lt;- read.table(\"data.csv\", header=TRUE, sep = \",\")\n\nこのコードでオブジェクト df にデータフレームとして読み込まれる。\nread.csv() を使えば、区切り文字やヘッダー有無の指定を省ける。\n\ndf &lt;- read.csv(\"data.csv\")\n\nただし read.csv() は列名に重複があると自動で X を付けて補正する。原データの列名をそのまま使いたい場合は check.names = FALSE を指定する。\n外部ファイルを読み込むと文字列が因子に変換される場合があるので、不要なら stringsAsFactors = FALSE を指定する。\n\ndf &lt;- read.csv(\"data.csv\", stringsAsFactors= FALSE)\n\n書き出すときは次のようにする。\n\nwrite.csv(df,\"data.csv\", row.names = FALSE)\n\nここでは行名が 1 列目に書き込まれないよう、row.names = FALSE を指定している。\n高速で柔軟な readr パッケージを使う方法もある。読み込みは次の通り。\n\nlibrary(readr)\ndf &lt;- read_csv(\"data.csv\")\n\nこちらは既定で文字列を因子化しない。 また read_csv() は列型を自動推定するが、必要に応じて col_types で明示的に指定できる。\n書き込みは次の通り。\n\nwrite_csv(df,\"data.csv\")\n\n特にオプションをつけなくても, rownames は書き込まない.\n日本語が含まれる CSV ファイルは文字コードに注意が必要である。詳細は次節で述べる。",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>データ入力</span>"
    ]
  },
  {
    "objectID": "05-datainput.html#excel-ファイル",
    "href": "05-datainput.html#excel-ファイル",
    "title": "6  データ入力",
    "section": "6.3 EXCEL ファイル",
    "text": "6.3 EXCEL ファイル\nExcel はビジネスで広く使われるスプレッドシートであり、R からもデータを扱える。\n最近の Excel ファイルは拡張子が xlsx で、readxl パッケージを使えば簡単に読み込める。\n\nlibrary(readxl)\ndf &lt;- read_excel(\"data.xlsx\",1)\n\nこの例では data.xlsx の 1 枚目のシートを読み込んでいる。\n直接シート名を指定することができる.\n\nread_excel(\"data.xlsx\",\"Revenues\")\n\nこちらは「Revenues」というシート名を指定している。\nExcel から取り込む場合は、1 行目を列名にし、各列でデータ型を揃えておく。最終行に合計行などがあると数値として取り込まれてしまうので注意。\nExcel ファイルを一度 CSV に変換してから読み込む方法もあるが、いくつか注意点がある。 主な注意点は 2 つある。 1 つ目は、桁区切りのカンマが入ったまま保存すると文字列として扱われること。read.csv() で数値として読み込みたい場合は、事前にカンマを削除して保存する（read_csv() なら自動で数値化されることが多い）。\n2 つ目は、ファイルを CSV に変換すると Shift_JIS で保存される場合がある点である。Linux や macOS（あるいは UTF-8 を標準とする環境）では文字化けするため、read.csv() で読み込む際は\n\ndf &lt;- read.csv(\"data.csv\", stringAsFactors=FALSE, fileEncoding=\"SJIS\")\n\nとし、read_csv() を使う場合は\n\ndf &lt;- read_csv(\"data.csv\", locale=locale(encoding = \"SJIS\"))\n\nと指定する。\n経験上、readxl は日本語を適切に扱ってくれるため、日本語が含まれる場合は無理に CSV に変換せず、Excel ファイルのまま読み込む方が安全である。 複数シートをまとめて読み込みたい場合は excel_sheets() でシート一覧を取得し、map() と組み合わせてループすると効率的である。",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>データ入力</span>"
    ]
  },
  {
    "objectID": "05-datainput.html#stata",
    "href": "05-datainput.html#stata",
    "title": "6  データ入力",
    "section": "6.4 STATA",
    "text": "6.4 STATA\nStata は実証研究で広く使われる統計ソフトで、R でもデータを読み込める。\nStata のデータは拡張子 .dta で、foreign パッケージなどを用いて読み込む。\n\nlibrary(foreign)\ndf &lt;- read.dta(\"data.dta\")\n\nただ, 最新の Stata には対応していない. 最新の Stata に対応するにはライブラリ haven を導入する.\n\nlibrary(haven)\ndf &lt;- read_dta(\"data.dta\")\n\nhaven では write_dta() を使って R のデータを Stata 形式で書き出すこともできる。\n他にも SAS や SPSS などの統計パッケージのデータも取り込むことができる. haven には read_sas() や read_sav() など、各種形式に対応した関数が揃っている。",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>データ入力</span>"
    ]
  },
  {
    "objectID": "05-datainput.html#r-に入っているデータ",
    "href": "05-datainput.html#r-に入っているデータ",
    "title": "6  データ入力",
    "section": "6.5 R に入っているデータ",
    "text": "6.5 R に入っているデータ\nR およびパッケージにはいくつかのデータがはいっている. どのようなデータが利用可能かは以下のコマンドで調べることができる.\n\ndata()\n\nそれがどのような変数が含まれているのかを調べるには, help を使えばよい.\n\nhelp(cars)\n\n\n\n\n\n\n\n\n\n\nパッケージに含まれるデータセットは data() を使ってロードする。\n\nlibrary(AER)\ndata(CPS1985)\nsummary(CPS1985)\n##       wage          education       experience         age       \n##  Min.   : 1.000   Min.   : 2.00   Min.   : 0.00   Min.   :18.00  \n##  1st Qu.: 5.250   1st Qu.:12.00   1st Qu.: 8.00   1st Qu.:28.00  \n##  Median : 7.780   Median :12.00   Median :15.00   Median :35.00  \n##  Mean   : 9.024   Mean   :13.02   Mean   :17.82   Mean   :36.83  \n##  3rd Qu.:11.250   3rd Qu.:15.00   3rd Qu.:26.00   3rd Qu.:44.00  \n##  Max.   :44.500   Max.   :18.00   Max.   :55.00   Max.   :64.00  \n##     ethnicity     region       gender         occupation            sector   \n##  cauc    :440   south:156   male  :289   worker    :156   manufacturing: 99  \n##  hispanic: 27   other:378   female:245   technical :105   construction : 24  \n##  other   : 67                            services  : 83   other        :411  \n##                                          office    : 97                      \n##                                          sales     : 38                      \n##                                          management: 55                      \n##  union     married  \n##  no :438   no :184  \n##  yes: 96   yes:350  \n##                     \n##                     \n##                     \n##",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>データ入力</span>"
    ]
  },
  {
    "objectID": "05-datainput.html#インターネットからデータ入力",
    "href": "05-datainput.html#インターネットからデータ入力",
    "title": "6  データ入力",
    "section": "6.6 インターネットからデータ入力",
    "text": "6.6 インターネットからデータ入力\nWeb スクレイピングや公式 API を利用すれば、インターネット上のデータを直接取得できる。代表的なデータベースと対応パッケージをいくつか挙げておく。\n\nYahoo! Finance (quantmod)\nYahoo! Finance Japan (RFinanceYJ)\nWorld Development Indicators (WDI)\nEurostat (eurostat)\ne-stat (estatap) 金融データの取得には tidyquant、世界銀行の指標には WDI、地理統計には sf パッケージなど、用途に応じたラッパーが多数存在する。\n\nURL を直接指定してファイルを読み込むことも可能である。\n\nlibrary(haven)\nURL &lt;- \"http://fmwww.bc.edu/ec-p/data/wooldridge/attend.dta\"\ndf &lt;-read_dta(URL)\n\nローカルに保存しておきたい場合は download.file() を併用するとよい。\n\nif(!file.exists(\"mroz.dta\")) download.file(URL, \"mroz.dta\",method=\"curl\")\nlibrary(haven)\ndf &lt;- read_dta(\"mroz.dta\")\n\nダウンロードに時間がかかる場合は、destfile を分かりやすいパスに設定し、mode = \"wb\"（バイナリモード）を指定するのが安全である。",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>データ入力</span>"
    ]
  },
  {
    "objectID": "05-datainput.html#その他のデータ入力",
    "href": "05-datainput.html#その他のデータ入力",
    "title": "6  データ入力",
    "section": "6.7 その他のデータ入力",
    "text": "6.7 その他のデータ入力\nR 専用のバイナリファイル（.RData や .rds）として保存していれば、load() や readRDS() で高速に読み込むことができる。\nさらに、DBI・RSQLite・odbc などのパッケージを使えばリレーショナルデータベースに接続してデータを取得できる。環境やニーズに応じて適切なドライバーを選ぶとよい。",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>データ入力</span>"
    ]
  },
  {
    "objectID": "06-datawrangling.html",
    "href": "06-datawrangling.html",
    "title": "7  datawrangling",
    "section": "",
    "text": "8 整然データ\nhttp://r4ds.had.co.nz/tidy-data.html\nデータが整然 (tidy) であるとは次の条件を満たすデータのことである.\nこれをこのようなデータを使って, データを整形する方法, またはそうしたデータにする方法を紹介する.\nここでは以下のライブラリに全面に依存する.\nlibrary(tidyverse)\n特に dplyr と tidyr を用いる.",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>datawrangling</span>"
    ]
  },
  {
    "objectID": "06-datawrangling.html#データ整形",
    "href": "06-datawrangling.html#データ整形",
    "title": "7  datawrangling",
    "section": "8.1 データ整形",
    "text": "8.1 データ整形\nデータセット mtcars を取り扱う. この最初の6つを見るには以下を実施する.\n\nmtcars %&gt;% head()\n##                    mpg cyl disp  hp drat    wt  qsec vs am gear carb\n## Mazda RX4         21.0   6  160 110 3.90 2.620 16.46  0  1    4    4\n## Mazda RX4 Wag     21.0   6  160 110 3.90 2.875 17.02  0  1    4    4\n## Datsun 710        22.8   4  108  93 3.85 2.320 18.61  1  1    4    1\n## Hornet 4 Drive    21.4   6  258 110 3.08 3.215 19.44  1  0    3    1\n## Hornet Sportabout 18.7   8  360 175 3.15 3.440 17.02  0  0    3    2\n## Valiant           18.1   6  225 105 2.76 3.460 20.22  1  0    3    1\n\nここで %&gt;% はパイプ処理といって,\n\nhead(mtcars)\n\nと同じ効果をもたらす. 括弧が重複する場合, こちらのほうがわかりやすい.\nライブラリ dplyr でデータフレイムの処理が簡単になる. select で変数を選択できる.\n\nmtcars %&gt;% select(mpg, disp) %&gt;% head()\n##                    mpg disp\n## Mazda RX4         21.0  160\n## Mazda RX4 Wag     21.0  160\n## Datsun 710        22.8  108\n## Hornet 4 Drive    21.4  258\n## Hornet Sportabout 18.7  360\n## Valiant           18.1  225\n\nfilter により条件に応じた抽出ができる.\n\nmtcars %&gt;% select(mpg, disp) %&gt;% filter(disp &gt; 300) %&gt;% head()\n##                      mpg disp\n## Hornet Sportabout   18.7  360\n## Duster 360          14.3  360\n## Cadillac Fleetwood  10.4  472\n## Lincoln Continental 10.4  460\n## Chrysler Imperial   14.7  440\n## Dodge Challenger    15.5  318\n\nrename により変数名を変更することができる. 日本語でも一応対応している.\n\nmtcars %&gt;% select(mpg, disp) %&gt;% rename(速度 =mpg, 距離 =disp) %&gt;% head()\n##                   速度 距離\n## Mazda RX4         21.0  160\n## Mazda RX4 Wag     21.0  160\n## Datsun 710        22.8  108\n## Hornet 4 Drive    21.4  258\n## Hornet Sportabout 18.7  360\n## Valiant           18.1  225\n\narrange により順序を変更できる.\n\nmtcars %&gt;% select(mpg, disp) %&gt;% arrange(mpg) %&gt;% head()\n##                      mpg disp\n## Cadillac Fleetwood  10.4  472\n## Lincoln Continental 10.4  460\n## Camaro Z28          13.3  350\n## Duster 360          14.3  360\n## Chrysler Imperial   14.7  440\n## Maserati Bora       15.0  301\n\n逆順には以下のようにすればよい.\n\nmtcars %&gt;% select(mpg, disp) %&gt;% arrange(desc(mpg)) %&gt;% head()\n##                 mpg  disp\n## Toyota Corolla 33.9  71.1\n## Fiat 128       32.4  78.7\n## Honda Civic    30.4  75.7\n## Lotus Europa   30.4  95.1\n## Fiat X1-9      27.3  79.0\n## Porsche 914-2  26.0 120.3\n\n新しい変数を作成するには以下のように mutate を用いる.\n\nmtcars %&gt;% select(mpg) %&gt;% mutate(gpm = 1/mpg) %&gt;% head()\n##                    mpg        gpm\n## Mazda RX4         21.0 0.04761905\n## Mazda RX4 Wag     21.0 0.04761905\n## Datsun 710        22.8 0.04385965\n## Hornet 4 Drive    21.4 0.04672897\n## Hornet Sportabout 18.7 0.05347594\n## Valiant           18.1 0.05524862\n\n以下は20より大きいとTRUE, そうでないと FALSE をとる変数を作成している.\n\nmtcars %&gt;% select(mpg) %&gt;% mutate(binarympg = ifelse(mpg&gt;20,TRUE,FALSE)) %&gt;% head()\n##                    mpg binarympg\n## Mazda RX4         21.0      TRUE\n## Mazda RX4 Wag     21.0      TRUE\n## Datsun 710        22.8      TRUE\n## Hornet 4 Drive    21.4      TRUE\n## Hornet Sportabout 18.7     FALSE\n## Valiant           18.1     FALSE\n\nsummarize により変数の基本統計表を作成できる.\n\nmtcars %&gt;% summarize(avg = mean(mpg), sd =sd(mpg))\n##        avg       sd\n## 1 20.09062 6.026948\n\ngroup_by と summarize を組み合わせてグループごとの基本統計量も作成できる.\n\nmtcars %&gt;% group_by(cyl) %&gt;% summarize(n = n(), avg = mean(mpg), sd =sd(mpg))\n## # A tibble: 3 × 4\n##     cyl     n   avg    sd\n##   &lt;dbl&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt;\n## 1     4    11  26.7  4.51\n## 2     6     7  19.7  1.45\n## 3     8    14  15.1  2.56",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>datawrangling</span>"
    ]
  },
  {
    "objectID": "06-datawrangling.html#データ結合",
    "href": "06-datawrangling.html#データ結合",
    "title": "7  datawrangling",
    "section": "8.2 データ結合",
    "text": "8.2 データ結合\ndplyr 2つのデータフレイムを結合する便利なコマンドがある. 列の追加は bind_rows を用いる.\n\ndf1 &lt;- data_frame(X=1:2, Y=1:2)\ndf2 &lt;- data_frame(X=4, Y=4)\nbind_rows(df1,df2)\n## # A tibble: 3 × 2\n##       X     Y\n##   &lt;dbl&gt; &lt;dbl&gt;\n## 1     1     1\n## 2     2     2\n## 3     4     4\n\n行の追加は bind_rows を用いる.\n\ndf3 &lt;- data_frame(Z=5:6)\nbind_cols(df1,df3)\n## # A tibble: 2 × 3\n##       X     Y     Z\n##   &lt;int&gt; &lt;int&gt; &lt;int&gt;\n## 1     1     1     5\n## 2     2     2     6\n\n2つのデータフレイムで共通部分を用いて結合させるには4つのやり方がある.\n\ndfx &lt;- data_frame(id=c(\"A\",\"B\",\"C\"), X=1:3)\ndfy &lt;- data_frame(id=c(\"A\",\"B\",\"D\"), Y=c(TRUE,FALSE,TRUE))\n\n左側の dfx がすべて残るように結合するには, left_join を実行する.\n\nleft_join(dfx,dfy,by=\"id\")\n## # A tibble: 3 × 3\n##   id        X Y    \n##   &lt;chr&gt; &lt;int&gt; &lt;lgl&gt;\n## 1 A         1 TRUE \n## 2 B         2 FALSE\n## 3 C         3 NA\n\n右側の dfx がすべて残るように結合するには, right_join を実行する.\n\nright_join(dfx,dfy,by=\"id\")\n## # A tibble: 3 × 3\n##   id        X Y    \n##   &lt;chr&gt; &lt;int&gt; &lt;lgl&gt;\n## 1 A         1 TRUE \n## 2 B         2 FALSE\n## 3 D        NA TRUE\n\n両方がすべて残るように結合するには, full_join を実行する.\n\nfull_join(dfx,dfy,by=\"id\")\n## # A tibble: 4 × 3\n##   id        X Y    \n##   &lt;chr&gt; &lt;int&gt; &lt;lgl&gt;\n## 1 A         1 TRUE \n## 2 B         2 FALSE\n## 3 C         3 NA   \n## 4 D        NA TRUE\n\n両方にある行のみ残して結合するには, inner_join を実行する.\n\ninner_join(dfx,dfy,by=\"id\")\n## # A tibble: 2 × 3\n##   id        X Y    \n##   &lt;chr&gt; &lt;int&gt; &lt;lgl&gt;\n## 1 A         1 TRUE \n## 2 B         2 FALSE",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>datawrangling</span>"
    ]
  },
  {
    "objectID": "06-datawrangling.html#tidyr",
    "href": "06-datawrangling.html#tidyr",
    "title": "7  datawrangling",
    "section": "8.3 tidyr",
    "text": "8.3 tidyr\n以下のデータセットを考える.\n\ndf &lt;- data_frame(\n  time = 2010:2014,\n  X = rnorm(5, 0, 1),\n  Y = rnorm(5, 0, 2),\n  Z = rnorm(5, 0, 4)\n)\ndf\n## # A tibble: 5 × 4\n##    time       X       Y       Z\n##   &lt;int&gt;   &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;\n## 1  2010  0.0758 -0.368   0.515 \n## 2  2011 -0.661   3.24   -2.12  \n## 3  2012  0.281  -0.667  -1.17  \n## 4  2013 -0.447   3.78    1.18  \n## 5  2014  1.40   -0.0180 -0.0270\n\nそれぞれの変数名をキーとして, 値を示した表は pivot_longer で作れる.\n\ndf_gather &lt;- df %&gt;% pivot_longer(col=-time,names_to='key',values_to = 'value')\ndf_gather\n## # A tibble: 15 × 3\n##     time key     value\n##    &lt;int&gt; &lt;chr&gt;   &lt;dbl&gt;\n##  1  2010 X      0.0758\n##  2  2010 Y     -0.368 \n##  3  2010 Z      0.515 \n##  4  2011 X     -0.661 \n##  5  2011 Y      3.24  \n##  6  2011 Z     -2.12  \n##  7  2012 X      0.281 \n##  8  2012 Y     -0.667 \n##  9  2012 Z     -1.17  \n## 10  2013 X     -0.447 \n## 11  2013 Y      3.78  \n## 12  2013 Z      1.18  \n## 13  2014 X      1.40  \n## 14  2014 Y     -0.0180\n## 15  2014 Z     -0.0270\n\npivot_wider でもとに戻ることができる.\n\ndf_gather %&gt;% pivot_wider(names_from = 'key', values_from = \"value\")\n## # A tibble: 5 × 4\n##    time       X       Y       Z\n##   &lt;int&gt;   &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;\n## 1  2010  0.0758 -0.368   0.515 \n## 2  2011 -0.661   3.24   -2.12  \n## 3  2012  0.281  -0.667  -1.17  \n## 4  2013 -0.447   3.78    1.18  \n## 5  2014  1.40   -0.0180 -0.0270\n\npivot_wider で time にすると別の形で展開できる.\n\ndf_spread &lt;- df_gather %&gt;% pivot_wider(names_from = 'time', values_from = \"value\")\ndf_spread\n## # A tibble: 3 × 6\n##   key    `2010` `2011` `2012` `2013`  `2014`\n##   &lt;chr&gt;   &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;   &lt;dbl&gt;\n## 1 X      0.0758 -0.661  0.281 -0.447  1.40  \n## 2 Y     -0.368   3.24  -0.667  3.78  -0.0180\n## 3 Z      0.515  -2.12  -1.17   1.18  -0.0270\n\n以下のようにすればもとに戻る.\n\ndf_spread %&gt;% pivot_longer(col=-key,names_to='time',values_to = 'value')\n## # A tibble: 15 × 3\n##    key   time    value\n##    &lt;chr&gt; &lt;chr&gt;   &lt;dbl&gt;\n##  1 X     2010   0.0758\n##  2 X     2011  -0.661 \n##  3 X     2012   0.281 \n##  4 X     2013  -0.447 \n##  5 X     2014   1.40  \n##  6 Y     2010  -0.368 \n##  7 Y     2011   3.24  \n##  8 Y     2012  -0.667 \n##  9 Y     2013   3.78  \n## 10 Y     2014  -0.0180\n## 11 Z     2010   0.515 \n## 12 Z     2011  -2.12  \n## 13 Z     2012  -1.17  \n## 14 Z     2013   1.18  \n## 15 Z     2014  -0.0270\n\npivot_longer をうまく使えば変数ごとの基本統計量の表を作ることができる.\n\ncars %&gt;% pivot_longer(everything(),names_to='variable',values_to = 'value') %&gt;% group_by(variable) %&gt;%\n  summarize(nobs = n(), avg = mean(value), sd =sd(value))\n## # A tibble: 2 × 4\n##   variable  nobs   avg    sd\n##   &lt;chr&gt;    &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt;\n## 1 dist        50  43.0 25.8 \n## 2 speed       50  15.4  5.29\n\n日本語だと次のようにすればよい.\n\ntab &lt;- cars %&gt;% rename(距離=dist,速度=speed ) %&gt;%\n  gather(変数,value) %&gt;% group_by(変数) %&gt;%\n  summarize(観測数 = n(), 平均 = mean(value), 標準偏差 =sd(value))\nhead(tab)\n## # A tibble: 2 × 4\n##   変数  観測数  平均 標準偏差\n##   &lt;chr&gt;  &lt;int&gt; &lt;dbl&gt;    &lt;dbl&gt;\n## 1 距離      50  43.0    25.8 \n## 2 速度      50  15.4     5.29",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>datawrangling</span>"
    ]
  },
  {
    "objectID": "06-datawrangling.html#実践例",
    "href": "06-datawrangling.html#実践例",
    "title": "7  datawrangling",
    "section": "8.4 実践例",
    "text": "8.4 実践例\ntidyr を用いた別の例をみてみよう. 横軸を年としたデータセット df がある.\n\ndf &lt;- data_frame(name=letters, \"2010\"=rnorm(26),\"2011\"=rnorm(26),\"2012\"=rnorm(26)) \nhead(df)\n## # A tibble: 6 × 4\n##   name  `2010` `2011` `2012`\n##   &lt;chr&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;\n## 1 a     -1.20  -0.151 -0.295\n## 2 b      1.98  -0.982  1.13 \n## 3 c     -0.849  0.531  1.37 \n## 4 d     -0.564  0.141 -0.236\n## 5 e     -0.326 -1.55  -1.27 \n## 6 f      2.21   0.188 -0.731\n\ndata.frame でないことに注意されたい.\nまた, 年ごとのデータセット df_2010, df_2011, df_2012 が3つある.\n\ndf_2010 &lt;- data_frame(name=letters,runif=runif(26))\ndf_2011 &lt;- data_frame(name=letters,runif=runif(26))\ndf_2012 &lt;- data_frame(name=letters,runif=runif(26))\n\nこれら4つのデータセットを1つにまとめよう.\nまずデータ df についてであるが, pivot_longer をつかう.\n\ndf_rnorm &lt;- df %&gt;% pivot_longer(col=-name,names_to='time',values_to = 'rnorm') %&gt;%\n  mutate(time=as.numeric(time))\nhead(df_rnorm)\n## # A tibble: 6 × 3\n##   name   time  rnorm\n##   &lt;chr&gt; &lt;dbl&gt;  &lt;dbl&gt;\n## 1 a      2010 -1.20 \n## 2 a      2011 -0.151\n## 3 a      2012 -0.295\n## 4 b      2010  1.98 \n## 5 b      2011 -0.982\n## 6 b      2012  1.13\n\n時間の変数を数値に変換している.\nデータセット df_2010, df_2011, df_2012 をつなげる.\n\ndf_runif &lt;- bind_rows(df_2010,df_2011,df_2012) %&gt;% \n  bind_cols(time=rep(2010:2012,each=26)) \nhead(df_runif)\n## # A tibble: 6 × 3\n##   name    runif  time\n##   &lt;chr&gt;   &lt;dbl&gt; &lt;int&gt;\n## 1 a     0.0816   2010\n## 2 b     0.398    2010\n## 3 c     0.0148   2010\n## 4 d     0.00895  2010\n## 5 e     0.807    2010\n## 6 f     0.646    2010\n\nそれぞれの年の変数を付け加えている.\nこれを full_join を用いてつなげる.\n\ndf_full &lt;- full_join(df_rnorm,df_runif,by=c(\"name\",\"time\"))\nhead(df_full)  \n## # A tibble: 6 × 4\n##   name   time  rnorm  runif\n##   &lt;chr&gt; &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;\n## 1 a      2010 -1.20  0.0816\n## 2 a      2011 -0.151 0.0433\n## 3 a      2012 -0.295 0.665 \n## 4 b      2010  1.98  0.398 \n## 5 b      2011 -0.982 0.226 \n## 6 b      2012  1.13  0.634",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>datawrangling</span>"
    ]
  },
  {
    "objectID": "08-regression2.html",
    "href": "08-regression2.html",
    "title": "9  現代的仮定のもとでの最小二乗法",
    "section": "",
    "text": "9.1 正規性の仮定について\n十分な観測値が得られるばあい, \\(u_i\\) が正規分布にしたがっていないくても, 中心極限定理定理より, 最小二乗法推定量は正規分布に近似できる.\nここの係数ゼロのティー検定について, ライブラリ AER を導入して coeftest を用いればよい. まず lm コマンドを用いて2つのモデルを推定する. fm1 は説明変数 x とダミー変数 w およびそれらの交差項を含むモデル, fm0 は x のみを含むモデルである.\nfm1 &lt;- lm(y~x*w,data=df)\nfm0 &lt;- lm(y~x,data=df)\ncoeftest(fm1,df=Inf)\n## \n## z test of coefficients:\n## \n##             Estimate Std. Error z value  Pr(&gt;|z|)    \n## (Intercept) 11.02661    0.36450 30.2516 &lt; 2.2e-16 ***\n## x            1.95216    0.57795  3.3777 0.0007309 ***\n## wT          -0.96739    0.46740 -2.0697 0.0384767 *  \n## x:wT         0.11278    0.76777  0.1469 0.8832179    \n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\ncoeftest コマンドは係数の検定を実行する関数である. オプション df=Inf を指定すると, ティー分布の代わりに標準正規分布（自由度無限大のティー分布）を用いた検定を実行する. これは大標本のもとでの漸近的な検定である. ただ十分なデータのもとではティー値のままでもよい.\n同様に複数制約の場合, エフ検定統計量に制約の数を乗じた統計量が 自由度が制約数のカイ二乗分布にしたがうことが知られている. これをR で実施するには waldtest を用いればよい. waldtest コマンドは制約のあるモデル（fm0）と制約のないモデル（fm1）を比較して, 複数の係数がゼロかどうかを検定する関数である.\nwaldtest(fm0,fm1,test=\"Chisq\")\n## Wald test\n## \n## Model 1: y ~ x\n## Model 2: y ~ x * w\n##   Res.Df Df  Chisq Pr(&gt;Chisq)    \n## 1     98                         \n## 2     96  2 18.643  8.947e-05 ***\n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\nオプション test=\"Chisq\" を指定すると, エフ検定統計量に制約の数を乗じた統計量が自由度が制約数のカイ二乗分布にしたがうことを利用した検定を実行する. これは大標本での漸近的な検定である.\nエフ検定も十分なデータのもとではそのままでよいであろう.\nオプション test を付けなければエフ検定を実施する.\nwaldtest(fm0,fm1)\n## Wald test\n## \n## Model 1: y ~ x\n## Model 2: y ~ x * w\n##   Res.Df Df      F    Pr(&gt;F)    \n## 1     98                        \n## 2     96  2 9.3216 0.0001997 ***\n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\nこの結果はエフ統計量とそのP値を表示している.\nこれは anova コマンドと同じである.\nanova(fm0,fm1)\n## Analysis of Variance Table\n## \n## Model 1: y ~ x\n## Model 2: y ~ x * w\n##   Res.Df    RSS Df Sum of Sq      F    Pr(&gt;F)    \n## 1     98 124.04                                  \n## 2     96 103.87  2    20.171 9.3216 0.0001997 ***\n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\nanova コマンドも2つのモデルを比較してエフ検定を実行する.\n複数制約の検定としてLM検定というのもある. 制約付きの回帰分析を実行し, その残差を制約なしのモデルの説明変数に回帰する. その決定係数に観測数を掛けた統計量が自由どが制約の数のカイ二乗分布にしたがうことが知られている.\n以下ではLM検定統計量を手動で計算している.\nlmt &lt;- lm(I(resid(fm1))~w*x,data=df)\n(lmt &lt;- nrow(df)*summary(lmt)$r.squared)\n## [1] 2.62098e-29\n1-pchisq(lmt,df=1)\n## [1] 1\n最初の行では, fm1 の残差（resid(fm1)）を被説明変数とし, w*x を説明変数として回帰分析を実行している. 2行目では, その決定係数（summary(lmt)$r.squared）に観測数（nrow(df)）を掛けてLM検定統計量を計算している. 3行目では, pchisq コマンドを用いて自由度1のカイ二乗分布のもとでP値を計算している.",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>現代的仮定のもとでの最小二乗法</span>"
    ]
  },
  {
    "objectID": "08-regression2.html#誤差項と説明変数が独立の仮定について",
    "href": "08-regression2.html#誤差項と説明変数が独立の仮定について",
    "title": "9  現代的仮定のもとでの最小二乗法",
    "section": "9.2 誤差項と説明変数が独立の仮定について",
    "text": "9.2 誤差項と説明変数が独立の仮定について\nまた \\(u_i\\) と \\(x_i\\) は独立でなく, \\(u_i\\) と \\(x_i\\) が無相関という弱い条件のもとでも, 一致推定量であることが知られている. ただ不偏推定量は保証できない. また 線形推定量のなかで最小の分散とも言えない.1 また独立のときの標準誤差の推定量が一致推定量でない.\nただし, 別の分散のもとで正規分布に近似できることがしられている.2 つまり, 説明変数と誤差項が無相関であるが, 独立とまでは言い切れない場合, 最小二乗推定量を実行した際, 別の方法で分散を推定する必要がある. この別の分散をロバスト分散という.\nR でロバスト分散を推定するにはパッケージ AER を導入するのが簡単である. 次のコマンド coeftest を実行すればよい.\n\ncoeftest(fm1,vcov=vcovHC)\n## \n## t test of coefficients:\n## \n##             Estimate Std. Error t value  Pr(&gt;|t|)    \n## (Intercept) 11.02661    0.30141 36.5832 &lt; 2.2e-16 ***\n## x            1.95216    0.51841  3.7657 0.0002863 ***\n## wT          -0.96739    0.41008 -2.3590 0.0203483 *  \n## x:wT         0.11278    0.71108  0.1586 0.8743144    \n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\ncoeftest コマンドのオプション vcov=vcovHC を指定することで, 不均一分散に頑健な（heteroskedasticity-consistent）標準誤差を用いた検定が実行される. vcovHC は分散共分散行列をロバスト推定する関数である.\n先の値と標準誤差が違っていることが確認できるであろう. ただこの値は STATA と少し異なっている. STATA と同じにするには\n\ncoeftest(fm1,vcov=vcovHC(fm1,type=\"HC1\"))\n## \n## t test of coefficients:\n## \n##             Estimate Std. Error t value  Pr(&gt;|t|)    \n## (Intercept) 11.02661    0.29272 37.6700 &lt; 2.2e-16 ***\n## x            1.95216    0.50357  3.8766 0.0001938 ***\n## wT          -0.96739    0.39881 -2.4257 0.0171466 *  \n## x:wT         0.11278    0.68888  0.1637 0.8703000    \n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nとしなければならない. オプション type=\"HC1\" は小標本補正を施したロバスト分散推定量を指定している. これはSTATAのデフォルト設定と同じである.\nまたティー分布でなく正規分布とすることもできる.\n\ncoeftest(fm0,vcov=vcovHC,df=Inf)\n## \n## z test of coefficients:\n## \n##             Estimate Std. Error z value  Pr(&gt;|z|)    \n## (Intercept) 10.40949    0.22906 45.4448 &lt; 2.2e-16 ***\n## x            2.23572    0.39423  5.6711 1.419e-08 ***\n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nオプション df=Inf を追加することで, 標準正規分布を用いた検定を実行する.\n複数の係数についての検定は waldtest を実行すればよい.\n\nwaldtest(fm0,fm1,vcov=vcovHC)\n## Wald test\n## \n## Model 1: y ~ x\n## Model 2: y ~ x * w\n##   Res.Df Df      F    Pr(&gt;F)    \n## 1     98                        \n## 2     96  2 9.5582 0.0001638 ***\n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nオプション vcov=vcovHC を指定することで, ロバスト分散を用いたワルド検定を実行する.\n先の結果はエフ検定であるが, カイ二乗検定を実施するには以下を実施すればよい.\n\nwaldtest(fm0,fm1,vcov=vcovHC, test=\"Chisq\")\n## Wald test\n## \n## Model 1: y ~ x\n## Model 2: y ~ x * w\n##   Res.Df Df  Chisq Pr(&gt;Chisq)    \n## 1     98                         \n## 2     96  2 19.116  7.062e-05 ***\n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nオプション test=\"Chisq\" を追加することで, エフ統計量の代わりにカイ二乗統計量を用いた検定を実行する.\n最近開発されたパッケージ estimatrのコマンド　lm_robust　を用いるとロバスト分散のもとの推定値が簡単に計算できる.\n\nfm2&lt;- lm_robust(y~x*w,data=df)\nsummary(fm2)\n## \n## Call:\n## lm_robust(formula = y ~ x * w, data = df)\n## \n## Standard error type:  HC2 \n## \n## Coefficients:\n##             Estimate Std. Error t value  Pr(&gt;|t|) CI Lower CI Upper DF\n## (Intercept)  11.0266     0.2940 37.5072 3.816e-59  10.4430  11.6102 96\n## x             1.9522     0.5057  3.8602 2.054e-04   0.9483   2.9560 96\n## wT           -0.9674     0.4003 -2.4169 1.754e-02  -1.7619  -0.1729 96\n## x:wT          0.1128     0.6927  0.1628 8.710e-01  -1.2623   1.4878 96\n## \n## Multiple R-squared:  0.3592 ,    Adjusted R-squared:  0.3391 \n## F-statistic:  18.5 on 3 and 96 DF,  p-value: 1.5e-09\n\nlm_robust コマンドは回帰分析を実行し, デフォルトでロバスト標準誤差を計算する. これにより lm と coeftest を別々に実行する手間が省ける.\nオプション　se_type = \"stata\" を用いればSTATAと同じ計算が可能である.\nまた以下のオプションをつければ分散均一の場合も計算できる.\n\nfm3&lt;- lm_robust(y~x*w,data=df,se_type = \"classical\")\nsummary(fm3)\n## \n## Call:\n## lm_robust(formula = y ~ x * w, data = df, se_type = \"classical\")\n## \n## Standard error type:  classical \n## \n## Coefficients:\n##             Estimate Std. Error t value  Pr(&gt;|t|) CI Lower CI Upper DF\n## (Intercept)  11.0266     0.3645 30.2516 7.056e-51  10.3031 11.75013 96\n## x             1.9522     0.5779  3.3777 1.057e-03   0.8049  3.09938 96\n## wT           -0.9674     0.4674 -2.0697 4.116e-02  -1.8952 -0.03961 96\n## x:wT          0.1128     0.7678  0.1469 8.835e-01  -1.4112  1.63680 96\n## \n## Multiple R-squared:  0.3592 ,    Adjusted R-squared:  0.3391 \n## F-statistic: 17.93 on 3 and 96 DF,  p-value: 2.545e-09\n\nオプション se_type = \"classical\" を指定すると, 通常の（ロバストでない）標準誤差を計算する. これは lm コマンドの結果と同じである.",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>現代的仮定のもとでの最小二乗法</span>"
    ]
  },
  {
    "objectID": "08-regression2.html#分散均一の検定",
    "href": "08-regression2.html#分散均一の検定",
    "title": "9  現代的仮定のもとでの最小二乗法",
    "section": "9.3 分散均一の検定",
    "text": "9.3 分散均一の検定\n誤差項が説明変数と独立のときと無相関のときでは標準誤差の推定量が異なる. 正確にいうと, 条件付き分散が説明変数に依存するかどうかによって標準誤差の推定量が異なる. このことは分散均一と呼ばれている.\n誤差項の分散が均一かどうかは検定可能である. 有名な検定方法としてBP (Breusch-Pagan) 検定というものがある. BP検定は帰無仮説が分散均一で, 対立仮説が分散が説明変数と線形関係になっている場合の検定である.\n残差の自乗を被説明変数として回帰分析をおこない, その決定係数に観測数をかけたものが検定統計量となる. 以下ではBP検定統計量を手動で計算している.\n\nbpt &lt;- lm(I(resid(fm1)^2)~w*x,data=df)\n(bpt &lt;-nrow(df)*summary(bpt)$r.squared)\n## [1] 1.521527\n1-pchisq(bpt,df=3)\n## [1] 0.6773109\n\n最初の行では, fm1 の残差の二乗（resid(fm1)^2）を被説明変数とし, w*x を説明変数として回帰分析を実行している. I() 関数は, 数式内で算術演算を実行するために用いる. 2行目では, その決定係数に観測数を掛けてBP検定統計量を計算している. 3行目では, 自由度3（説明変数の数）のカイ二乗分布のもとでP値を計算している.\nここでの例ではP値が5%を超えているので帰無仮説を棄却できないので, 分散均一を仮定してよいことが示唆されている.\nR では bptest コマンドを用いて簡単にBP検定を実施できる.\n\nbptest(fm1)\n## \n##  studentized Breusch-Pagan test\n## \n## data:  fm1\n## BP = 1.5215, df = 3, p-value = 0.6773\n\nbptest コマンドは自動的にBP検定統計量とP値を計算してくれる.\nこれまでのBPテストは誤差項の分散が説明変数の線形関係あることを暗黙に仮定している. 非線形性を考慮するために説明変数の二次項を導入した分散不均一性の検定をホワイト検定という. 説明変数が複数ある場合ホワイト検定は煩雑になるため, 被説明変数の予測値を使って計算することがある. そのときホワイトテストは以下で実施する.\n\nwht &lt;- lm(I(resid(fm1)^2)~fitted(fm1)+I(fitted(fm1)^2),data=df)\n(wht &lt;- nrow(df)*summary(wht)$r.squared)\n## [1] 0.6128075\n1-pchisq(wht,df=2)\n## [1] 0.7360894\n\n最初の行では, 残差の二乗を被説明変数とし, 予測値（fitted(fm1)）とその二乗を説明変数として回帰分析を実行している. これにより分散の非線形性を検出できる. 2行目では, その決定係数に観測数を掛けてホワイト検定統計量を計算している. 3行目では, 自由度2のカイ二乗分布のもとでP値を計算している.\nホワイト検定でも分散均一が示唆されている.\nもしくは bptest コマンドに予測値とその二乗を指定して実行することもできる.\n\nbptest(fm1,~fitted(fm1)+I(fitted(fm1)^2))\n## \n##  studentized Breusch-Pagan test\n## \n## data:  fm1\n## BP = 0.61281, df = 2, p-value = 0.7361\n\nこのコマンドは上記の手動計算と同じ結果を返す.\nこのように分散均一性は検定することが可能であるが, そもそも分散均一が疑われる場合は, ロバスト分散で推定するので十分であるため最近の実証分析ではこの検定は実施されない.",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>現代的仮定のもとでの最小二乗法</span>"
    ]
  },
  {
    "objectID": "08-regression2.html#footnotes",
    "href": "08-regression2.html#footnotes",
    "title": "9  現代的仮定のもとでの最小二乗法",
    "section": "",
    "text": "正確にいえば, 不偏推定量のとめには条件付き期待値が説明変数に依存しないことが必要である. また線形推定量のなかで最小の分散になるためには 条件付き分散が説明変数に依存しないことが必要である.↩︎\n正確には観測される変数に4次のモーメントが存在するという仮定が必要となる. この仮定の直感的な意味は異常値が存在しないことである.↩︎",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>現代的仮定のもとでの最小二乗法</span>"
    ]
  },
  {
    "objectID": "07-regression1.html",
    "href": "07-regression1.html",
    "title": "8  古典的仮定のもとでの最小二乗法",
    "section": "",
    "text": "8.1 単回帰モデル\n次の単回帰モデルを考える.\n\\[\ny = \\alpha + \\beta x + u\n\\] ここで \\(x\\) は説明変数で, \\(y\\) は被説明変数である. \\(u\\) は誤差項である. パラメータとして \\(\\alpha\\) は切片パラメータ, \\(\\beta\\) は傾きパラメータである.\n次の仮定を置いている.\nこのとき最小二乗推定量は一致で, 不偏であり, 正規分布にしたがう. 一致とは推定量が観測値を増やすことによって真のパラメータに (確率) 収束することある. 不偏とは推定量の期待値が真のパラメータになることである. また他の線形不偏推定量のなかで最も分散が小さいことも知られている.\n仮想的に以下のモデルを考える. ここでは標本サイズを100とし, 説明変数 \\(x\\) は0から1の一様分布から生成する. 被説明変数 \\(y\\) は真の切片パラメータを10, 真の傾きパラメータを2として, 正規分布の誤差項を加えて生成する. 最後にこれらのデータを data.frame 関数でデータフレームにまとめる.\nN &lt;- 100\nx &lt;- runif(N)\ny &lt;- 10 + 2*x + rnorm(N)\ndf &lt;- data.frame(x,y)\n散布図を作図すると以下である. plot 関数で y~x という形式で指定すると, x軸に説明変数, y軸に被説明変数をとった散布図が描かれる.\nplot(y~x)\nR で回帰分析を実施するには lm 関数を使用する. 第一引数には回帰式を y ~ x という形式で指定し, data 引数にはデータフレームを指定する. 推定結果は fm というオブジェクトに保存する.\nfm &lt;- lm(y ~ x, data=df)\nfm 自体はリストであり, 以下の要素がある. typeof 関数でオブジェクトの型を確認でき, names 関数でリストの要素名を確認できる.\ntypeof(fm)\n## [1] \"list\"\nnames(fm)\n##  [1] \"coefficients\"  \"residuals\"     \"effects\"       \"rank\"         \n##  [5] \"fitted.values\" \"assign\"        \"qr\"            \"df.residual\"  \n##  [9] \"xlevels\"       \"call\"          \"terms\"         \"model\"\n推定された係数 (切片と傾き) を取り出すには coef 関数を使用する. coefficients 関数でも同じ結果が得られる (コメントアウトしている).\ncoef(fm)\n## (Intercept)           x \n##    10.06380     1.87096\n# coefficients(fm)\n傾きの推定値は共分散を分散で割った値として計算できる. with 関数を使ってデータフレーム内の変数を直接参照し, cov 関数で共分散, var 関数で分散を計算する.\nwith(df, cov(x,y)/var(x))\n## [1] 1.87096\n散布図に推定された回帰直線を重ねて描くには, plot 関数で散布図を描いた後, abline 関数で回帰直線を追加する. abline 関数に lm オブジェクトを渡すと自動的に回帰直線が描画される.\nplot(y~x,data=df)\nabline(fm)\n残差 (実際の値と予測値の差) を取り出すには resid 関数を使用する. ここでは head 関数で最初の6つの値のみを表示している. residuals 関数でも同じ結果が得られる (コメントアウトしている).\nhead(resid(fm))\n##          1          2          3          4          5          6 \n## -0.4983544 -0.1189251  0.8013264 -1.2750641 -1.4901049  0.7380966\n# residuals(fm)\n# with(fm, residuals)\n予測値 (回帰式から計算された \\(\\hat{y}\\) の値) を取り出すには fitted 関数を使用する. ここでは head 関数で最初の6つの値のみを表示している. fitted.values でも同じ結果が得られる (コメントアウトしている).\nhead(fitted(fm))\n##        1        2        3        4        5        6 \n## 11.16643 11.45346 11.40651 10.48278 11.05165 11.72699\n# fitted.values(fm)\n# with(fm, fitted.values)\n最小二乗法の性質として, 予測値の平均は被説明変数の平均と等しいことが知られている. 以下のコマンドで両者が一致することを確認できる.\nmean(fitted(fm))\n## [1] 10.97767\nmean(df$y)\n## [1] 10.97767\n残差自乗和 (residual sum of squares) を計算するには deviance 関数を使用する. これは残差を二乗して合計した値であり, sum(resid(fm)^2) で直接計算することもできる.\ndeviance(fm)\n## [1] 120.6358\nsum(resid(fm)^2)\n## [1] 120.6358\n残差自乗和は残差変動とも呼ばれる． 予測値の偏差の自乗和を回帰変動といい, 被説明変数の偏差の自乗和を全変動という. 全変動は回帰変動と残差変動に分解できる (変動の分解). 以下のコマンドで, 左辺の全変動が右辺の回帰変動と残差変動の和に等しいことを確認できる.\nsum((df$y-mean(df$y))^2)\n## [1] 152.9797\nsum((fitted(fm)-mean(df$y))^2)+deviance(fm)\n## [1] 152.9797",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>古典的仮定のもとでの最小二乗法</span>"
    ]
  },
  {
    "objectID": "07-regression1.html#単回帰モデル",
    "href": "07-regression1.html#単回帰モデル",
    "title": "8  古典的仮定のもとでの最小二乗法",
    "section": "",
    "text": "\\((x_i,y_i)\\) は独立同一分布にしたがう.\n\\(E[u_i]=0\\) である.\n\\(u_i\\) と \\(x_i\\) は独立である.\n\\(u_i\\) は正規分布にしたがう.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n8.1.1 ティー検定\n回帰分析の詳細な結果を見るには summary 関数を使用する. これにより係数の推定値, 標準誤差, t値, p値などが表示される.\n\nsummary(fm)\n## \n## Call:\n## lm(formula = y ~ x, data = df)\n## \n## Residuals:\n##     Min      1Q  Median      3Q     Max \n## -2.4709 -0.5052  0.0822  0.7203  3.2953 \n## \n## Coefficients:\n##             Estimate Std. Error t value Pr(&gt;|t|)    \n## (Intercept)   10.064      0.210  47.926  &lt; 2e-16 ***\n## x              1.871      0.365   5.126 1.49e-06 ***\n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n## \n## Residual standard error: 1.109 on 98 degrees of freedom\n## Multiple R-squared:  0.2114, Adjusted R-squared:  0.2034 \n## F-statistic: 26.28 on 1 and 98 DF,  p-value: 1.489e-06\n\nこの出力には以下の情報が含まれている:\n\nCoefficients: 各変数の係数の推定値, 標準誤差, t値, p値 (係数がゼロであるというティー検定の結果)\nResidual standard error: 残差標準誤差\nMultiple R-squared: 決定係数 (モデルの当てはまりの良さ)\nAdjusted R-squared: 修正済み決定係数 (説明変数の数を考慮した決定係数)\nF-statistic: 全ての係数がゼロであるというエフ検定の結果\n\nsummary(fm) もリストであり, typeof 関数と names 関数でその構造を確認できる.\n\ntypeof(summary(fm))\n## [1] \"list\"\nnames(summary(fm))\n##  [1] \"call\"          \"terms\"         \"residuals\"     \"coefficients\" \n##  [5] \"aliased\"       \"sigma\"         \"df\"            \"r.squared\"    \n##  [9] \"adj.r.squared\" \"fstatistic\"    \"cov.unscaled\"\n\n単なる fm と同じ名前の要素もあるが, 中身が違っている場合がある. 例えば residuals は同じであるが, 係数には標準誤差やt値などの情報が加わっている. coef 関数を summary(fm) に適用すると, これらの情報を含む行列が得られる.\n\ncoef(summary(fm))\n##             Estimate Std. Error   t value     Pr(&gt;|t|)\n## (Intercept) 10.06380  0.2099880 47.925613 7.932672e-70\n## x            1.87096  0.3649999  5.125918 1.489267e-06\n# coefficients(summary(fm))\n\n残差の標準誤差 (residual standard error) は summary(fm) の sigma 要素から得られる. これは残差自乗和を残差の自由度で割った値の平方根である.\n\nwith(summary(fm),sigma)\n## [1] 1.109494\nsqrt(deviance(fm)/df.residual(fm))\n## [1] 1.109494\n\n決定係数 (R-squared) は summary(fm) の r.squared 要素から得られる. これは 1 から (残差変動/全変動) を引いた値として計算される.\n\nwith(summary(fm),r.squared)\n## [1] 0.2114265\n1-deviance(fm)/with(df, sum((y-mean(y))^2))\n## [1] 0.2114265\n\n調整済み決定係数 (adjusted R-squared) は summary(fm) の adj.r.squared 要素から得られる. これは決定係数を自由度で調整した値であり, 説明変数の数が増えても必ずしも増加しない性質を持つ.\n\nwith(summary(fm),adj.r.squared)\n## [1] 0.2033799\n1-(deviance(fm)/df.residual(fm))/with(df, sum((y-mean(y))^2/(nrow(df)-1)))\n## [1] 0.2033799\n\n\n\n8.1.2 対数変換\n次のモデルを考える. \\[\ny = \\alpha + \\beta \\log(x) + u\n\\]\n説明変数を対数変換する場合, lm 関数の式の中で直接 log 関数を使用できる. この場合, 係数 \\(\\beta\\) は \\(x\\) が1%変化したときの \\(y\\) の変化量 (の近似値) を表す.\n\nfm &lt;- lm(y~log(x),data=df)\nsummary(fm)\n## \n## Call:\n## lm(formula = y ~ log(x), data = df)\n## \n## Residuals:\n##     Min      1Q  Median      3Q     Max \n## -2.5820 -0.6395  0.0782  0.7341  3.4800 \n## \n## Coefficients:\n##             Estimate Std. Error t value Pr(&gt;|t|)    \n## (Intercept)  11.4778     0.1642  69.918  &lt; 2e-16 ***\n## log(x)        0.4628     0.1086   4.261 4.68e-05 ***\n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n## \n## Residual standard error: 1.148 on 98 degrees of freedom\n## Multiple R-squared:  0.1563, Adjusted R-squared:  0.1477 \n## F-statistic: 18.16 on 1 and 98 DF,  p-value: 4.681e-05\n\n散布図と回帰直線を描くと以下のようになる. 横軸が対数変換された \\(x\\) になっている点に注意.\n\nplot(y~log(x),data=df)\nabline(fm)\n\n\n\n\n\n\n\n\n被説明変数を対数変換する場合も同様に, lm 関数の式の中で log 関数を使用する. この場合, 係数 \\(\\beta\\) は \\(x\\) が1単位変化したときの \\(y\\) の変化率 (%) の近似値を表す.\n\nfm &lt;- lm(log(y)~x,data=df)\nsummary(fm)\n## \n## Call:\n## lm(formula = log(y) ~ x, data = df)\n## \n## Residuals:\n##      Min       1Q   Median       3Q      Max \n## -0.23741 -0.03986  0.01309  0.06591  0.25686 \n## \n## Coefficients:\n##             Estimate Std. Error t value Pr(&gt;|t|)    \n## (Intercept)  2.30783    0.01934 119.344  &lt; 2e-16 ***\n## x            0.16718    0.03361   4.974  2.8e-06 ***\n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n## \n## Residual standard error: 0.1022 on 98 degrees of freedom\n## Multiple R-squared:  0.2015, Adjusted R-squared:  0.1934 \n## F-statistic: 24.74 on 1 and 98 DF,  p-value: 2.802e-06\n\n散布図と回帰直線を描くと以下のようになる. 縦軸が対数変換された \\(y\\) になっている点に注意.\n\nplot(log(y)~x,data=df)\nabline(fm)\n\n\n\n\n\n\n\n\n被説明変数と説明変数の両方を対数変換する場合 (対数線形モデル) は以下のようにする. この場合, 係数 \\(\\beta\\) は弾力性を表し, \\(x\\) が1%変化したときの \\(y\\) の変化率 (%) を表す.\n\nfm &lt;- lm(log(y)~log(x),data=df)\nsummary(fm)\n## \n## Call:\n## lm(formula = log(y) ~ log(x), data = df)\n## \n## Residuals:\n##       Min        1Q    Median        3Q       Max \n## -0.261464 -0.054253  0.009099  0.070891  0.273537 \n## \n## Coefficients:\n##             Estimate Std. Error t value Pr(&gt;|t|)    \n## (Intercept) 2.433966   0.015101 161.174  &lt; 2e-16 ***\n## log(x)      0.041149   0.009991   4.119 7.96e-05 ***\n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n## \n## Residual standard error: 0.1056 on 98 degrees of freedom\n## Multiple R-squared:  0.1476, Adjusted R-squared:  0.1389 \n## F-statistic: 16.96 on 1 and 98 DF,  p-value: 7.964e-05\n\n散布図と回帰直線を描くと以下のようになる. 両軸とも対数変換されている点に注意.\n\nplot(log(y)~log(x),data=df)\nabline(fm)\n\n\n\n\n\n\n\n\n\n\n8.1.3 切片なし回帰モデル\n次のモデルを考える. \\[\ny = \\beta x + u\n\\]\n切片を含まないモデルを推定したい場合は, 式の中に -1 を加える. これにより切片項が除外され, 原点を通る回帰直線が推定される.\n\nfm &lt;- lm(y~x-1,data=df)\nsummary(fm)\n## \n## Call:\n## lm(formula = y ~ x - 1, data = df)\n## \n## Residuals:\n##    Min     1Q Median     3Q    Max \n## -6.018 -1.509  3.018  7.000 10.484 \n## \n## Coefficients:\n##   Estimate Std. Error t value Pr(&gt;|t|)    \n## x  16.7227     0.9485   17.63   &lt;2e-16 ***\n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n## \n## Residual standard error: 5.457 on 99 degrees of freedom\n## Multiple R-squared:  0.7584, Adjusted R-squared:  0.756 \n## F-statistic: 310.8 on 1 and 99 DF,  p-value: &lt; 2.2e-16\n\nもしくは +0 を加えることでも同じ結果が得られる.\n\nfm &lt;- lm(y~x+0,data=df)\nsummary(fm)\n## \n## Call:\n## lm(formula = y ~ x + 0, data = df)\n## \n## Residuals:\n##    Min     1Q Median     3Q    Max \n## -6.018 -1.509  3.018  7.000 10.484 \n## \n## Coefficients:\n##   Estimate Std. Error t value Pr(&gt;|t|)    \n## x  16.7227     0.9485   17.63   &lt;2e-16 ***\n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n## \n## Residual standard error: 5.457 on 99 degrees of freedom\n## Multiple R-squared:  0.7584, Adjusted R-squared:  0.756 \n## F-statistic: 310.8 on 1 and 99 DF,  p-value: &lt; 2.2e-16",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>古典的仮定のもとでの最小二乗法</span>"
    ]
  },
  {
    "objectID": "07-regression1.html#重回帰モデル",
    "href": "07-regression1.html#重回帰モデル",
    "title": "8  古典的仮定のもとでの最小二乗法",
    "section": "8.2 重回帰モデル",
    "text": "8.2 重回帰モデル\n説明変数として \\(w\\) を加えたモデルを考える. \\[\ny = \\alpha + \\beta x +\\gamma w+ u\n\\]\n暗黙に次の仮定を置いている.\n\n\\((w_i, x_i,y_i)\\) は独立同一分布にしたがう.\n誤差項の期待値はゼロである. \\(E[u_i]=0\\) である.\n誤差項 \\(u_i\\) は説明変数 \\((x_i, w_i)\\) に対して独立である.\n誤差項 \\(u_i\\) は正規分布にしたがう.\n説明変数間に多重共線性は存在しない. つまり \\(x_i\\) は \\(w_i\\) の一次変換で表せない.\n\n仮想的に以下のモデルを考える. 標本サイズを100とし, 説明変数 \\(x\\) は0から1の一様分布から, \\(w\\) は「H」と「T」からランダムに生成する. 被説明変数 \\(y\\) は, 真の切片を10, \\(x\\) の係数を2, \\(w\\) が「H」のときに1を加算し, 正規分布の誤差項を加えて生成する.\n\nN &lt;- 100\nx&lt;-runif(N)\nw&lt;-sample(c(\"H\",\"T\"),N,replace=TRUE)\ny &lt;- 10 + 2*x + ifelse(w==\"H\",1,0) + rnorm(N)\ndf &lt;- data.frame(w,x,y)\n\n複数の説明変数を含むモデルを推定するには, + 記号で変数を連結する. 式 y~x+w は被説明変数 \\(y\\) を説明変数 \\(x\\) と \\(w\\) で回帰することを意味する.\n\nfm &lt;- lm(y~x+w,data=df)\nsummary(fm)\n## \n## Call:\n## lm(formula = y ~ x + w, data = df)\n## \n## Residuals:\n##      Min       1Q   Median       3Q      Max \n## -3.10009 -0.54866 -0.00186  0.48371  1.97915 \n## \n## Coefficients:\n##             Estimate Std. Error t value Pr(&gt;|t|)    \n## (Intercept)  11.2561     0.2373  47.437  &lt; 2e-16 ***\n## x             1.7808     0.3286   5.419 4.37e-07 ***\n## wT           -1.2397     0.1911  -6.487 3.70e-09 ***\n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n## \n## Residual standard error: 0.9452 on 97 degrees of freedom\n## Multiple R-squared:  0.4522, Adjusted R-squared:  0.4409 \n## F-statistic: 40.03 on 2 and 97 DF,  p-value: 2.113e-13\n\nR の特徴として, 因子型 (factor) やカテゴリカル変数 (文字列) を特に変換することなく自動的にダミー変数として扱える. ここでは \\(w\\) が「H」と「T」の2値をとるが, 自動的に一方 (「H」) のダミー変数が作成され, 「T」が基準カテゴリとなる.\n\n8.2.1 自乗項\n説明変数として自乗項を加えたモデルを考える. \\[\ny = \\alpha + \\beta x + \\gamma x^2 + u\n\\]\nR で自乗項を式に含める場合, I() 関数で囲んで I(x^2) と記述する必要がある. これは ^ が R の式の中で特別な意味を持つため, 通常の算術演算として解釈させるための処理である.\n\nfm &lt;- lm(y~x+I(x^2),data=df)\nsummary(fm)\n## \n## Call:\n## lm(formula = y ~ x + I(x^2), data = df)\n## \n## Residuals:\n##     Min      1Q  Median      3Q     Max \n## -2.3353 -0.7086  0.1491  0.7081  2.7208 \n## \n## Coefficients:\n##             Estimate Std. Error t value Pr(&gt;|t|)    \n## (Intercept)  10.6464     0.3674  28.978   &lt;2e-16 ***\n## x             0.9231     1.5669   0.589    0.557    \n## I(x^2)        1.0373     1.4440   0.718    0.474    \n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n## \n## Residual standard error: 1.129 on 97 degrees of freedom\n## Multiple R-squared:  0.2187, Adjusted R-squared:  0.2026 \n## F-statistic: 13.57 on 2 and 97 DF,  p-value: 6.345e-06\n\n\n\n8.2.2 交差項\n説明変数として交差項 (interaction term) を加えたモデルを考える. \\[\ny = \\alpha + \\beta x + \\gamma w + \\delta xw + u\n\\]\n説明変数 x と w の交差項は : 記号を使って x:w と表す. このモデルでは主効果 x と w に加えて, 交差項 x:w を明示的に指定している.\n\nfm&lt;-lm(y~x+w+x:w,data=df)\nsummary(fm)\n## \n## Call:\n## lm(formula = y ~ x + w + x:w, data = df)\n## \n## Residuals:\n##      Min       1Q   Median       3Q      Max \n## -3.10486 -0.56990 -0.02496  0.46515  1.99951 \n## \n## Coefficients:\n##             Estimate Std. Error t value Pr(&gt;|t|)    \n## (Intercept)  11.3862     0.3416  33.329  &lt; 2e-16 ***\n## x             1.5569     0.5353   2.908 0.004514 ** \n## wT           -1.4408     0.4243  -3.395 0.000998 ***\n## x:wT          0.3611     0.6797   0.531 0.596466    \n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n## \n## Residual standard error: 0.9487 on 96 degrees of freedom\n## Multiple R-squared:  0.4538, Adjusted R-squared:  0.4367 \n## F-statistic: 26.58 on 3 and 96 DF,  p-value: 1.332e-12\n\nもしくは以下のように * 記号を使って簡便に表すこともできる. x*w は自動的に x + w + x:w に展開される.\n\nfm &lt;- lm(y~x*w,data=df)\nsummary(fm)\n## \n## Call:\n## lm(formula = y ~ x * w, data = df)\n## \n## Residuals:\n##      Min       1Q   Median       3Q      Max \n## -3.10486 -0.56990 -0.02496  0.46515  1.99951 \n## \n## Coefficients:\n##             Estimate Std. Error t value Pr(&gt;|t|)    \n## (Intercept)  11.3862     0.3416  33.329  &lt; 2e-16 ***\n## x             1.5569     0.5353   2.908 0.004514 ** \n## wT           -1.4408     0.4243  -3.395 0.000998 ***\n## x:wT          0.3611     0.6797   0.531 0.596466    \n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n## \n## Residual standard error: 0.9487 on 96 degrees of freedom\n## Multiple R-squared:  0.4538, Adjusted R-squared:  0.4367 \n## F-statistic: 26.58 on 3 and 96 DF,  p-value: 1.332e-12\n\n\n\n8.2.3 エフ検定\n今, 帰無仮説が \\[\ny = \\alpha + \\beta x + u\n\\] で, 対立仮説が \\[\ny = \\alpha + \\beta x + \\gamma w + \\delta xw + u\n\\] となる検定を実施したい.\nこれは複数の係数 (\\(\\gamma\\) と \\(\\delta\\)) が同時にゼロであるかを検定するエフ検定である. このような制約付き検定は, 制約なしモデル (対立仮説) と制約付きモデル (帰無仮説) の残差自乗和を比較することで実施できる. 対立仮説 (制約なしモデル) の残差自乗和を \\(SSR\\) とし, その自由度を \\(df\\) とする. 自由度は観測数から推定されるパラメータの数 (説明変数の数と切片) を減じた数である. 帰無仮説 (制約付きモデル) の残差自乗和を \\(SSR_0\\) とし, 制約の数を \\(q\\) とする. 制約の数は帰無仮説の自由度から対立仮説の自由度を差し引いた数である. このとき, 以下のF値は帰無仮説が正しいもとで自由度 \\((q, df)\\) のF分布にしたがう. \\[\nF = \\frac{(SSR_0-SSR)/q}{SSR/df}\n\\]\nR でF値を手動で計算するには以下のようにする. まず両方のモデルを推定し, それぞれの自由度 ($df) と残差自乗和 (deviance) を取り出す. 制約の数 \\(q\\) は両モデルの自由度の差である. F値は上記の式に従って計算する.\n\nfm0 &lt;- lm(y~x,data=df)\nfm1 &lt;- lm(y~x*w,data=df)\ndof &lt;- fm1$df\nq &lt;- fm0$df-dof\nSSR0 &lt;- deviance(fm0)\nSSR &lt;- deviance(fm1)\n(F &lt;- ((SSR0-SSR)/q)/(SSR/dof))\n## [1] 21.02338\n\nこのF値に対応するp値は pf 関数を使って計算できる. pf 関数はF分布の累積分布関数であり, 1-pf(F, df1, df2) で上側確率 (p値) が得られる. 第一自由度 (df1) は制約の数 \\(q\\), 第二自由度 (df2) は対立仮説の自由度である.\n\n1-pf(F,df1=q,df2=dof)\n## [1] 2.677698e-08\n\nこれらの手順は anova 関数を用いれば簡単に実行できる. anova 関数に2つのモデルを渡すと, 自動的にエフ検定を実施し, F値とp値を表示してくれる.\n\nanova(fm0,fm1)\n## Analysis of Variance Table\n## \n## Model 1: y ~ x\n## Model 2: y ~ x * w\n##   Res.Df     RSS Df Sum of Sq      F    Pr(&gt;F)    \n## 1     98 124.240                                  \n## 2     96  86.399  2    37.841 21.023 2.678e-08 ***\n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nモデルの順番を入れ替えても, 検定統計量とp値は同じである. ただし残差自乗和の差の符号が変わるため, 出力の見た目は異なる.\n\nanova(fm1,fm0)\n## Analysis of Variance Table\n## \n## Model 1: y ~ x * w\n## Model 2: y ~ x\n##   Res.Df     RSS Df Sum of Sq      F    Pr(&gt;F)    \n## 1     96  86.399                                  \n## 2     98 124.240 -2   -37.841 21.023 2.678e-08 ***\n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>古典的仮定のもとでの最小二乗法</span>"
    ]
  }
]