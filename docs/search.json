[
  {
    "objectID": "06-datawrangling.html",
    "href": "06-datawrangling.html",
    "title": "7  整然データ",
    "section": "",
    "text": "7.1 データ整形\nまずデータセット mtcars を例に取り、整形の基本操作を確認する。as_tibble() を介して行名を列に移すと、後続の操作が行いやすくなる。\nmtcars_tbl &lt;- mtcars |&gt; \n  as_tibble(rownames = \"model\")\n\nmtcars_tbl |&gt; slice_head(n = 6)\n## # A tibble: 6 × 12\n##   model          mpg   cyl  disp    hp  drat    wt  qsec    vs    am  gear  carb\n##   &lt;chr&gt;        &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n## 1 Mazda RX4     21       6   160   110  3.9   2.62  16.5     0     1     4     4\n## 2 Mazda RX4 W…  21       6   160   110  3.9   2.88  17.0     0     1     4     4\n## 3 Datsun 710    22.8     4   108    93  3.85  2.32  18.6     1     1     4     1\n## 4 Hornet 4 Dr…  21.4     6   258   110  3.08  3.22  19.4     1     0     3     1\n## 5 Hornet Spor…  18.7     8   360   175  3.15  3.44  17.0     0     0     3     2\n## 6 Valiant       18.1     6   225   105  2.76  3.46  20.2     1     0     3     1\nここでは R 4.1 から導入されたパイプ演算子 |&gt; を利用している。従来の %&gt;% と同様に、左辺の結果を右辺の関数に渡す構文である。\ndplyr を使うとデータフレームの処理が大幅に簡潔になる。 変数の抽出には select() を使う。\nmtcars_tbl |&gt; \n  select(model, mpg, disp) |&gt; \n  slice_head(n = 6)\n## # A tibble: 6 × 3\n##   model               mpg  disp\n##   &lt;chr&gt;             &lt;dbl&gt; &lt;dbl&gt;\n## 1 Mazda RX4          21     160\n## 2 Mazda RX4 Wag      21     160\n## 3 Datsun 710         22.8   108\n## 4 Hornet 4 Drive     21.4   258\n## 5 Hornet Sportabout  18.7   360\n## 6 Valiant            18.1   225\n条件に合致した行だけを抽出したい場合は filter() が便利である。\nmtcars_tbl |&gt; \n  select(model, mpg, disp) |&gt; \n  filter(disp &gt; 300)\n## # A tibble: 11 × 3\n##    model                 mpg  disp\n##    &lt;chr&gt;               &lt;dbl&gt; &lt;dbl&gt;\n##  1 Hornet Sportabout    18.7   360\n##  2 Duster 360           14.3   360\n##  3 Cadillac Fleetwood   10.4   472\n##  4 Lincoln Continental  10.4   460\n##  5 Chrysler Imperial    14.7   440\n##  6 Dodge Challenger     15.5   318\n##  7 AMC Javelin          15.2   304\n##  8 Camaro Z28           13.3   350\n##  9 Pontiac Firebird     19.2   400\n## 10 Ford Pantera L       15.8   351\n## 11 Maserati Bora        15     301\nrename() を使えば変数名を変更できる。日本語の列名にも対応している。\nmtcars_tbl |&gt; \n  select(model, mpg, disp) |&gt; \n  rename(`速度` = mpg, `距離` = disp) |&gt; \n  slice_head(n = 6)\n## # A tibble: 6 × 3\n##   model              速度  距離\n##   &lt;chr&gt;             &lt;dbl&gt; &lt;dbl&gt;\n## 1 Mazda RX4          21     160\n## 2 Mazda RX4 Wag      21     160\n## 3 Datsun 710         22.8   108\n## 4 Hornet 4 Drive     21.4   258\n## 5 Hornet Sportabout  18.7   360\n## 6 Valiant            18.1   225\n並べ替えは arrange() で行う。\nmtcars_tbl |&gt; \n  select(model, mpg, disp) |&gt; \n  arrange(mpg) |&gt; \n  slice_head(n = 6)\n## # A tibble: 6 × 3\n##   model                 mpg  disp\n##   &lt;chr&gt;               &lt;dbl&gt; &lt;dbl&gt;\n## 1 Cadillac Fleetwood   10.4   472\n## 2 Lincoln Continental  10.4   460\n## 3 Camaro Z28           13.3   350\n## 4 Duster 360           14.3   360\n## 5 Chrysler Imperial    14.7   440\n## 6 Maserati Bora        15     301\n降順に並べる場合は desc() と組み合わせる。\nmtcars_tbl |&gt; \n  select(model, mpg, disp) |&gt; \n  arrange(desc(mpg)) |&gt; \n  slice_head(n = 6)\n## # A tibble: 6 × 3\n##   model            mpg  disp\n##   &lt;chr&gt;          &lt;dbl&gt; &lt;dbl&gt;\n## 1 Toyota Corolla  33.9  71.1\n## 2 Fiat 128        32.4  78.7\n## 3 Honda Civic     30.4  75.7\n## 4 Lotus Europa    30.4  95.1\n## 5 Fiat X1-9       27.3  79  \n## 6 Porsche 914-2   26   120.\nmutate() を使うと新しい列を追加できる。\nmtcars_tbl |&gt; \n  mutate(gpm = 1 / mpg) |&gt; \n  select(model, mpg, gpm) |&gt; \n  slice_head(n = 6)\n## # A tibble: 6 × 3\n##   model               mpg    gpm\n##   &lt;chr&gt;             &lt;dbl&gt;  &lt;dbl&gt;\n## 1 Mazda RX4          21   0.0476\n## 2 Mazda RX4 Wag      21   0.0476\n## 3 Datsun 710         22.8 0.0439\n## 4 Hornet 4 Drive     21.4 0.0467\n## 5 Hornet Sportabout  18.7 0.0535\n## 6 Valiant            18.1 0.0552\nmutate() は既存列の上書きや複数列の同時作成も可能で、計算や条件分岐をまとめて記述できる点が強みである。\n次の例では、mpg が 20 を超える場合に TRUE を返すブール列を追加している。\nmtcars_tbl |&gt; \n  mutate(is_high_mileage = mpg &gt; 20) |&gt; \n  select(model, mpg, is_high_mileage) |&gt; \n  slice_head(n = 6)\n## # A tibble: 6 × 3\n##   model               mpg is_high_mileage\n##   &lt;chr&gt;             &lt;dbl&gt; &lt;lgl&gt;          \n## 1 Mazda RX4          21   TRUE           \n## 2 Mazda RX4 Wag      21   TRUE           \n## 3 Datsun 710         22.8 TRUE           \n## 4 Hornet 4 Drive     21.4 TRUE           \n## 5 Hornet Sportabout  18.7 FALSE          \n## 6 Valiant            18.1 FALSE\nsummarise() で基本統計量を算出できる。\nmtcars_tbl |&gt; \n  summarise(avg = mean(mpg), \n            sd  = sd(mpg), \n            .groups = \"drop\")\n## # A tibble: 1 × 2\n##     avg    sd\n##   &lt;dbl&gt; &lt;dbl&gt;\n## 1  20.1  6.03\n列名を任意に付けておけば、後続の処理で指標を参照しやすくなる。\nsummarise() に .by を指定すれば、グループごとの集計も容易である。\nmtcars_tbl |&gt; \n  summarise(\n    n   = n(),\n    avg = mean(mpg),\n    sd  = sd(mpg),\n    .by = cyl\n  )\n## # A tibble: 3 × 4\n##     cyl     n   avg    sd\n##   &lt;dbl&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt;\n## 1     6     7  19.7  1.45\n## 2     4    11  26.7  4.51\n## 3     8    14  15.1  2.56",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>整然データ</span>"
    ]
  },
  {
    "objectID": "06-datawrangling.html#データ結合",
    "href": "06-datawrangling.html#データ結合",
    "title": "7  整然データ",
    "section": "7.2 データ結合",
    "text": "7.2 データ結合\ndplyr にはデータフレームを縦横方向に結合したり、キーを用いて結合したりするための関数が揃っている。\n縦方向に結合するには bind_rows() を使う。\n\ndf1 &lt;- tibble(X = 1:2, Y = 1:2)\ndf2 &lt;- tibble(X = 4,   Y = 4)\n\nbind_rows(df1, df2)\n## # A tibble: 3 × 2\n##       X     Y\n##   &lt;dbl&gt; &lt;dbl&gt;\n## 1     1     1\n## 2     2     2\n## 3     4     4\n\n列名と型が一致していれば、欠けている列には自動で NA が補われる。\n横方向に結合する場合は bind_cols() を利用する。\n\ndf3 &lt;- tibble(Z = 5:6)\nbind_cols(df1, df3)\n## # A tibble: 2 × 3\n##       X     Y     Z\n##   &lt;int&gt; &lt;int&gt; &lt;int&gt;\n## 1     1     1     5\n## 2     2     2     6\n\n行数が一致していないとリサイクルされるか警告が出るので注意する。\nキーを用いた結合には四種類の join 関数が利用できる。\n\ndfx &lt;- tibble(id = c(\"A\", \"B\", \"C\"), X = 1:3)\ndfy &lt;- tibble(id = c(\"A\", \"B\", \"D\"), Y = c(TRUE, FALSE, TRUE))\n\n左側データ（dfx）の行をすべて保持して結合するには left_join() を用いる。\n\nleft_join(dfx, dfy, by = \"id\")\n## # A tibble: 3 × 3\n##   id        X Y    \n##   &lt;chr&gt; &lt;int&gt; &lt;lgl&gt;\n## 1 A         1 TRUE \n## 2 B         2 FALSE\n## 3 C         3 NA\n\n右側データ（dfy）の行をすべて保持するなら right_join()。\n\nright_join(dfx, dfy, by = \"id\")\n## # A tibble: 3 × 3\n##   id        X Y    \n##   &lt;chr&gt; &lt;int&gt; &lt;lgl&gt;\n## 1 A         1 TRUE \n## 2 B         2 FALSE\n## 3 D        NA TRUE\n\n両方の行をすべて保持するなら full_join()。\n\nfull_join(dfx, dfy, by = \"id\")\n## # A tibble: 4 × 3\n##   id        X Y    \n##   &lt;chr&gt; &lt;int&gt; &lt;lgl&gt;\n## 1 A         1 TRUE \n## 2 B         2 FALSE\n## 3 C         3 NA   \n## 4 D        NA TRUE\n\ninner_join() は共通部分のみを抽出する。\n\ninner_join(dfx, dfy, by = \"id\")\n## # A tibble: 2 × 3\n##   id        X Y    \n##   &lt;chr&gt; &lt;int&gt; &lt;lgl&gt;\n## 1 A         1 TRUE \n## 2 B         2 FALSE\n\n複雑な条件で結合する場合は join_by() を使うと柔軟に定義できる。",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>整然データ</span>"
    ]
  },
  {
    "objectID": "06-datawrangling.html#tidyr",
    "href": "06-datawrangling.html#tidyr",
    "title": "7  整然データ",
    "section": "7.3 tidyr",
    "text": "7.3 tidyr\nここからは tidyr による整形の例を紹介する。まず次のデータセットを用意する。\n\ndf &lt;- tibble(\n  time = 2010:2014,\n  X = rnorm(5, 0, 1),\n  Y = rnorm(5, 0, 2),\n  Z = rnorm(5, 0, 4)\n)\n# `tibble()` なら列の型を意識しつつ手早くサンプル値を用意できる\ndf |&gt; slice_head(n = 6)\n## # A tibble: 5 × 4\n##    time      X      Y      Z\n##   &lt;int&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;\n## 1  2010 -1.51   3.03  -0.356\n## 2  2011  0.203  0.466 -0.617\n## 3  2012  0.868 -0.638 -5.21 \n## 4  2013  0.146  0.478  1.31 \n## 5  2014 -0.649 -1.35   4.82\n\n列名をキーにして縦長へ変換するときは pivot_longer() を用いる。\n\ndf_long &lt;- df |&gt; \n  pivot_longer(-time, names_to = \"key\", values_to = \"value\")\n# names_to / values_to を指定しておくと後続処理が読みやすい\ndf_long\n## # A tibble: 15 × 3\n##     time key    value\n##    &lt;int&gt; &lt;chr&gt;  &lt;dbl&gt;\n##  1  2010 X     -1.51 \n##  2  2010 Y      3.03 \n##  3  2010 Z     -0.356\n##  4  2011 X      0.203\n##  5  2011 Y      0.466\n##  6  2011 Z     -0.617\n##  7  2012 X      0.868\n##  8  2012 Y     -0.638\n##  9  2012 Z     -5.21 \n## 10  2013 X      0.146\n## 11  2013 Y      0.478\n## 12  2013 Z      1.31 \n## 13  2014 X     -0.649\n## 14  2014 Y     -1.35 \n## 15  2014 Z      4.82\n\npivot_wider() を使えば再び元の構造に戻すことができる。\n\ndf_long |&gt; \n  pivot_wider(names_from = \"key\", values_from = \"value\")\n## # A tibble: 5 × 4\n##    time      X      Y      Z\n##   &lt;int&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;\n## 1  2010 -1.51   3.03  -0.356\n## 2  2011  0.203  0.466 -0.617\n## 3  2012  0.868 -0.638 -5.21 \n## 4  2013  0.146  0.478  1.31 \n## 5  2014 -0.649 -1.35   4.82\n\n列数を増やして見せたいときや、プレゼン資料で横持ちの表が必要なときに役立つ。\ntime を列方向に展開すれば、年次を横持ちした表へ変換できる。\n\ndf_wide &lt;- df_long |&gt; \n  pivot_wider(names_from = \"time\", values_from = \"value\")\ndf_wide\n## # A tibble: 3 × 6\n##   key   `2010` `2011` `2012` `2013` `2014`\n##   &lt;chr&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;\n## 1 X     -1.51   0.203  0.868  0.146 -0.649\n## 2 Y      3.03   0.466 -0.638  0.478 -1.35 \n## 3 Z     -0.356 -0.617 -5.21   1.31   4.82\n\n再び縦長に戻す場合は次のとおりである。\n\ndf_wide |&gt; \n  pivot_longer(-key, names_to = \"time\", values_to = \"value\")\n## # A tibble: 15 × 3\n##    key   time   value\n##    &lt;chr&gt; &lt;chr&gt;  &lt;dbl&gt;\n##  1 X     2010  -1.51 \n##  2 X     2011   0.203\n##  3 X     2012   0.868\n##  4 X     2013   0.146\n##  5 X     2014  -0.649\n##  6 Y     2010   3.03 \n##  7 Y     2011   0.466\n##  8 Y     2012  -0.638\n##  9 Y     2013   0.478\n## 10 Y     2014  -1.35 \n## 11 Z     2010  -0.356\n## 12 Z     2011  -0.617\n## 13 Z     2012  -5.21 \n## 14 Z     2013   1.31 \n## 15 Z     2014   4.82\n\npivot_longer() と summarise() を組み合わせると、変数別の記述統計を簡潔にまとめられる。\n\ncars |&gt; \n  as_tibble() |&gt; \n  pivot_longer(everything(), names_to = \"variable\", values_to = \"value\") |&gt; \n  group_by(variable) |&gt;\n  summarise(\n    nobs = n(),\n    avg  = mean(value),\n    sd   = sd(value)\n  ) |&gt;\n  ungroup()\n## # A tibble: 2 × 4\n##   variable  nobs   avg    sd\n##   &lt;chr&gt;    &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt;\n## 1 dist        50  43.0 25.8 \n## 2 speed       50  15.4  5.29\n# 欠損を除外したいときは mean(value, na.rm = TRUE) のように na.rm を付ける\n\n日本語の列名でも同じ操作が可能である。\n\ntab &lt;- cars |&gt; \n  as_tibble() |&gt; \n  pivot_longer(c(dist, speed), names_to = \"variable\", values_to = \"value\") |&gt; \n  group_by(variable) |&gt;\n  summarise(\n    nobs = n(),\n    avg  = mean(value),\n    sd   = sd(value)\n  ) |&gt;\n  ungroup() |&gt;\n  mutate(\n    `変数` = dplyr::recode(variable, dist = \"距離\", speed = \"速度\")\n  ) |&gt;\n  select(\n    `変数`,\n    `観測数`   = nobs,\n    `平均`     = avg,\n    `標準偏差` = sd\n  )\ntab |&gt; slice_head(n = 6)\n## # A tibble: 2 × 4\n##   変数  観測数  平均 標準偏差\n##   &lt;chr&gt;  &lt;int&gt; &lt;dbl&gt;    &lt;dbl&gt;\n## 1 距離      50  43.0    25.8 \n## 2 速度      50  15.4     5.29",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>整然データ</span>"
    ]
  },
  {
    "objectID": "06-datawrangling.html#実践例",
    "href": "06-datawrangling.html#実践例",
    "title": "7  整然データ",
    "section": "7.4 実践例",
    "text": "7.4 実践例\ntidyr を用いた別の例を見てみよう。横軸を年としたデータセット df がある。\n\ndf &lt;- tibble(\n  name  = letters,\n  `2010` = rnorm(26),\n  `2011` = rnorm(26),\n  `2012` = rnorm(26)\n) \ndf |&gt; slice_head(n = 6)\n## # A tibble: 6 × 4\n##   name    `2010` `2011` `2012`\n##   &lt;chr&gt;    &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;\n## 1 a      0.00278  1.14   0.553\n## 2 b      0.445   -0.381 -0.105\n## 3 c      0.427    0.462 -0.130\n## 4 d      1.31    -0.607 -2.02 \n## 5 e     -0.479    0.128 -0.384\n## 6 f      1.19    -1.43  -1.29\n\nさらに、年ごとのデータセット df_2010、df_2011、df_2012 の 3 つも用意する。\n\ndf_2010 &lt;- tibble(name = letters, runif = runif(26))\ndf_2011 &lt;- tibble(name = letters, runif = runif(26))\ndf_2012 &lt;- tibble(name = letters, runif = runif(26))\n\nこれら 4 つのデータセットを統合して整然データにする。\nまず df を pivot_longer() で縦長に変換する。\n\ndf_rnorm &lt;- df |&gt; \n  pivot_longer(-name, names_to = \"time\", values_to = \"rnorm\") |&gt; \n  mutate(time = as.numeric(time))\ndf_rnorm |&gt; slice_head(n = 6)\n## # A tibble: 6 × 3\n##   name   time    rnorm\n##   &lt;chr&gt; &lt;dbl&gt;    &lt;dbl&gt;\n## 1 a      2010  0.00278\n## 2 a      2011  1.14   \n## 3 a      2012  0.553  \n## 4 b      2010  0.445  \n## 5 b      2011 -0.381  \n## 6 b      2012 -0.105\n\nここでは time 列を数値に変換している。\n次に、3 つの年別データセットを bind_rows() で縦に結合する。\n\ndf_runif &lt;- bind_rows(\n  \"2010\" = df_2010,\n  \"2011\" = df_2011,\n  \"2012\" = df_2012,\n  .id    = \"time\"\n) |&gt; \n  mutate(time = as.numeric(time))\ndf_runif |&gt; slice_head(n = 6)\n## # A tibble: 6 × 3\n##    time name   runif\n##   &lt;dbl&gt; &lt;chr&gt;  &lt;dbl&gt;\n## 1  2010 a     0.958 \n## 2  2010 b     0.0967\n## 3  2010 c     0.492 \n## 4  2010 d     0.810 \n## 5  2010 e     0.365 \n## 6  2010 f     0.453\n\n.id で追加された列を数値に変換して年情報として利用している。\n最後に full_join() を使って 2 つのデータを結合する。\n\ndf_full &lt;- full_join(df_rnorm, df_runif, by = c(\"name\", \"time\"))\ndf_full |&gt; slice_head(n = 6)\n## # A tibble: 6 × 4\n##   name   time    rnorm  runif\n##   &lt;chr&gt; &lt;dbl&gt;    &lt;dbl&gt;  &lt;dbl&gt;\n## 1 a      2010  0.00278 0.958 \n## 2 a      2011  1.14    0.0235\n## 3 a      2012  0.553   0.146 \n## 4 b      2010  0.445   0.0967\n## 5 b      2011 -0.381   0.680 \n## 6 b      2012 -0.105   0.615\n\n整然データにまとめておけば、ggplot2 やモデリング関数へそのまま渡せるため、後続処理がスムーズになり再現性も高まる。",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>整然データ</span>"
    ]
  },
  {
    "objectID": "10-panel.html",
    "href": "10-panel.html",
    "title": "11  パネル分析",
    "section": "",
    "text": "11.1 データ\nパネル分析に必要なパッケージを読み込み、データセットを準備する。 library(AER) コマンドで AER パッケージを、library(plm) コマンドで plm パッケージを読み込む。 次に data(\"Grunfeld\", package = \"plm\") コマンドで Grunfeld データセットを読み込む。 Grunfeld データは企業の投資、企業価値、資本ストックに関するパネルデータである。 head(Grunfeld) コマンドでデータの最初の数行を表示する。\nlibrary(AER)\nlibrary(plm)\ndata(\"Grunfeld\", package = \"plm\")\nhead(Grunfeld)\n##   firm year   inv  value capital\n## 1    1 1935 317.6 3078.5     2.8\n## 2    1 1936 391.8 4661.7    52.6\n## 3    1 1937 410.6 5387.1   156.9\n## 4    1 1938 257.7 2792.2   209.2\n## 5    1 1939 330.8 4313.2   203.4\n## 6    1 1940 461.2 4643.9   207.2\n次にパネルデータとして扱うために、pdata.frame() 関数を使用する。 pdata.frame(Grunfeld, index = c(\"firm\", \"year\")) コマンドで、firm (企業) と year (年) をインデックスとしてパネルデータフレームを作成し、pdata に格納する。 pdim(pdata) コマンドでパネルデータの次元 (企業数、時間数、総観測数) を確認する。\npdata &lt;- pdata.frame(Grunfeld, index = c(\"firm\", \"year\"))\npdim(pdata)\n## Balanced Panel: n = 10, T = 20, N = 200",
    "crumbs": [
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>パネル分析</span>"
    ]
  },
  {
    "objectID": "10-panel.html#プーリングols",
    "href": "10-panel.html#プーリングols",
    "title": "11  パネル分析",
    "section": "11.2 プーリングOLS",
    "text": "11.2 プーリングOLS\n次の重回帰モデルを考える。\n\\[\ninv_{it} = \\beta_0 + \\beta_1 value_{it} + \\beta_2 capital_{it} + u_{it}\n\\]\n誤差項 \\(u_{it}\\) は \\(i\\) についても\\(t\\) についても独立同一分布と仮定する。 さらに誤差項は説明変数と独立である。 この時、パネルデータにおいてもOLS推定法でパラメータは不偏である。 ここでの重回帰モデルをプーリングOLSモデルと呼ぶことにする。\nプーリングOLS推定を実行するには、plm() 関数で model = \"pooling\" を指定する。 plm(inv ~ value + capital, data = pdata, model = \"pooling\") コマンドで、inv を被説明変数、value と capital を説明変数としてプーリングOLS推定を行い、結果を gp に格納する。 summary(gp) コマンドで推定結果の詳細を表示する。\n\ngp &lt;- plm(inv ~ value + capital, data = pdata, model = \"pooling\")\nsummary(gp)\n## Pooling Model\n## \n## Call:\n## plm(formula = inv ~ value + capital, data = pdata, model = \"pooling\")\n## \n## Balanced Panel: n = 10, T = 20, N = 200\n## \n## Residuals:\n##      Min.   1st Qu.    Median   3rd Qu.      Max. \n## -291.6757  -30.0137    5.3033   34.8293  369.4464 \n## \n## Coefficients:\n##                Estimate  Std. Error t-value  Pr(&gt;|t|)    \n## (Intercept) -42.7143694   9.5116760 -4.4907 1.207e-05 ***\n## value         0.1155622   0.0058357 19.8026 &lt; 2.2e-16 ***\n## capital       0.2306785   0.0254758  9.0548 &lt; 2.2e-16 ***\n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n## \n## Total Sum of Squares:    9359900\n## Residual Sum of Squares: 1755900\n## R-Squared:      0.81241\n## Adj. R-Squared: 0.8105\n## F-statistic: 426.576 on 2 and 197 DF, p-value: &lt; 2.22e-16\n\nこのプーリングOLS推定は、通常の lm() 関数を使った回帰分析と同じ結果を得る。 lm(inv ~ value + capital, data = pdata) コマンドで通常のOLS推定を行い、summary() コマンドで結果を表示すると、上記の plm() による結果と同一であることが確認できる。\n\nsummary(lm(inv ~ value + capital, data = pdata))\n## \n## Call:\n## lm(formula = inv ~ value + capital, data = pdata)\n## \n## Residuals:\n##     Min      1Q  Median      3Q     Max \n## -291.68  -30.01    5.30   34.83  369.45 \n## \n## Coefficients:\n##               Estimate Std. Error t value Pr(&gt;|t|)    \n## (Intercept) -42.714369   9.511676  -4.491 1.21e-05 ***\n## value         0.115562   0.005836  19.803  &lt; 2e-16 ***\n## capital       0.230678   0.025476   9.055  &lt; 2e-16 ***\n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n## \n## Residual standard error: 94.41 on 197 degrees of freedom\n## Multiple R-squared:  0.8124, Adjusted R-squared:  0.8105 \n## F-statistic: 426.6 on 2 and 197 DF,  p-value: &lt; 2.2e-16",
    "crumbs": [
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>パネル分析</span>"
    ]
  },
  {
    "objectID": "10-panel.html#固定効果-平均差分法",
    "href": "10-panel.html#固定効果-平均差分法",
    "title": "11  パネル分析",
    "section": "11.3 固定効果 (平均差分法)",
    "text": "11.3 固定効果 (平均差分法)\n次の重回帰モデルを考える。\n\\[\ninv_{it} = \\beta_1 value_{it} + \\beta_2 capital_{it} +\\alpha_i + u_{it}\n\\]\nこの \\(\\alpha_i\\) は個別固定効果と呼ばれている。 \\(\\alpha_i\\) は時間 \\(t\\) に対して一定である。 \\(\\alpha_i\\) は誤差項と相関があるかもしれない。 この個別固定効果を持つ重回帰モデルを固定効果モデルと呼ぶことにする。\nそれぞれの時間平均をとれば以下になる。\n\\[\n\\bar{inv}_{i} = \\beta_1 \\bar{value}_{i} + \\beta_2 \\bar{capital}_{i} +\\alpha_i  + \\bar{u}_{i}\n\\]\nそして、それぞれの観測値から時間平均を差し引けば以下のように \\(\\alpha_i\\) は消去される。\n\\[\ninv_{it}-\\overline{inv}_{i} = \\beta_1 (value_{it}-\\overline{value}_{i}) + \\beta_2 (capital_{it}-\\overline{capital}_{i})  + u_{it} -\\bar{u}_{i}\n\\]\nこのように変換して回帰分析すれば \\(\\alpha_i\\) は誤差項と相関があっても一致推定量である。 このような推定方法を平均差分法という。\n固定効果モデルを平均差分法で推定するには、plm() 関数で model = \"within\" を指定する。 plm(inv ~ value + capital, data = pdata, model = \"within\") コマンドで固定効果推定を行い、結果を gi に格納する。 summary(gi) コマンドで推定結果の詳細を表示する。\n\ngi &lt;- plm(inv ~ value + capital, data = pdata, model = \"within\")\nsummary(gi)\n## Oneway (individual) effect Within Model\n## \n## Call:\n## plm(formula = inv ~ value + capital, data = pdata, model = \"within\")\n## \n## Balanced Panel: n = 10, T = 20, N = 200\n## \n## Residuals:\n##       Min.    1st Qu.     Median    3rd Qu.       Max. \n## -184.00857  -17.64316    0.56337   19.19222  250.70974 \n## \n## Coefficients:\n##         Estimate Std. Error t-value  Pr(&gt;|t|)    \n## value   0.110124   0.011857  9.2879 &lt; 2.2e-16 ***\n## capital 0.310065   0.017355 17.8666 &lt; 2.2e-16 ***\n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n## \n## Total Sum of Squares:    2244400\n## Residual Sum of Squares: 523480\n## R-Squared:      0.76676\n## Adj. R-Squared: 0.75311\n## F-statistic: 309.014 on 2 and 188 DF, p-value: &lt; 2.22e-16\n\n推定された個別固定効果 \\(\\alpha_i\\) の値を確認するには、fixef() 関数を使用する。 fixef(gi) コマンドで各企業の固定効果の推定値を表示する。\n\nfixef(gi)\n##         1         2         3         4         5         6         7         8 \n##  -70.2967  101.9058 -235.5718  -27.8093 -114.6168  -23.1613  -66.5535  -57.5457 \n##         9        10 \n##  -87.2223   -6.5678\n\nこの固定効果推定は、lm() 関数で企業ダミーを含めた回帰分析と同等である。 lm(inv ~ value + capital+0+factor(firm), data = pdata) コマンドで、定数項を除外 (+0) し企業ダミー (factor(firm)) を含めた推定を行い、summary() コマンドで結果を表示する。 係数の推定値は同じであるが、決定係数が大きく異なっていることに注意されたい。\n\nsummary(lm(inv ~ value + capital+0+factor(firm), data = pdata))\n## \n## Call:\n## lm(formula = inv ~ value + capital + 0 + factor(firm), data = pdata)\n## \n## Residuals:\n##      Min       1Q   Median       3Q      Max \n## -184.009  -17.643    0.563   19.192  250.710 \n## \n## Coefficients:\n##                  Estimate Std. Error t value Pr(&gt;|t|)    \n## value             0.11012    0.01186   9.288  &lt; 2e-16 ***\n## capital           0.31007    0.01735  17.867  &lt; 2e-16 ***\n## factor(firm)1   -70.29672   49.70796  -1.414   0.1590    \n## factor(firm)2   101.90581   24.93832   4.086 6.49e-05 ***\n## factor(firm)3  -235.57184   24.43162  -9.642  &lt; 2e-16 ***\n## factor(firm)4   -27.80929   14.07775  -1.975   0.0497 *  \n## factor(firm)5  -114.61681   14.16543  -8.091 7.14e-14 ***\n## factor(firm)6   -23.16130   12.66874  -1.828   0.0691 .  \n## factor(firm)7   -66.55347   12.84297  -5.182 5.63e-07 ***\n## factor(firm)8   -57.54566   13.99315  -4.112 5.85e-05 ***\n## factor(firm)9   -87.22227   12.89189  -6.766 1.63e-10 ***\n## factor(firm)10   -6.56784   11.82689  -0.555   0.5793    \n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n## \n## Residual standard error: 52.77 on 188 degrees of freedom\n## Multiple R-squared:  0.9616, Adjusted R-squared:  0.9591 \n## F-statistic:   392 on 12 and 188 DF,  p-value: &lt; 2.2e-16\n\n個別固定効果が統計的に有効かどうか (すなわち、固定効果モデルとプーリングOLSモデルのどちらが適切か) を検定するには、F検定を実施する。 pFtest(gi,gp) コマンドで、固定効果モデル (gi) とプーリングOLSモデル (gp) を比較するF検定を実行する。\n\npFtest(gi,gp)\n## \n##  F test for individual effects\n## \n## data:  inv ~ value + capital\n## F = 49.177, df1 = 9, df2 = 188, p-value &lt; 2.2e-16\n## alternative hypothesis: significant effects\n\n\n11.3.1 時間効果モデル\n次のモデルを考える。\n\\[\ninv_{it} = \\beta_1 value_{it} + \\beta_2 capital_{it}+ \\gamma_t +\\alpha_i + u_{it}\n\\]\nこの \\(\\gamma_t\\) は時間固定効果と呼ばれている。 ここでは個別固定効果と時間固定効果の2つの固定効果を持つ重回帰モデルを時間効果モデルと呼ぶことにする。\n時間効果モデルを推定するには、plm() 関数で effect=\"twoways\" と model = \"within\" を指定する。 plm(inv ~ value + capital, data = pdata, effect=\"twoways\", model = \"within\") コマンドで、個別固定効果と時間固定効果の両方を含むモデルを推定し、結果を gi2 に格納する。 summary(gi2) コマンドで推定結果の詳細を表示する。\n\ngi2 &lt;- plm(inv ~ value + capital, data = pdata, effect=\"twoways\",model = \"within\")\nsummary(gi2)\n## Twoways effects Within Model\n## \n## Call:\n## plm(formula = inv ~ value + capital, data = pdata, effect = \"twoways\", \n##     model = \"within\")\n## \n## Balanced Panel: n = 10, T = 20, N = 200\n## \n## Residuals:\n##      Min.   1st Qu.    Median   3rd Qu.      Max. \n## -162.6094  -19.4710   -1.2669   19.1277  211.8420 \n## \n## Coefficients:\n##         Estimate Std. Error t-value  Pr(&gt;|t|)    \n## value   0.117716   0.013751  8.5604 6.653e-15 ***\n## capital 0.357916   0.022719 15.7540 &lt; 2.2e-16 ***\n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n## \n## Total Sum of Squares:    1615600\n## Residual Sum of Squares: 452150\n## R-Squared:      0.72015\n## Adj. R-Squared: 0.67047\n## F-statistic: 217.442 on 2 and 169 DF, p-value: &lt; 2.22e-16\n\n推定された個別固定効果と時間固定効果をそれぞれ確認するには、fixef() 関数で effect 引数を指定する。 fixef(gi2, effect = \"individual\") コマンドで各企業の固定効果を、fixef(gi2, effect = \"time\") コマンドで各年の固定効果を表示する。\n\nfixef(gi2, effect = \"individual\")\n##         1         2         3         4         5         6         7         8 \n##  -86.9002  120.1540 -222.1310    8.4536  -92.3388   15.9884  -35.4336  -19.4097 \n##         9        10 \n##  -56.6827   39.9369\nfixef(gi2, effect = \"time\")\n##    1935    1936    1937    1938    1939    1940    1941    1942    1943    1944 \n##  -86.90 -106.10 -127.59 -126.13 -156.37 -131.14 -105.70 -108.04 -129.88 -130.00 \n##    1945    1946    1947    1948    1949    1950    1951    1952    1953    1954 \n## -142.58 -118.07 -126.29 -130.62 -160.40 -162.80 -149.38 -151.53 -154.62 -180.43\n\nこの時間効果モデルの推定は、lm() 関数で企業ダミーと年ダミーの両方を含めた回帰分析と同等である。 lm(inv ~ value + capital+0+factor(firm)+factor(year), data = pdata) コマンドで、定数項を除外し企業ダミーと年ダミーを含めた推定を行い、summary() コマンドで結果を表示する。 係数の推定値は同じであるが、決定係数が大きく異なっていることに注意されたい。\n\nsummary(lm(inv ~ value + capital+0+factor(firm)+factor(year), data = pdata))\n## \n## Call:\n## lm(formula = inv ~ value + capital + 0 + factor(firm) + factor(year), \n##     data = pdata)\n## \n## Residuals:\n##      Min       1Q   Median       3Q      Max \n## -162.609  -19.471   -1.267   19.128  211.842 \n## \n## Coefficients:\n##                    Estimate Std. Error t value Pr(&gt;|t|)    \n## value               0.11772    0.01375   8.560 6.65e-15 ***\n## capital             0.35792    0.02272  15.754  &lt; 2e-16 ***\n## factor(firm)1     -86.90023   56.04663  -1.550 0.122893    \n## factor(firm)2     120.15401   29.16688   4.120 5.93e-05 ***\n## factor(firm)3    -222.13103   28.59744  -7.768 7.37e-13 ***\n## factor(firm)4       8.45361   20.41784   0.414 0.679377    \n## factor(firm)5     -92.33883   20.91106  -4.416 1.79e-05 ***\n## factor(firm)6      15.98841   19.88487   0.804 0.422498    \n## factor(firm)7     -35.43362   20.17003  -1.757 0.080772 .  \n## factor(firm)8     -19.40972   20.49076  -0.947 0.344868    \n## factor(firm)9     -56.68267   19.81211  -2.861 0.004756 ** \n## factor(firm)10     39.93689   20.40337   1.957 0.051951 .  \n## factor(year)1936  -19.19741   23.67586  -0.811 0.418596    \n## factor(year)1937  -40.69001   24.69541  -1.648 0.101277    \n## factor(year)1938  -39.22640   23.23594  -1.688 0.093221 .  \n## factor(year)1939  -69.47029   23.65607  -2.937 0.003780 ** \n## factor(year)1940  -44.23508   23.80979  -1.858 0.064930 .  \n## factor(year)1941  -18.80446   23.69400  -0.794 0.428519    \n## factor(year)1942  -21.13979   23.38163  -0.904 0.367219    \n## factor(year)1943  -42.97762   23.55287  -1.825 0.069808 .  \n## factor(year)1944  -43.09877   23.61020  -1.825 0.069701 .  \n## factor(year)1945  -55.68304   23.89562  -2.330 0.020974 *  \n## factor(year)1946  -31.16928   24.11598  -1.292 0.197957    \n## factor(year)1947  -39.39224   23.78368  -1.656 0.099522 .  \n## factor(year)1948  -43.71651   23.96965  -1.824 0.069945 .  \n## factor(year)1949  -73.49510   24.18292  -3.039 0.002750 ** \n## factor(year)1950  -75.89611   24.34553  -3.117 0.002144 ** \n## factor(year)1951  -62.48091   24.86425  -2.513 0.012911 *  \n## factor(year)1952  -64.63234   25.34950  -2.550 0.011672 *  \n## factor(year)1953  -67.71797   26.61108  -2.545 0.011832 *  \n## factor(year)1954  -93.52622   27.10786  -3.450 0.000708 ***\n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n## \n## Residual standard error: 51.72 on 169 degrees of freedom\n## Multiple R-squared:  0.9668, Adjusted R-squared:  0.9607 \n## F-statistic: 158.8 on 31 and 169 DF,  p-value: &lt; 2.2e-16\n\n時間固定効果が統計的に有効かどうか (すなわち、時間効果モデルと個別固定効果のみのモデルのどちらが適切か) を検定するには、F検定を実施する。 pFtest(gi2, gi) コマンドで、時間効果モデル (gi2) と個別固定効果のみのモデル (gi) を比較するF検定を実行する。\n\npFtest(gi2, gi)\n## \n##  F test for twoways effects\n## \n## data:  inv ~ value + capital\n## F = 1.4032, df1 = 19, df2 = 169, p-value = 0.1309\n## alternative hypothesis: significant effects",
    "crumbs": [
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>パネル分析</span>"
    ]
  },
  {
    "objectID": "10-panel.html#固定効果-一階差分法",
    "href": "10-panel.html#固定効果-一階差分法",
    "title": "11  パネル分析",
    "section": "11.4 固定効果 (一階差分法)",
    "text": "11.4 固定効果 (一階差分法)\n次のモデルを考える。\n\\[\ninv_{it} = \\beta_1 value_{it} + \\beta_2 capital_{it} +\\alpha_i + u_{it}\n\\]\nこの \\(\\alpha_i\\) は固定効果と呼ばれている。 \\(\\alpha_i\\) は時間 \\(t\\) に対して一定である。 \\(\\alpha_i\\) は誤差項と相関があるかもしれない。\nそれぞれの階差をとれば \\(\\alpha_i\\) は消去できる。\n\\[\n\\Delta inv_{it} = \\beta_1 \\Delta value_{it} + \\beta_2 \\Delta capital_{it} + \\Delta u_{it}\n\\]\nこのように変換して回帰分析すれば、\\(\\alpha_i\\) は誤差項と相関があっても一致推定量である。\n一階差分法による固定効果推定を実行するには、plm() 関数で model = \"fd\" を指定する。 plm(inv ~ value + capital+0, data = pdata, model = \"fd\") コマンドで、定数項を除外 (+0) して一階差分推定を行い、結果を gf に格納する。 summary(gf) コマンドで推定結果の詳細を表示する。\n\ngf &lt;- plm(inv ~ value + capital+0, data = pdata, model = \"fd\")\nsummary(gf)\n## Oneway (individual) effect First-Difference Model\n## \n## Call:\n## plm(formula = inv ~ value + capital + 0, data = pdata, model = \"fd\")\n## \n## Balanced Panel: n = 10, T = 20, N = 200\n## Observations used in estimation: 190\n## \n## Residuals:\n##    Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n## -202.05  -15.23   -1.76   -1.39    7.95  199.27 \n## \n## Coefficients:\n##          Estimate Std. Error t-value  Pr(&gt;|t|)    \n## value   0.0890628  0.0082341  10.816 &lt; 2.2e-16 ***\n## capital 0.2786940  0.0471564   5.910  1.58e-08 ***\n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n## \n## Total Sum of Squares:    584410\n## Residual Sum of Squares: 345940\n## R-Squared:      0.40876\n## Adj. R-Squared: 0.40561\n## F-statistic: 70.5784 on 2 and 188 DF, p-value: &lt; 2.22e-16\n\n時間固定効果を含む一階差分モデルを推定する場合は、年ダミーを追加する。 plm(inv ~ value + capital+0+factor(year), data = pdata, model = \"fd\") コマンドで、年ダミー (factor(year)) を含む一階差分推定を行い、結果を gf2 に格納する。 summary(gf2) コマンドで推定結果の詳細を表示する。\n\ngf2 &lt;-plm(inv ~ value + capital+0+factor(year), data = pdata, model = \"fd\")\nsummary(gf2)\n## Oneway (individual) effect First-Difference Model\n## \n## Call:\n## plm(formula = inv ~ value + capital + 0 + factor(year), data = pdata, \n##     model = \"fd\")\n## \n## Balanced Panel: n = 10, T = 20, N = 200\n## Observations used in estimation: 190\n## \n## Residuals:\n##       Min.    1st Qu.     Median    3rd Qu.       Max. \n## -179.69353  -18.68501    0.49555   14.27860  179.03692 \n## \n## Coefficients: (1 dropped because of singularities)\n##                    Estimate Std. Error t-value  Pr(&gt;|t|)    \n## value             0.0875445  0.0095107  9.2048 &lt; 2.2e-16 ***\n## capital           0.3246777  0.0571472  5.6814 5.727e-08 ***\n## factor(year)1935 52.1173697 67.1610018  0.7760   0.43883    \n## factor(year)1936 44.5420725 65.0001486  0.6853   0.49412    \n## factor(year)1937 32.2308400 62.5656219  0.5152   0.60712    \n## factor(year)1938 19.6675926 60.6802571  0.3241   0.74625    \n## factor(year)1939 -3.0067716 58.4729853 -0.0514   0.95905    \n## factor(year)1940 23.9596588 56.8175845  0.4217   0.67378    \n## factor(year)1941 48.5989734 54.8059164  0.8867   0.37648    \n## factor(year)1942 40.9122279 52.7118790  0.7761   0.43875    \n## factor(year)1943 22.8491024 50.5894648  0.4517   0.65209    \n## factor(year)1944 23.6577035 48.8480758  0.4843   0.62879    \n## factor(year)1945 14.7036587 46.6708001  0.3151   0.75311    \n## factor(year)1946 41.6241613 44.2490709  0.9407   0.34821    \n## factor(year)1947 27.5209677 40.4024259  0.6812   0.49670    \n## factor(year)1948 23.6476936 37.0841079  0.6377   0.52455    \n## factor(year)1949 -4.3351290 33.6481639 -0.1288   0.89764    \n## factor(year)1950 -4.2709916 30.2836724 -0.1410   0.88801    \n## factor(year)1951 16.8493484 26.2244634  0.6425   0.52142    \n## factor(year)1952 18.0590591 20.8995024  0.8641   0.38876    \n## factor(year)1953 24.3453549 13.9307034  1.7476   0.08235 .  \n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n## \n## Total Sum of Squares:    584410\n## Residual Sum of Squares: 293000\n## R-Squared:      0.49864\n## Adj. R-Squared: 0.4393\n## F-statistic: 8.5881 on 21 and 169 DF, p-value: &lt; 2.22e-16\n\n時間固定効果が統計的に有効かどうかを検定するには、F検定を実施する。 pFtest(gf2,gf) コマンドで、時間効果を含むモデル (gf2) と含まないモデル (gf) を比較するF検定を実行する。\n\npFtest(gf2,gf)\n## \n##  F test for individual effects\n## \n## data:  inv ~ value + capital + 0 + factor(year)\n## F = 1.607, df1 = 19, df2 = 169, p-value = 0.05928\n## alternative hypothesis: significant effects\n\n\n11.4.1 平均差分法と一階差分法\n平均差分法と一階差分法は誤差項の仮定をどのようにおくかによって変わってくる。 誤差項の階差をとることによって時間を通じて無相関になるなら一階差分法が望ましいであろう。 しかしながら、固定効果や時間効果の値を求めて経済学的に解釈したい場合には、平均差分法が望ましい。 さらにプーリングOLSモデルや変量効果モデルとの比較を行う意味でも平均差分法がよく使われる。\nなお時間が2期間のパネルデータのとき、平均差分法も一階差分法も計算値は同じである。 たとえば \\(t=2\\) のときの変数 \\(x_{it}\\) の平均差分値は以下のようになる。\n\\[\nx_{i2}-\\bar{x}_i=x_{i2}-\\frac{x_{i1}+x_{i2}}{2}=\\frac{x_{i2}-x_{i1}}{2}\n\\]",
    "crumbs": [
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>パネル分析</span>"
    ]
  },
  {
    "objectID": "10-panel.html#変量効果",
    "href": "10-panel.html#変量効果",
    "title": "11  パネル分析",
    "section": "11.5 変量効果",
    "text": "11.5 変量効果\n次のモデルを考える。\n\\[\ninv_{it} = \\beta_1 value_{it} + \\beta_2 capital_{it} +\\alpha_i + u_{it}\n\\]\nこの \\(\\alpha_i\\) は時間 \\(t\\) について一定であるが、\\(i\\) について独立同一分布の確率変数にしたがう。 さらに \\(\\alpha_i\\) は説明変数と無相関である時、この \\(\\alpha_i\\) は個別変量効果と呼ばれている。 なお個別固定効果は説明変数と無相関を仮定していないが、個別変量効果は無相関を仮定している点で異なる。 この個別変量効果を持つ重回帰モデルを変量効果モデルと呼ぶことにする。\n変量効果モデルを推定するには、plm() 関数で model = \"random\" を指定する。 plm(inv ~ value + capital, data = pdata, model = \"random\") コマンドで変量効果推定を行い、結果を gr に格納する。 summary(gr) コマンドで推定結果の詳細を表示する。\n\ngr &lt;- plm(inv ~ value + capital, data = pdata, model = \"random\")\nsummary(gr)\n## Oneway (individual) effect Random Effect Model \n##    (Swamy-Arora's transformation)\n## \n## Call:\n## plm(formula = inv ~ value + capital, data = pdata, model = \"random\")\n## \n## Balanced Panel: n = 10, T = 20, N = 200\n## \n## Effects:\n##                   var std.dev share\n## idiosyncratic 2784.46   52.77 0.282\n## individual    7089.80   84.20 0.718\n## theta: 0.8612\n## \n## Residuals:\n##      Min.   1st Qu.    Median   3rd Qu.      Max. \n## -177.6063  -19.7350    4.6851   19.5105  252.8743 \n## \n## Coefficients:\n##               Estimate Std. Error z-value Pr(&gt;|z|)    \n## (Intercept) -57.834415  28.898935 -2.0013  0.04536 *  \n## value         0.109781   0.010493 10.4627  &lt; 2e-16 ***\n## capital       0.308113   0.017180 17.9339  &lt; 2e-16 ***\n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n## \n## Total Sum of Squares:    2381400\n## Residual Sum of Squares: 548900\n## R-Squared:      0.7695\n## Adj. R-Squared: 0.76716\n## Chisq: 657.674 on 2 DF, p-value: &lt; 2.22e-16\n\n推定された変量効果の値を確認するには、ranef() 関数を使用する。 ranef(gr) コマンドで各企業の変量効果の推定値を表示する。\n\nranef(gr)\n##            1            2            3            4            5            6 \n##   -9.5242955  157.8910235 -172.8958044   29.9119801  -54.6790089   34.3461316 \n##            7            8            9           10 \n##   -7.8977584    0.6726376  -28.1393497   50.3144442\n\n\n11.5.1 ハウスマン検定\n変量効果モデルと固定効果モデルのどちらが適切かを検定するにはハウスマン検定を実施する。 帰無仮説は変量効果モデルが適切、対立仮説は固定効果モデルが適切である。 ハウスマン検定では、変量効果モデルと固定効果モデルの係数の差が統計的に有意かどうかを検定する。 phtest(gi,gr) コマンドで、固定効果モデル (gi) と変量効果モデル (gr) のハウスマン検定を実行する。\n\nphtest(gi,gr)\n## \n##  Hausman Test\n## \n## data:  inv ~ value + capital\n## chisq = 2.3304, df = 2, p-value = 0.3119\n## alternative hypothesis: one model is inconsistent",
    "crumbs": [
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>パネル分析</span>"
    ]
  },
  {
    "objectID": "10-panel.html#クラスターロバスト分散",
    "href": "10-panel.html#クラスターロバスト分散",
    "title": "11  パネル分析",
    "section": "11.6 クラスターロバスト分散",
    "text": "11.6 クラスターロバスト分散\n固定効果モデルにおいて、分散不均一が疑われる場合、クラスターロバスト分散を用いる。 時間効果がない固定効果モデル (gi) について、クラスターロバスト標準誤差を計算するには、coeftest() 関数と vcovHC() 関数を組み合わせて使用する。 coeftest(gi, vcov=vcovHC(gi, type=\"sss\")) コマンドで、type=\"sss\" を指定したクラスターロバスト分散を用いた係数検定を実行する。\n\ncoeftest(gi,vcov=vcovHC(gi,type=\"sss\"))\n## \n## t test of coefficients:\n## \n##         Estimate Std. Error t value  Pr(&gt;|t|)    \n## value   0.110124   0.015156  7.2660 9.596e-12 ***\n## capital 0.310065   0.052618  5.8927 1.726e-08 ***\n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n時間効果モデル (gi2) についても同様に、クラスターロバスト標準誤差を計算できる。 coeftest(gi2, vcov=vcovHC(gi2, type=\"sss\")) コマンドで、時間効果モデルにおけるクラスターロバスト分散を用いた係数検定を実行する。\n\ncoeftest(gi2,vcov=vcovHC(gi2,type=\"sss\"))\n## \n## t test of coefficients:\n## \n##         Estimate Std. Error t value  Pr(&gt;|t|)    \n## value   0.117716   0.010263 11.4697 &lt; 2.2e-16 ***\n## capital 0.357916   0.045367  7.8893  3.62e-13 ***\n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nSTATA の計算結果に合わせるには、個別固定効果モデルに年ダミーを明示的に追加する必要がある。 update(gi, .~. + factor(year)) コマンドで、モデル gi に年ダミーを追加して更新し、git に格納する。 その後 coeftest(git, vcov=vcovHC(git, type=\"sss\")) コマンドで、クラスターロバスト分散を用いた係数検定を実行する。 gi2 と git のどちらを採用するかによって結果が変わってしまうので注意されたい。\n\ngit &lt;- update(gi, .~. + factor(year))\ncoeftest(git,vcov=vcovHC(git,type=\"sss\"))\n## \n## t test of coefficients:\n## \n##                    Estimate Std. Error t value  Pr(&gt;|t|)    \n## value              0.117716   0.010794 10.9055 &lt; 2.2e-16 ***\n## capital            0.357916   0.047715  7.5012 3.424e-12 ***\n## factor(year)1936 -19.197405  20.640669 -0.9301 0.3536580    \n## factor(year)1937 -40.690009  33.190087 -1.2260 0.2219160    \n## factor(year)1938 -39.226404  15.692472 -2.4997 0.0133837 *  \n## factor(year)1939 -69.470288  26.923231 -2.5803 0.0107211 *  \n## factor(year)1940 -44.235085  17.323706 -2.5534 0.0115505 *  \n## factor(year)1941 -18.804463  17.797543 -1.0566 0.2922130    \n## factor(year)1942 -21.139792  14.125147 -1.4966 0.1363608    \n## factor(year)1943 -42.977623  12.509017 -3.4357 0.0007437 ***\n## factor(year)1944 -43.098772  10.965103 -3.9305 0.0001234 ***\n## factor(year)1945 -55.683040  15.159383 -3.6732 0.0003212 ***\n## factor(year)1946 -31.169284  20.858408 -1.4943 0.1369549    \n## factor(year)1947 -39.392242  26.363118 -1.4942 0.1369835    \n## factor(year)1948 -43.716514  38.769856 -1.1276 0.2610913    \n## factor(year)1949 -73.495099  38.147491 -1.9266 0.0557069 .  \n## factor(year)1950 -75.896112  36.695524 -2.0683 0.0401383 *  \n## factor(year)1951 -62.480912  49.279892 -1.2679 0.2065854    \n## factor(year)1952 -64.632341  51.417852 -1.2570 0.2104874    \n## factor(year)1953 -67.717966  43.622288 -1.5524 0.1224442    \n## factor(year)1954 -93.526221  31.637576 -2.9562 0.0035603 ** \n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n11.6.1 分散不均一の検定\n固定効果モデルにおいて、分散不均一かどうかを検定するには、Breusch-Pagan 検定を実施する。 bptest() 関数を使用して、企業ダミーを含むモデルで検定を行う。 bptest(inv ~ value + capital + factor(firm), data=pdata) コマンドで、個別固定効果モデルの分散不均一性を検定する。\n\nbptest(inv ~ value + capital + factor(firm), data=pdata)\n## \n##  studentized Breusch-Pagan test\n## \n## data:  inv ~ value + capital + factor(firm)\n## BP = 85.836, df = 11, p-value = 1.086e-13\n\n時間効果モデルの場合、企業ダミーと年ダミーの両方を含めて検定を行う。 bptest(inv ~ value + capital + factor(firm) + factor(year), data=pdata) コマンドで、時間効果モデルの分散不均一性を検定する。\n\nbptest(inv ~ value + capital + factor(firm) + factor(year),data=pdata)\n## \n##  studentized Breusch-Pagan test\n## \n## data:  inv ~ value + capital + factor(firm) + factor(year)\n## BP = 97.357, df = 30, p-value = 4.833e-09",
    "crumbs": [
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>パネル分析</span>"
    ]
  },
  {
    "objectID": "01-base.html",
    "href": "01-base.html",
    "title": "2  R の基本",
    "section": "",
    "text": "2.1 電卓としての R\nR の基礎を学ぶには、次のオンライン教材が役立つ（2025 年時点）。\n日本語で要点を確認したい場合は、以下のリソースが便利である。\n動画教材としては、ドットインストールの「はじめての R プログラミング」講座（13 本、合計約 40 分）が 2024 年以降も公開されており、基本編は無料で視聴できる。\nhttp://dotinstall.com/lessons/basic_r\nこのほかにも、Posit 公式チャンネルや国内コミュニティが公開する YouTube 動画が随時更新されているため、興味のあるトピックで検索してみるとよい。\nR は電卓としても利用できる。 代表的な算術演算子を以下に示す。\n演算は一般的な優先順位に従って処理されるが、() で囲めば計算の順序を明示的に指定できる。\n5 + 2\n## [1] 7\n5 - 2\n## [1] 3\n5 * 2\n## [1] 10\n5 / 2\n## [1] 2.5\n5 ^ 2\n## [1] 25\n5 ** 2\n## [1] 25\n5 %% 2\n## [1] 1\n5 %/% 2\n## [1] 2",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>R の基本</span>"
    ]
  },
  {
    "objectID": "01-base.html#電卓としての-r",
    "href": "01-base.html#電卓としての-r",
    "title": "2  R の基本",
    "section": "",
    "text": "演算子\n説明\n例\n\n\n\n\n+\n足し算\n5 + 2 = 7\n\n\n-\n引き算\n5 - 2 = 3\n\n\n*\n掛け算\n5 * 2 = 10\n\n\n/\n割り算\n5 / 2 = 2.5\n\n\n^, **\nべき算\n5 ^ 2 = 25, 5 ** 2 = 25\n\n\n%%\n割り算の余り\n5 %% 2 = 1\n\n\n%/%\n割り算の切り下げ\n5 %/% 2 = 2",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>R の基本</span>"
    ]
  },
  {
    "objectID": "01-base.html#関数電卓としての-r",
    "href": "01-base.html#関数電卓としての-r",
    "title": "2  R の基本",
    "section": "2.2 関数電卓としての R",
    "text": "2.2 関数電卓としての R\nR は関数電卓のようにさまざまな関数を呼び出して計算できる。たとえば以下の関数がある。\n\n\n\n関数\n説明\n\n\n\n\nsqrt()\n平方根 \\(\\sqrt{\\cdot}\\)\n\n\nexp()\n指数\n\n\nlog()\n対数\n\n\nfactorial()\n階乗\n\n\nchoose()\n組み合わせ\n\n\nabs()\n絶対値\n\n\nround()\n四捨五入\n\n\nfloor()\n切り下げ\n\n\nceiling()\n切り上げ\n\n\n\n\nsqrt(10)\n## [1] 3.162278\nexp(10)\n## [1] 22026.47\nlog(10)\n## [1] 2.302585\nfactorial(4)\n## [1] 24\nchoose(4,2)\n## [1] 6\nabs(-10)\n## [1] 10\nround(3.5)\n## [1] 4\nfloor(3.5)\n## [1] 3\nceiling(3.5)\n## [1] 4\n\n関数に渡す値は引数と呼ばれる。 組み合わせを計算する関数 choose の引数は 2 つあり、複数の引数は , で区切る。 引数の順序は、名前を明示すれば入れ替えられる。\n\nchoose(4, 2)\n## [1] 6\nchoose(n=4, k=2)\n## [1] 6\nchoose(k=2, n=4)\n## [1] 6\n\n引数によっては省略しても既定値が自動的に補われることがある。 詳細は関数ごとのヘルプを参照するとよい。\nたとえば choose のヘルプは次のように参照できる。\n\nhelp(choose)\n?choose\n\nで確認できる。\nヘルプには関数の説明、使用例、引数の既定値などがまとまっている。 RStudio を利用している場合は、ヘルプペインに整形されたドキュメントが表示される。",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>R の基本</span>"
    ]
  },
  {
    "objectID": "01-base.html#r-の型",
    "href": "01-base.html#r-の型",
    "title": "2  R の基本",
    "section": "2.3 R の型",
    "text": "2.3 R の型\nR では値に型 (type) があり、数値 (numeric)、文字列 (character)、論理値 (logical) など1が用意されている。 多くの言語と異なり、型をあらかじめ宣言しなくても自動的に決まる。\n数値には整数 (integer) や、実数をコンピュータ上で扱う倍精度浮動小数点数 (double) など2が含まれる。 整数か倍精度浮動小数点数かは自動的に振り分けられるが、数字の後ろに L を付けて整数を明示することもできる。\n文字列は \" (ダブルクォーテーション) もしくは ' (シングルクォーテーション) で囲む。 TRUE もしくは FALSE を取る値は論理値 (logical) と呼ばれる。省略して T や F と表せるが、混乱を招きやすいので推奨しない。\n値の型は関数 typeof() で確認できる。\n\ntypeof(3)\n## [1] \"double\"\ntypeof(3L)\n## [1] \"integer\"\ntypeof(\"3\")\n## [1] \"character\"\ntypeof(TRUE)\n## [1] \"logical\"\ntypeof(FALSE)\n## [1] \"logical\"\ntypeof(T)\n## [1] \"logical\"\ntypeof(F)\n## [1] \"logical\"\n\nオブジェクトのクラス（統計的な型付け）を確認するには class() を使う。 より複雑なオブジェクトでは typeof() と class() の結果が異なることもある点を覚えておきたい。\n特殊な値として、無限大を表す Inf、非数を表す NaN、欠損値を表す NA、空を表す NULL がある。 Inf と NaN は数値として分類され、NA の型は論理値として扱われる。 また、NULL は独自の型として扱われる。 NaN は 0 を 0 で割ったときのように値が定まらない計算で現れる。 NA はデータが欠損している場合に使われ、数値・文字列など別の型の NA も存在する。\n\n1/0\n## [1] Inf\ntypeof(1/0)\n## [1] \"double\"\n0/0\n## [1] NaN\ntypeof(0/0)\n## [1] \"double\"\ntypeof(NA)\n## [1] \"logical\"\ntypeof(NULL)\n## [1] \"NULL\"",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>R の基本</span>"
    ]
  },
  {
    "objectID": "01-base.html#変数",
    "href": "01-base.html#変数",
    "title": "2  R の基本",
    "section": "2.4 変数",
    "text": "2.4 変数\n値は変数 (variable) に代入すると再利用できる。 R では代入のことを付値 (assign) といい、次のように実行する。\n\nx &lt;- 4 \n4 -&gt; x\nx = 4\nassign(\"x\",4)\n\n多くのプログラミング言語では 3 番目の方法のみが一般的だが、 R では最初の方法が推奨されている。3\n代入した値は、その変数名を入力すれば確認できる。 代入と同時に確認したい場合は式全体を丸括弧で囲む。\n\nx\n## [1] 4\n(x&lt;-3)\n## [1] 3\n\n変数名は記号や数字で始まらなければ、ほぼ自由に付けられる。 アルファベットは大文字と小文字が区別される点に注意する。 日本語も変数名に使えるが、環境によって文字コードが異なるため避けるのが無難である。 アンダースコア _ やピリオド . は途中に入れられるが、a.b と a_b は別の名前として扱われる。\n予約語である if など一部の名前4は変数名に使えずエラーになる。 一方で pi のように既存の組み込み変数を上書きすることは可能である。\n\npi\n## [1] 3.141593\npi &lt;- 3\npi\n## [1] 3\n\n関数 objects() を使うと、現在存在するオブジェクトを確認できる。 ls() も同じ結果を返すエイリアスである。 R は変数や関数をすべてオブジェクトとして扱う言語である。 既存のオブジェクトを削除するには rm() を使う。 組み込み変数を上書きしていても、pi を削除すれば元の値が復活する。\n\nrm(pi)\npi\n## [1] 3.141593\n\nさらに、すべてのオブジェクトを削除したい場合は rm(list=ls(all=TRUE)) と入力する。",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>R の基本</span>"
    ]
  },
  {
    "objectID": "01-base.html#パッケージ",
    "href": "01-base.html#パッケージ",
    "title": "2  R の基本",
    "section": "2.5 パッケージ",
    "text": "2.5 パッケージ\nR ではパッケージを導入することで機能を拡張できる。\nパッケージ pkg を導入する際は次を 1 度だけ実行する。\n\ninstall.packages(\"pkg\")\n\nオプション dependencies = TRUE を指定すると、依存パッケージもまとめて導入される。 インストールは 1 度実行すればよいが、R を起動し直すたびに library() などで読み込む必要がある点に注意する。\nパッケージ pkg が導入済みであれば、そのパッケージ内のコマンド cmd を実行するには\n\npkg::cmd\n\nと、パッケージ名とコマンド名の間に :: を挟む必要がある。 この書き方は、パッケージを読み込まずに特定の関数だけを呼び出したいときや、名前が衝突したときに便利である。\nまた、事前に library(pkg) や require(pkg) を実行しておけば、 関数呼び出し時の pkg:: を省略できる。 複数のパッケージに同名のコマンドが含まれる場合は、 後から library や require で読み込んだパッケージが優先される点に注意する。\nlibrary と require の使い方はほとんど同じだが、 require では次のようにパッケージがなければインストールするといった書き方ができる。\n\nif (!require(lattice)){\n  install.packages(\"lattice\")\n  require(lattice)\n} \n\nlibrary() はパッケージが見つからない場合にエラーで処理を止めるのに対し、require() は失敗すると FALSE を返し、処理を続行できる。 私自身は慣れもあって library を使うことが多い。",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>R の基本</span>"
    ]
  },
  {
    "objectID": "01-base.html#footnotes",
    "href": "01-base.html#footnotes",
    "title": "2  R の基本",
    "section": "",
    "text": "他にも日付 (Date) やバイナリ (raw) がある。↩︎\n他にも複素数 (complex) がある。↩︎\n 例えば以下を参照されたい: http://adv-r.had.co.nz/Style.html↩︎\nbreak, else, FALSE, for, function, if, in, Inf, NA, NaN, next, NULL, repeat, TRUE, while など↩︎",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>R の基本</span>"
    ]
  },
  {
    "objectID": "08-regression2.html",
    "href": "08-regression2.html",
    "title": "9  現代的仮定のもとでの最小二乗法",
    "section": "",
    "text": "9.1 正規性の仮定について\n前節では以下の仮定を置いていた。\nここではこれらの仮定を緩めた場合に、推定結果や検定にどのような影響が生じるかを確認する。\nまずは仮想データを用いて状況を設定する。\n散布図を描くと次のようになる。 散布図を描く際には、点の雲が線形からどの程度離れているかを目視で把握しておくと、後で外れ値や非線形性を疑う際の手がかりになる。\n標本サイズが十分大きければ、誤差項 \\(u_i\\) が正規分布でなくとも中心極限定理により推定量は正規分布に近似される。これは大標本を扱う実務上、正規性の仮定が多少破れていても t 検定や信頼区間が大きく崩れない理由づけになる。\nここで係数がゼロかどうかを検定するときは AER パッケージの coeftest() を用いると便利である。推定した lm オブジェクトと分散共分散行列の指定を渡すだけで、t 統計量と p 値を表示してくれる。 まず lm() 関数を用いて2つのモデルを推定する。 fm1 は説明変数 x、ダミー変数 w、およびその交差項を含むモデル、fm0 は x のみを含むモデルである。\nfm1 &lt;- lm(y~x*w,data=df)\nfm0 &lt;- lm(y~x,data=df)\ncoeftest(fm1,df=Inf)\n## \n## z test of coefficients:\n## \n##             Estimate Std. Error z value  Pr(&gt;|z|)    \n## (Intercept) 11.13652    0.22886 48.6614 &lt; 2.2e-16 ***\n## x            1.52569    0.42883  3.5578 0.0003739 ***\n## wT          -1.46108    0.34353 -4.2531 2.108e-05 ***\n## x:wT         1.19787    0.60927  1.9661 0.0492889 *  \n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\ncoeftest() 関数は係数の検定を行う関数である。 オプション df=Inf を指定すると、ティー分布の代わりに標準正規分布（自由度無限大のティー分布）を用いた検定を実行する。 これは大標本を前提とした漸近的な検定である。 ただしサンプルサイズが大きければ、通常のt検定でも大きく結果は変わらない。\n複数係数の同時検定では、F 統計量に制約数を掛けたものが自由度を制約数とするカイ二乗分布に従う。この性質を利用すると、漸近的な Wald 検定としてカイ二乗ベースの判断が行える。 R では waldtest() を用いれば簡単に検定できる。 waldtest() は制約付きモデル（fm0）と制約なしモデル（fm1）を比較し、複数係数の同時仮説を検定する関数である。\nwaldtest(fm0,fm1,test=\"Chisq\")\n## Wald test\n## \n## Model 1: y ~ x\n## Model 2: y ~ x * w\n##   Res.Df Df  Chisq Pr(&gt;Chisq)    \n## 1     98                         \n## 2     96  2 29.318  4.302e-07 ***\n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\nオプション test=\"Chisq\" を指定すると、F検定統計量に制約の数を乗じた統計量が自由度が制約数のカイ二乗分布にしたがうことを利用した検定を実行する。 これは大標本での漸近的な検定である。\nサンプルサイズが十分大きければ、F 検定でも同様の結論が得られる。\nオプションを省略すると標準の F 検定が実行される。\nwaldtest(fm0,fm1)\n## Wald test\n## \n## Model 1: y ~ x\n## Model 2: y ~ x * w\n##   Res.Df Df      F    Pr(&gt;F)    \n## 1     98                        \n## 2     96  2 14.659 2.782e-06 ***\n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n出力には F 統計量とその p 値が含まれる。\nこれは anova() の結果と同じで、2 つのモデルの当てはまりを比較している。\nanova(fm0,fm1)\n## Analysis of Variance Table\n## \n## Model 1: y ~ x\n## Model 2: y ~ x * w\n##   Res.Df    RSS Df Sum of Sq      F    Pr(&gt;F)    \n## 1     98 93.745                                  \n## 2     96 71.813  2    21.931 14.659 2.782e-06 ***\n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\nanova() 関数もモデルを比較してF検定を行うための関数である。\n複数制約の検定としてLM検定（Lagrange Multiplier test）を用いる方法もある。まず制約付きモデルの残差を使って補助回帰を組み、その決定係数を基に統計量を構成する。 制約付きの回帰分析を実行し、その残差を制約なしのモデルの説明変数に回帰する。 残差回帰の決定係数に観測数を掛けた統計量は、自由度を制約数とするカイ二乗分布に従う。\n以下ではLM統計量を手動で計算してみる。\nlmt &lt;- lm(I(resid(fm1))~w*x,data=df)\n(lmt &lt;- nrow(df)*summary(lmt)$r.squared)\n## [1] 4.985178e-30\n1-pchisq(lmt,df=1)\n## [1] 1\n最初の行では fm1 の残差を目的変数にして w*x を説明変数に回帰している。 続いて、決定係数に観測数を掛けてLM統計量を計算する。 最後に pchisq() 関数で自由度1のカイ二乗分布を用いてp値を算出する。",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>現代的仮定のもとでの最小二乗法</span>"
    ]
  },
  {
    "objectID": "08-regression2.html#誤差項と説明変数が独立の仮定について",
    "href": "08-regression2.html#誤差項と説明変数が独立の仮定について",
    "title": "9  現代的仮定のもとでの最小二乗法",
    "section": "9.2 誤差項と説明変数が独立の仮定について",
    "text": "9.2 誤差項と説明変数が独立の仮定について\n誤差項 \\(u_i\\) と説明変数 \\(x_i\\) の独立性が満たされなくても、互いに無相関であれば最小二乗推定量は一致性を保つ。 ただしその場合でも不偏性は保証されない。 また線形推定量の中で最小分散とは限らない。1 さらに、独立性が崩れると従来の標準誤差推定量は一致性を失う。\nしかし別の分散推定を用いれば、推定量は依然として正規分布に近似できることが知られている。2 すなわち説明変数と誤差項が無相関であっても独立とまでは言えない状況では、分散をロバストに推定する必要がある。 この代替的な分散をロバスト分散と呼ぶ。誤差の分散が説明変数によって変わるような状況（不均一分散）でも、推定係数の信頼区間を信頼できるようにするための工夫である。\nR では AER パッケージを使うとロバスト分散を簡単に計算できる。vcovHC() 関数を coeftest() 関数に渡すだけで、White（1980）型の頑健標準誤差が得られる。 次のように coeftest() 関数を実行すればよい。\n\ncoeftest(fm1,vcov=vcovHC)\n## \n## t test of coefficients:\n## \n##             Estimate Std. Error t value  Pr(&gt;|t|)    \n## (Intercept) 11.13652    0.26839 41.4940 &lt; 2.2e-16 ***\n## x            1.52569    0.42885  3.5577 0.0005834 ***\n## wT          -1.46108    0.35493 -4.1166 8.138e-05 ***\n## x:wT         1.19787    0.56928  2.1042 0.0379768 *  \n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\ncoeftest() 関数のオプション vcov=vcovHC を指定することで、不均一分散に頑健な（heteroskedasticity-consistent）標準誤差を用いた検定が実行される。 vcovHC() 関数は分散共分散行列をロバスト推定する関数である。\nこの結果で標準誤差が変化していることが分かる。 ただしSTATAのデフォルト設定とは若干異なる。 STATAと同じにするには\n\ncoeftest(fm1,vcov=vcovHC(fm1,type=\"HC1\"))\n## \n## t test of coefficients:\n## \n##             Estimate Std. Error t value  Pr(&gt;|t|)    \n## (Intercept) 11.13652    0.26173 42.5495 &lt; 2.2e-16 ***\n## x            1.52569    0.41510  3.6755 0.0003911 ***\n## wT          -1.46108    0.34589 -4.2241 5.458e-05 ***\n## x:wT         1.19787    0.55089  2.1744 0.0321304 *  \n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nとしなければならない。 オプション type=\"HC1\" は小標本補正を施したロバスト分散推定量を指定している。 これはSTATAの既定設定と同じである。\nまたティー分布でなく正規分布とすることもできる。\n\ncoeftest(fm0,vcov=vcovHC,df=Inf)\n## \n## z test of coefficients:\n## \n##             Estimate Std. Error z value  Pr(&gt;|z|)    \n## (Intercept) 10.52955    0.20866  50.462 &lt; 2.2e-16 ***\n## x            1.96035    0.31974   6.131 8.731e-10 ***\n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nオプション df=Inf を追加することで、標準正規分布を用いた検定を実行する。\n複数の係数についての検定は waldtest() 関数を実行すればよい。\n\nwaldtest(fm0,fm1,vcov=vcovHC)\n## Wald test\n## \n## Model 1: y ~ x\n## Model 2: y ~ x * w\n##   Res.Df Df     F   Pr(&gt;F)    \n## 1     98                      \n## 2     96  2 13.53 6.66e-06 ***\n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nオプション vcov=vcovHC を指定することで、ロバスト分散を用いたワルド検定を実行する。\n先の結果はF検定であるが、カイ二乗検定を実施するには以下を実行すればよい。\n\nwaldtest(fm0,fm1,vcov=vcovHC, test=\"Chisq\")\n## Wald test\n## \n## Model 1: y ~ x\n## Model 2: y ~ x * w\n##   Res.Df Df  Chisq Pr(&gt;Chisq)    \n## 1     98                         \n## 2     96  2 27.059  1.331e-06 ***\n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nオプション test=\"Chisq\" を追加することで、F統計量の代わりにカイ二乗統計量を用いた検定を実行する。\n近年の estimatr パッケージを使うと lm_robust() 関数でロバスト分散を持つ推定を直接実行できる。推定と同時にヘテロスケダスティシティ対策の標準誤差が得られるので、コードを簡潔に保ちたい場合に有用である。\n\nfm2&lt;- lm_robust(y~x*w,data=df)\nsummary(fm2)\n## \n## Call:\n## lm_robust(formula = y ~ x * w, data = df)\n## \n## Standard error type:  HC2 \n## \n## Coefficients:\n##             Estimate Std. Error t value  Pr(&gt;|t|) CI Lower CI Upper DF\n## (Intercept)   11.137     0.2623  42.452 5.127e-64 10.61579  11.6572 96\n## x              1.526     0.4176   3.653 4.218e-04  0.69675   2.3546 96\n## wT            -1.461     0.3468  -4.213 5.690e-05 -2.14947  -0.7727 96\n## x:wT           1.198     0.5543   2.161 3.317e-02  0.09762   2.2981 96\n## \n## Multiple R-squared:  0.4258 ,    Adjusted R-squared:  0.4078 \n## F-statistic: 32.01 on 3 and 96 DF,  p-value: 1.983e-14\n\nlm_robust() 関数は回帰分析を実行し、デフォルトでロバスト標準誤差を計算する。 これにより lm() 関数と coeftest() 関数を別々に呼び出す手間が省ける。\nse_type = \"stata\" を指定するとSTATAと同じ補正が掛けられる。\nまた以下のオプションをつければ分散均一の場合も計算できる。\n\nfm3&lt;- lm_robust(y~x*w,data=df,se_type = \"classical\")\nsummary(fm3)\n## \n## Call:\n## lm_robust(formula = y ~ x * w, data = df, se_type = \"classical\")\n## \n## Standard error type:  classical \n## \n## Coefficients:\n##             Estimate Std. Error t value  Pr(&gt;|t|) CI Lower CI Upper DF\n## (Intercept)   11.137     0.2289  48.661 1.858e-69 10.68224  11.5908 96\n## x              1.526     0.4288   3.558 5.831e-04  0.67448   2.3769 96\n## wT            -1.461     0.3435  -4.253 4.897e-05 -2.14299  -0.7792 96\n## x:wT           1.198     0.6093   1.966 5.218e-02 -0.01152   2.4073 96\n## \n## Multiple R-squared:  0.4258 ,    Adjusted R-squared:  0.4078 \n## F-statistic: 23.73 on 3 and 96 DF,  p-value: 1.423e-11\n\nオプション se_type = \"classical\" を指定すると、通常の（ロバストでない）標準誤差を計算する。 これは lm() 関数の結果と同じである。",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>現代的仮定のもとでの最小二乗法</span>"
    ]
  },
  {
    "objectID": "08-regression2.html#分散均一の検定",
    "href": "08-regression2.html#分散均一の検定",
    "title": "9  現代的仮定のもとでの最小二乗法",
    "section": "9.3 分散均一の検定",
    "text": "9.3 分散均一の検定\n誤差項が説明変数と独立な場合と、単に無相関であるだけの場合では標準誤差の推定方法が異なる。 正確には、条件付き分散が説明変数に依存するか否かが標準誤差の推定量を分ける条件となる。実務で言えば、残差の分布を見て異常に広がりが大きい領域があるかどうかを確認することが、ロバスト手法を使うべきかどうかの判断材料になる。 この性質を分散均一（homoskedasticity）という。\n誤差項の分散が均一かどうかは検定可能である。 有名な検定方法としてBP（Breusch-Pagan）検定というものがある。 BP検定は帰無仮説が分散均一で、対立仮説が分散が説明変数と線形関係になっている場合の検定である。\n残差の自乗を被説明変数として回帰分析を行い、その決定係数に観測数をかけたものが検定統計量となる。 以下ではBP検定統計量を手動で計算している。\n\nbpt &lt;- lm(I(resid(fm1)^2)~w*x,data=df)\n(bpt &lt;-nrow(df)*summary(bpt)$r.squared)\n## [1] 4.88153\n1-pchisq(bpt,df=3)\n## [1] 0.1806805\n\n最初の行では、fm1 の残差の二乗（resid(fm1)^2）を被説明変数とし、w*x を説明変数として回帰分析を実行している。 I() 関数は、数式内で算術演算を実行するために用いる。 2行目では、その決定係数に観測数を掛けてBP検定統計量を計算している。 3行目では、自由度3（説明変数の数）のカイ二乗分布のもとでP値を計算している。\nここでの例ではP値が5%を超えているので帰無仮説を棄却できないため、分散均一を仮定してよいことが示唆されている。\nR では bptest() 関数を用いて簡単にBP検定を実施できる。\n\nbptest(fm1)\n## \n##  studentized Breusch-Pagan test\n## \n## data:  fm1\n## BP = 4.8815, df = 3, p-value = 0.1807\n\nbptest() 関数は自動的にBP検定統計量とP値を計算してくれる。\nこれまでのBP検定は誤差項の分散が説明変数の線形関係にあることを暗黙に仮定している。 非線形性を考慮するために説明変数の二次項を導入した分散不均一性の検定をホワイト検定という。 説明変数が複数ある場合ホワイト検定は煩雑になるため、被説明変数の予測値を使って計算することがある。 そのときホワイト検定は以下で実施する。\n\nwht &lt;- lm(I(resid(fm1)^2)~fitted(fm1)+I(fitted(fm1)^2),data=df)\n(wht &lt;- nrow(df)*summary(wht)$r.squared)\n## [1] 4.460125\n1-pchisq(wht,df=2)\n## [1] 0.1075217\n\n最初の行では、残差の二乗を被説明変数とし、予測値（fitted(fm1)）とその二乗を説明変数として回帰分析を実行している。 これにより分散の非線形性を検出できる。 2行目では、その決定係数に観測数を掛けてホワイト検定統計量を計算している。 3行目では、自由度2のカイ二乗分布のもとでP値を計算している。\nホワイト検定でも分散均一が示唆されている。\nもしくは bptest() 関数に予測値とその二乗を指定して実行することもできる。\n\nbptest(fm1,~fitted(fm1)+I(fitted(fm1)^2))\n## \n##  studentized Breusch-Pagan test\n## \n## data:  fm1\n## BP = 4.4601, df = 2, p-value = 0.1075\n\nこの関数は上記の手動計算と同じ結果を返す。\nこのように分散均一性は検定することが可能であるが、そもそも分散均一が疑われる場合は、ロバスト分散で推定するので十分であるため最近の実証分析ではこの検定は実施されない。",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>現代的仮定のもとでの最小二乗法</span>"
    ]
  },
  {
    "objectID": "08-regression2.html#footnotes",
    "href": "08-regression2.html#footnotes",
    "title": "9  現代的仮定のもとでの最小二乗法",
    "section": "",
    "text": "正確にいえば、不偏推定量を得るためには条件付き期待値が説明変数に依存しないことが必要である。また線形推定量のなかで最小分散を実現するには、条件付き分散が説明変数に依存しないことが求められる。↩︎\n正確には観測される変数に 4 次のモーメントが存在するという仮定が必要となる。この仮定の直感的な意味は極端な外れ値が存在しないことである。↩︎",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>現代的仮定のもとでの最小二乗法</span>"
    ]
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "R と RStudio",
    "section": "",
    "text": "1 はじめに",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>R と RStudio</span>"
    ]
  },
  {
    "objectID": "index.html#r-とは",
    "href": "index.html#r-とは",
    "title": "R と RStudio",
    "section": "1.1 R とは",
    "text": "1.1 R とは\nRは統計・データ解析・統計グラフ作成のためのオープンソースソフトである。 基本的に無料で使える。 最近はその統合環境であるRStudioがデファクトスタンダードとなっている。 さらにそれらは RStudio Cloud (https://rstudio.cloud/) としてクラウド環境でも使用できる。 ここではまずローカル環境でR言語をいれる方法を解説する。 第2節にRStudioのローカル環境での導入方法を述べる。\nRStudio Cloud　については直接サイトに行き、そのヘルプを見て導入すれば良いだろう。 日本語の解説としては以下が参考になるだろう。\nhttps://qiita.com/ZaKama/items/937e6d7fa25f6d3cb385",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>R と RStudio</span>"
    ]
  },
  {
    "objectID": "index.html#r-のインストール",
    "href": "index.html#r-のインストール",
    "title": "R と RStudio",
    "section": "1.2 R のインストール",
    "text": "1.2 R のインストール\nRをインストールするには\nhttps://cran.r-project.org/\nにいき、該当機種のファイルをダウンロードする。 ダウンロードしたあとに実行すればインストールされる。\nWindows の場合、32bit か 64bit を選択する。 最近のパソコンの CPU は 64bit と考えられるが、 どちらかわからなければ 32bit にしておけばよい。\nUbuntu なら ppa を使って導入してもよい。\nsudo add-apt-repository ppa:marutter/rrutter\nsudo apt-get update\nsudo apt-get install r-base r-base-dev",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>R と RStudio</span>"
    ]
  },
  {
    "objectID": "index.html#r-の設定",
    "href": "index.html#r-の設定",
    "title": "R と RStudio",
    "section": "1.3 R の設定",
    "text": "1.3 R の設定\n設定ファイル .Rprofile をホームディレクトリに作成すれば、設定を変更できる。 ホームディレクトリはユーザー名が kenji のとき、Windows なら通常 C:\\Users\\kenji である。バックスラッシュ \\ は \\(\\yen\\) と読み替えて頂きたい。 最初は .Rprofile を特に作成しなくても大丈夫である。\nWindowsを利用して日本語のユーザー名を使用している場合に使えない。 Rを実施するためのユーザー名を別に作成するか、アカウント名を変えた方がよいだろう。 なお日本語ユーザー名のままファイルパスを英語化するには以下を参考されたい:\nhttps://clean-copy-of-onenote.hatenablog.com/entry/R_japanese_username",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>R と RStudio</span>"
    ]
  },
  {
    "objectID": "index.html#r-の使い方",
    "href": "index.html#r-の使い方",
    "title": "R と RStudio",
    "section": "1.4 R の使い方",
    "text": "1.4 R の使い方\nWindows だとコマンドプロンプトから R と入力して立ち上げるか、R のアイコンをダブルクリックすると、Rコンソールと言われる画面が現れる。 コマンドプロンプトからだと最初の表示が文字化けしている可能性があるが、その後の起動に問題ないはずである。 アイコンがなければ、Winキーを押した後、rgui と入力すれば起動できる。 Mac や Ubuntu だとターミナルから R と入力して起動できる。\n立ち上げた後、コンソールから そこにコマンドを入力すると、その結果が直後に出力される。 終了には q() とする。 作業スペースを保存するかと聞かれたなら、No を意味する n を選択する。\nコマンド入力中、最後の括弧を付け忘れたり、正しく実行ができないときがある。 たとえば、rnorm(5 としてEnterキーを押せば、次の行に + とでてくる。 ここでは正しく ) を付けて再度Enterキーを押せば正しく実行されるが、 ときにはどれを入力すれば正しく実行されるかわからない一方で、単にEnterを押すだけだと、再度入力を求められることがある。 そうしたとときは通常左上にあるエスケープキー (ESC) を押せば途中入力がキャンセルされる。\nR はRコンソールから対話式にコマンドを入力していく方法と、 拡張子 R のスクリプトファイルを実行していくやり方がある。 実行履歴を記録するためにスクリプトファイルを作成していくやり方を推奨する。\nスクリプトファイル project.R を Rコンソールから実行するには、\nsource(\"project.R\")\nとすればよい。\nR外部のコマンドプロンプトから実行するには\nRscript project.R\nとすればよい。起動できないときには、 環境変数の PATH にRの実行ファイルの場所が登録されていない可能性がある。\nまた外部ファイルを導入する際やファイルを外部出力する際には、現在の作業ディレクトリに気をつけなければならない。 現在の作業ディレクトリの場所はRコンソールから\ngetwd()\nとすれば、確認できる。Windows だと通常の表記と異なっていることに注意されたい。\n作業ディレクトリの指定は以下のようにする。\nsetwd(PATH)\nWindows のとき指定の仕方に注意が必要である。 たとえば作業ディレクトリが C:\\Users\\kenji\\work\\project のとき、\nsetwd(\"C:/Users/kenji/work/project\")\nとなる。バックスラッシュ \\ (\\(\\yen\\)) を スラッシュ / に変更しなければならない。",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>R と RStudio</span>"
    ]
  },
  {
    "objectID": "03-vector.html",
    "href": "03-vector.html",
    "title": "4  ベクトル",
    "section": "",
    "text": "4.1 ベクトル\nR では同じ型の値を集めたものをベクトルという。 ベクトルは c()（concatenate の略）を用いて構成する。既存のベクトルを渡すと、ひと続きのベクトルとして結合される点にも注意する。\n(num&lt;-c(2,3,7,9))\n## [1] 2 3 7 9\n(chr &lt;- c(\"cat\",\"dog\",\"cow\"))\n## [1] \"cat\" \"dog\" \"cow\"\nベクトルには長さという属性 (attribute) が付く。length() で要素数を取得できるほか、str() を使えばオブジェクトの構造をまとめて確認できる。\nlength(num)\n## [1] 4\nlength(chr)\n## [1] 3\nベクトルはオブジェクトの基本単位であり、単一の値も長さ 1 のベクトルとみなせる。\n型が混在している場合は、自動的に最も表現力の高い型へ変換される。強制変換の優先順位は、おおむね「論理値 → 数値 → 文字列」の順と覚えておくとよい。 文字列が 1 つでも含まれると、すべて文字列に変換される。 数値と論理値が混在している場合は、論理値が数値に強制変換され、TRUE は 1、FALSE は 0 になる。\n(x&lt;- c(1,4))\n## [1] 1 4\ntypeof(x)\n## [1] \"double\"\n(y &lt;- c(2,FALSE,\"4\"))\n## [1] \"2\"     \"FALSE\" \"4\"\ntypeof(y)\n## [1] \"character\"\n(z &lt;- c(2,FALSE))\n## [1] 2 0\ntypeof(z)\n## [1] \"double\"",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>ベクトル</span>"
    ]
  },
  {
    "objectID": "03-vector.html#算術演算子",
    "href": "03-vector.html#算術演算子",
    "title": "4  ベクトル",
    "section": "4.2 算術演算子",
    "text": "4.2 算術演算子\n四則演算などの算術演算子は要素ごとに適用される。^ は累乗、%% は剰余、%/% は整数除算（切り捨て）を表す。\n\na&lt;-c(2,3,3,3)\nb&lt;-c(3,3,5,7)\na+b\n## [1]  5  6  8 10\na-b\n## [1] -1  0 -2 -4\na*b\n## [1]  6  9 15 21\na/b\n## [1] 0.6666667 1.0000000 0.6000000 0.4285714\na^b\n## [1]    8   27  243 2187\n\n片方がスカラーであっても、同じ長さのベクトルに再利用されて演算される。\n\na+2\n## [1] 4 5 5 5\na-2\n## [1] 0 1 1 1\na*2\n## [1] 4 6 6 6\na/2\n## [1] 1.0 1.5 1.5 1.5\na^2\n## [1] 4 9 9 9\n\n長さが異なるベクトル同士を演算する場合、短い方のベクトルが自動的にリサイクルされて長さを揃える。\n\nc&lt;-c(1,2)\na+c\n## [1] 3 5 4 5\na-c\n## [1] 1 1 2 1\na*c\n## [1] 2 6 3 6\na/c\n## [1] 2.0 1.5 3.0 1.5\na^c\n## [1] 2 9 3 9\n\nただし、短いベクトルの長さが長いベクトルの長さの約数でない場合は警告が表示される。",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>ベクトル</span>"
    ]
  },
  {
    "objectID": "03-vector.html#論理演算子",
    "href": "03-vector.html#論理演算子",
    "title": "4  ベクトル",
    "section": "4.3 論理演算子",
    "text": "4.3 論理演算子\n論理値を入力に取り、論理値を返す演算子を論理演算子という。 R では、否定 (!)、論理和 (|)、論理積 (&) などの演算子が用意されている。 これらの演算子も要素ごとに評価される。 || や && といった二重記号の演算子は、最初の要素のみを評価する短絡演算子であり、条件分岐で判定回数を抑えたいときに使う。\n\nlogic1 &lt;- c(TRUE, FALSE, FALSE)\nlogic2 &lt;- c(TRUE, TRUE, FALSE)\n!logic1\n## [1] FALSE  TRUE  TRUE\nlogic1 | logic2\n## [1]  TRUE  TRUE FALSE\nlogic1 & logic2\n## [1]  TRUE FALSE FALSE\n\nall() はすべての要素が TRUE かどうか、any() は少なくとも 1 つが TRUE かどうかを判定する。\n\nany(logic1)\n## [1] TRUE\nall(logic1)\n## [1] FALSE",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>ベクトル</span>"
    ]
  },
  {
    "objectID": "03-vector.html#比較演算子",
    "href": "03-vector.html#比較演算子",
    "title": "4  ベクトル",
    "section": "4.4 比較演算子",
    "text": "4.4 比較演算子\n2 つの値を比較して論理値を返す演算子を比較演算子という。 R では等しいかどうかを判定する ==、大小を判定する &gt; や &lt; などが用意されている。 これらもベクトルの要素ごとに評価される。\n\nvec1 &lt;- 1:4\nvec2 &lt;- c(2,1,3,4)\nvec1 == vec2\n## [1] FALSE FALSE  TRUE  TRUE\nvec1 &gt; vec2\n## [1] FALSE  TRUE FALSE FALSE\nvec1 &lt; vec2\n## [1]  TRUE FALSE FALSE FALSE\n\n不等号として !=（等しくない）、&gt;=（以上）、&lt;=（以下）も利用できる。\n\nvec1 != vec2 # !(vec1==vec2)\n## [1]  TRUE  TRUE FALSE FALSE\nvec1 &gt;= vec2 # (vec1 &gt; vec2 | vec1 == vec2)\n## [1] FALSE  TRUE  TRUE  TRUE\nvec1 &lt;= vec2 # (vec1 &lt; vec2 | vec1 == vec2)\n## [1]  TRUE FALSE  TRUE  TRUE\n\nスカラーとベクトルを比較する場合は、スカラーが再利用されて要素ごとに評価される。\n\nvec1 &gt; 2\n## [1] FALSE FALSE  TRUE  TRUE\n\n%in% 演算子を使うと、左側のベクトル要素が右側のベクトルに含まれているかを判定できる。返り値は論理値のベクトルで、元の長さと同じになる。\n\nvec1 %in% 4:5\n## [1] FALSE FALSE FALSE  TRUE",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>ベクトル</span>"
    ]
  },
  {
    "objectID": "03-vector.html#要素",
    "href": "03-vector.html#要素",
    "title": "4  ベクトル",
    "section": "4.5 要素",
    "text": "4.5 要素\nベクトルの要素は角括弧で取り出す。\n\nnum &lt;- c(2,3,7,9)\nnum[3]\n## [1] 7\n\n取り出すだけでなく、新しい値を代入することもできる。\n\nnum[3] &lt;- 500\nnum\n## [1]   2   3 500   9\n\n負のインデックスを指定すると、その位置の要素を除いたベクトルが得られる。\n\nnum[-3]\n## [1] 2 3 9\n\n複数の要素を同時に取り出すことも容易である。\n\nnum[c(1,4)]\n## [1] 2 9\n\n論理値ベクトルをインデックスとして使えば、条件に合致する要素のみを抽出できる。\n\nidx &lt;- c(TRUE,FALSE,TRUE,TRUE)\nnum[idx]\n## [1]   2 500   9\n\n比較演算子と組み合わせれば、条件式を直接インデックスに渡してフィルタリングできる。\n\n(num &gt; 4)\n## [1] FALSE FALSE  TRUE  TRUE\nnum[num &gt; 4]\n## [1] 500   9\n\n: 演算子で連続した整数ベクトルを生成し、その範囲を指定して抜き出すこともできる。非整数のステップや逆順が必要な場合は seq() を利用すると柔軟に制御できる。\n\n2:4\n## [1] 2 3 4\nnum[2:4]\n## [1]   3 500   9\n\nベクトルには名前属性を付与できる。\n\nvec &lt;- c(x= 3, y =3, z = 4)\n\n別の方法として次のように設定できる。\n\nnames(num) &lt;- letters[1:4]\n\n名前を付けると、文字列で要素を参照できる。\n\nvec[\"x\"]\n## x \n## 3\nnum[\"d\"]\n## d \n## 9\n\n現在の名前一覧は names() で取得でき、不要になった場合は names(num) &lt;- NULL のようにして削除する。",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>ベクトル</span>"
    ]
  },
  {
    "objectID": "03-vector.html#関数",
    "href": "03-vector.html#関数",
    "title": "4  ベクトル",
    "section": "4.6 関数",
    "text": "4.6 関数\nベクトルを引数に取る関数も多数用意されており、和や積などを簡単に計算できる。累積和（cumsum()）や累積積（cumprod()）は系列データの推移を追跡したいときに便利である。\n\nx&lt;-c(1,2,3,4,5)\nsum(x)\n## [1] 15\ncumsum(x)\n## [1]  1  3  6 10 15\nprod(x)\n## [1] 120\ncumprod(x)\n## [1]   1   2   6  24 120\n\n平均、中央値、分散、標準偏差といった統計量もワンライナーで求められる。\n\nx &lt;- c(x,10)\nmean(x)\n## [1] 4.166667\nmedian(x)\n## [1] 3.5\nvar(x)\n## [1] 10.16667\nsd(x)\n## [1] 3.188521\n\nベクトルを並べ替えたり、最小値・最大値やその位置を取得したりする関数も充実している。\n\nx &lt;- c(3,3,5,0)\nsort(x)\n## [1] 0 3 3 5\nsort(x,decreasing = TRUE)\n## [1] 5 3 3 0\nmin(x)\n## [1] 0\nmax(x)\n## [1] 5\nwhich.min(x)\n## [1] 4\nwhich.max(x)\n## [1] 3\n\n欠損値 NA が含まれている場合、mean() など多くの集計関数は既定の挙動として NA を返す。 集計から欠損を除外したいときは、na.rm = TRUE を指定する。\n\nx &lt;- c(4,2,NA,3)\nmean(x)\n## [1] NA\nmean(x, na.rm = TRUE)\n## [1] 3",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>ベクトル</span>"
    ]
  },
  {
    "objectID": "03-vector.html#規則的なベクトル",
    "href": "03-vector.html#規則的なベクトル",
    "title": "4  ベクトル",
    "section": "4.7 規則的なベクトル",
    "text": "4.7 規則的なベクトル\n1:5 のような規則的なベクトルを柔軟に作成するのに seq を用いるとよい。\n\n1:5\n## [1] 1 2 3 4 5\nseq(1, 5)\n## [1] 1 2 3 4 5\nseq(1, 5, by = 2)\n## [1] 1 3 5\nseq(1, 5, length.out = 4)\n## [1] 1.000000 2.333333 3.666667 5.000000\n\n繰り返しを作成することができる rep も覚えておくと便利である。\n\nrep(1, 5)\n## [1] 1 1 1 1 1\nrep(c(1, 2), times = 3)\n## [1] 1 2 1 2 1 2\nrep(c(1, 2), each = 3)\n## [1] 1 1 1 2 2 2\n\nまたアルファベットの文字列もあらかじめ組み込まれている。\n\nletters\n##  [1] \"a\" \"b\" \"c\" \"d\" \"e\" \"f\" \"g\" \"h\" \"i\" \"j\" \"k\" \"l\" \"m\" \"n\" \"o\" \"p\" \"q\" \"r\" \"s\"\n## [20] \"t\" \"u\" \"v\" \"w\" \"x\" \"y\" \"z\"\nLETTERS\n##  [1] \"A\" \"B\" \"C\" \"D\" \"E\" \"F\" \"G\" \"H\" \"I\" \"J\" \"K\" \"L\" \"M\" \"N\" \"O\" \"P\" \"Q\" \"R\" \"S\"\n## [20] \"T\" \"U\" \"V\" \"W\" \"X\" \"Y\" \"Z\"\nLETTERS[1:2]\n## [1] \"A\" \"B\"",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>ベクトル</span>"
    ]
  },
  {
    "objectID": "03-vector.html#乱数ベクトル",
    "href": "03-vector.html#乱数ベクトル",
    "title": "4  ベクトル",
    "section": "4.8 乱数ベクトル",
    "text": "4.8 乱数ベクトル\nベクトルを無作為に並べ替えたり抽出したりするには sample() を使う。\n\nset.seed(10)\nsample(1:5)\n## [1] 3 1 2 5 4\n\nここで set.seed() は乱数の種を固定し、別の環境でも同じ結果を再現できるようにするための設定である。\n上記は一度選ばれた値を再度選ばない非復元抽出である。復元抽出にする場合は replace = TRUE を指定する。\n\nsample(1:5, replace = TRUE)\n## [1] 3 2 2 2 5\n\nsize 引数を指定すれば、取り出す要素数も制御できる。\n\nsample(LETTERS[1:2], size = 10, replace = TRUE)\n##  [1] \"A\" \"B\" \"B\" \"A\" \"B\" \"A\" \"A\" \"B\" \"B\" \"A\"\n\n非復元抽出では、size を母集合の長さより大きくすることはできない点に注意する。\nさらに prob で各要素が選ばれる確率を指定できる（確率の合計は 1 になるようにする）。\n\nsample(LETTERS[1:2], prob = c(0.8, 0.2), size = 10, replace = TRUE)\n##  [1] \"A\" \"A\" \"A\" \"B\" \"A\" \"A\" \"B\" \"B\" \"A\" \"A\"\n\n独立な一様分布に従う長さ size のベクトルは runif(size)、平均と分散を指定した正規分布なら rnorm(size, mean, sd) で生成できる（既定値は平均 0、標準偏差 1）。\n\nsize &lt;- 8\nrunif(size)\n## [1] 0.27548386 0.22890394 0.01443391 0.72896456 0.24988047 0.16118328 0.01704265\n## [8] 0.48610035\nrnorm(size)\n## [1] -1.26519802 -0.37366156 -0.68755543 -0.87215883 -0.10176101 -0.25378053\n## [7] -1.85374045 -0.07794607",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>ベクトル</span>"
    ]
  },
  {
    "objectID": "02-rstudio.html",
    "href": "02-rstudio.html",
    "title": "3  RStudio",
    "section": "",
    "text": "3.1 RStudio とは\nRStudio は R の統合開発環境 (IDE, Integrated Development Enviroment) の一つである。 オープンソース版が存在する。\nhttps://ja.wikipedia.org/wiki/R-Studio",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>RStudio</span>"
    ]
  },
  {
    "objectID": "02-rstudio.html#rstudio-のインストール",
    "href": "02-rstudio.html#rstudio-のインストール",
    "title": "3  RStudio",
    "section": "3.2 RStudio のインストール",
    "text": "3.2 RStudio のインストール\nオープンソース版のRStudio のインストールは\nhttps://www.rstudio.com/products/rstudio/download/\nにいき、該当機種のファイルをダウンロードする。 ダウンロードしたあとに実行すればインストールされる。\nUbuntu ならサーバー版を導入するとよい。\nhttps://www.rstudio.com/products/rstudio/download-server/",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>RStudio</span>"
    ]
  },
  {
    "objectID": "02-rstudio.html#rstudio-の設定",
    "href": "02-rstudio.html#rstudio-の設定",
    "title": "3  RStudio",
    "section": "3.3 RStudio の設定",
    "text": "3.3 RStudio の設定\nメニューバーの [Tools] から [Global Options…] を選択することで設定を変更できる。\n[General] で以下のように [Restore .RData …] のチェックを外していいて、 その下を Never にしている。 これは、立ち上げたきに環境をクリーンし、 終了時に、データの保存を聞かれないようにするためである。\n\n\n\n\n\n\n\n\n\n次に、[Code] の タブ [Saving] で。 [Default text encoding] を UTF-8 とする。 Windows 以外だとOSのシステムフォントが同じなので問題ない。 しかし Windows は SJIS を拡張した CP932 なので、注意が必要である。\nWindows のRは UTF-8 を選択してもR自身はCP932処理している。 ただ、他のOSとの併用の場合、UTF-8 にしたほうがよいだろう。 またHTMLファイルは UTF-8 でのファイルが前提になりつつあるので、 HTML として出力を考えているなら、UTF-8 としたほうが無難である。\nまたインターネットで公開されている日本語のRファイルは Windows の使用が前提となっているため、文字コードが CP932 であることが多い。Windows 以外を使っている場合、一時的に文字コードを SJIS を選択する必要がある。\n\n\n\n\n\n\n\n\n\nあと、[R Markdown] で 真ん中あたりの [Show output preview in:] を View Pane に変更する",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>RStudio</span>"
    ]
  },
  {
    "objectID": "02-rstudio.html#rstudio-の使い方",
    "href": "02-rstudio.html#rstudio-の使い方",
    "title": "3  RStudio",
    "section": "3.4 RStudio の使い方",
    "text": "3.4 RStudio の使い方\nRStudio の使い方として日本語版のチートシートがある。\nhttps://github.com/rstudio/cheatsheets/raw/master/translations/japanese/rstudio-IDE-cheatsheet_ja.pdf\n英語であるがこの動画も有益である。 第一章だけ公開されている。\nhttps://www.datacamp.com/courses/working-with-the-rstudio-ide-part-1\nRStudio プロジェクト単位で複数のソースコードを管理するのことが推奨される。 そうするとプロジェクトごとに作業ディレクトリが設定される。 プロジェクトはメニューバー の [File] から [New Project] を選択する。 そうすると新たに新たにディレクトリを作成するか、既存のディレクトリを採用するかなどが選べる。 また、バージョン管理ソフトを導入していればそこから取り入れることも可能となる。\n\n\n\n\n\n\n\n\n\nプロジェクトを立ち上げると左にコンソールペイン (Console Pane) が、右側に上下に二分割されたペインが現れる。 この配置は メニューバーの [Tools] から [Project Options -&gt; Pane Layout] を選べば変更可能である。 コンソールペインにコマンドを入力するとその結果が直下に返される。 何か入力した後に、Ctrl + l (Cmd + l) を押すと、画面が更新される。 上下の矢印キーで過去に実行したコマンドを選択できる。\nメニューバー の [File] から [New File -&gt; RScript] を選択するか、 Ctrl + Shift + n (Cmd + Shift + n) と入力するか、メニューバー下の一番左の白紙のアイコンをクリックすると、 Rのスクリプトファイルが新規に作られる。 スクリプフォファイルを開くと左側のコンソール画面の上にソースペインが登場する。 ここにソースコードを書く。\nソースペインで何かコマンドを書いていきながら、 ソースコードの該当行で Ctrl + Enter (Cmd + Return) と入力するか、ソースペインの上側の右に並んでいるアイコンのうち、左側のRunと書かれたアイコンをクリックすると、該当行がコンソール画面で実行される。 複数行選択した後に、メニューバー の [Code] から [Run Selected line(s)] を選ぶか、 Ctrl + Shift + Enter (Cmd + Shift + Enter) と入力すると複数行をまとめて実行させることも可能である。\nメニューバー の [File] から [Save] を選択するか、Ctrl + s (Cmd + s) と入力するか、メニューバー下の左から3番目のフロッピーディスクアイコンをクリック すると、スクリプトファイルを保存することができる。 またメニューバー の [File] から [Open] を選択するか、 Ctrl + o (Cmd + o) と入力するか、メニューバー下の左から2番めのフォルダを開くアイコンをクリックすると、 既存のスクリプトファイルを開くことができる。\n\n\n\n\n\n\n\n\n\n右上のペインには Environment と History のタブがある。 Environment は現在使っているオブジェクトが表示される。 最初は空白である。 変数に数値を代入 (R の言い方ではオブジェクトに付値) することによって、 値が付け加わっている。 History はこれまでの履歴が記録される。 履歴の一部ををエディトペインかコンソールペインに挿入することができる。\n右下のペインには Files, Plots, Packages, Help, Viewer のタブがある。 Files ペインはWindowsではエクスプローラーのようなもので、 Mac はFinder のようなもので、ファイル管理をおこなう。 ファイル管理として新たなフォルダを作成したり、ファイルを削除したり、 ファイル名を変更したりする。\nまたワーキングディレクトリを直感的に設定することもできる。 ワーキングを設定したい場所に移動して、 Files ペインの上に並んでいるアイコンのうち、Moreをクリックし、 [Set As Working Directory] をクリックすればよい。\nPlots ペインはコンソール画面で作図をコマンドの実行したら、表示されるペインである。そこで作成した図をコマンドを使わずに保存したりすることができる。 Packages ペインは現在Rに導入されているパッケージリストが表示される。 そこに無いパッケージはメニューバーの [Tools] から [Install Packages…] を選択して実行すればよい。 すでにあるパッケージは、パッケージ名の左側のボックスをチェックすれば、 ライブライリ名を付けずにコマンドを実行させることができる。\nHelp ペインはその名の通り、ヘルプ画面が表示される。 コンソールペインから help (コマンド) もしくは ?コマンド と入力するとそのコマンドのヘルプがこのペインに表示される。 R ではソースペインやコンソールペインで、コマンド入力していると、コマンドの後補があらわてくる。[TAB] でコマンドを補完できる。 さらにそのコマンドでどのような引数が使われるのかも示される。 さらに [TAB] を押せば、引数を選べるだけでなく、簡単なコマンドの説明がある。 そのときに [F1] を押せば、より詳細なヘルプが立ち上がる。 また Packages パインから該当パッケージをクリックするとそのパッケージのコマンド一覧が Help ペインに表示される。\n\n\n\n\n\n\n\n\n\n最後のViewer ペインは R Markdown で作成したファイルを HTMLで出力したときに表示されるペインである。 最初の設定だと別のウィンドウ画面として結果が表示される。 このペインに出力されるためには [Tools -&gt; R Markdown] にいき、真ん中あたりの [Show output preview in:] を View Pane に変更する必要がある。 その上でソースペインから [Ctrl + Shift + k] とするか、ソースペインの左側のアイコン群の一番右側のノートのアイコンをクリックすると、 確認画面が現れるので HTML を押す。 そうするとそのコードがすべて実行されて、実行結果が作図も含めてHTMLファイルに出力される。 もしくはメニューバーの [File] から [Knit Document…] としを選択するとよい。\n\n\n\n\n\n\n\n\n\nこれは knitr と rmarkdown いわれるパッケージを利用したもので、Rのコードを埋め込んだマークダウンファイルを作成し、 そこからHTMLファイルを作成する。 他にもword ファイル や pdf ファイル生成することも適切に設定していれば可能である。 ソースコードだけでなく、マークダウンファイルに R コマンドを埋め込んだ Rmd ファイルを作成することができる それは新規作成でRスクリプトでなく、R Notebook や R Markdown を選択すればよい。",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>RStudio</span>"
    ]
  },
  {
    "objectID": "09-ivreg.html",
    "href": "09-ivreg.html",
    "title": "10  操作変数法",
    "section": "",
    "text": "10.1 データ\nlibrary(AER)\nlibrary(wooldridge)\nlibrary(estimatr)\ndata(\"mroz\", package=\"wooldridge\")\ndf &lt;- subset(mroz, inlf==1)",
    "crumbs": [
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>操作変数法</span>"
    ]
  },
  {
    "objectID": "09-ivreg.html#操作変数",
    "href": "09-ivreg.html#操作変数",
    "title": "10  操作変数法",
    "section": "10.2 操作変数",
    "text": "10.2 操作変数\nこれまで回帰モデルで一致推定量を得るためには次の仮定が必要であった。\n\n母集団が線形モデル\n標本が無作為抽出\n誤差項が平均ゼロで説明変数と無相関\n説明変数に多重共線性が存在しない\n\n3つ目の仮定が必ずしも成立しない場合の推定方法を紹介する。\nそのために、外生変数と内生変数と操作変数の3つの概念を導入する。 誤差項と相関が無い説明変数を 外生変数 といい、誤差項と相関がある説明変数を 内生変数 という。 操作変数 とは、説明変数に含まれず、説明変数と相関をもち、誤差項と相関をもたない変数のことである。 なお操作変数の個数は内生変数の個数より多くなければならない。\nR では ivreg 関数を用いて操作変数法を実行する。 この関数は AER パッケージに含まれており、基本的な書式は ivreg(被説明変数 ~ 内生変数 | 操作変数, data=データフレーム) である。 ここで被説明変数は log(wage), 内生変数は educ, 操作変数は fatheduc である。\n以下のコマンドで操作変数法を実行し、coef() 関数で推定された係数を取り出す。\n\nfm  &lt;- ivreg(log(wage)~educ|fatheduc, data=df)\ncoef(fm)\n## (Intercept)        educ \n##  0.44110339  0.05917348\n\n傾きの推定値は操作変数推定量の公式を用いて直接計算することもできる。 具体的には、被説明変数と操作変数の共分散を内生変数と操作変数の共分散で割ることで得られる。 以下のコマンドで cov() 関数を用いて共分散を計算し、同じ推定値が得られることを確認する。\n\nwith(df, cov(log(wage),fatheduc)/cov(educ,fatheduc))\n## [1] 0.05917348",
    "crumbs": [
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>操作変数法</span>"
    ]
  },
  {
    "objectID": "09-ivreg.html#段階最小二乗法",
    "href": "09-ivreg.html#段階最小二乗法",
    "title": "10  操作変数法",
    "section": "10.3 2段階最小二乗法",
    "text": "10.3 2段階最小二乗法\n複数の説明変数があり、操作変数の数が内生変数の数以上のとき、係数の一致推定量を得るには二段階最小二乗法を用いる。 二段階最小二乗法は次の手順で実行される:\n\nそれぞれの内生変数を外生変数と操作変数に回帰させて、その予測値を得る。\n被説明変数を外生変数と内生変数の予測値に回帰させて、その係数を得る。\n\nこの係数が一致推定量になるための条件は以下である。\n\n母集団が線形モデル\n標本が無作為抽出\n誤差項が平均ゼロで操作変数と外生変数に対して独立\n操作変数は内生変数と相関をもつ\n外生変数と内生変数の予測値に多重共線性が存在しない\n\nR では ivreg() 関数を用いて二段階最小二乗法を実行する。 複数の説明変数がある場合の書式は ivreg(被説明変数 ~ 内生変数 + 外生変数 | 外生変数 + 操作変数, data=データフレーム) である。 ここで被説明変数は log(wage), 内生変数は educ, 外生変数は exper, I(exper^2), 操作変数は motheduc, fatheduc である。 注意点として、パイプ記号 | の右側には外生変数も含める必要がある。\n以下のコマンドで二段階最小二乗法を実行し、summary() 関数で推定結果の要約を表示する。\n\nfm  &lt;- ivreg(log(wage)~educ+exper+I(exper^2)|\n            exper+I(exper^2)+motheduc+fatheduc,\n            data=df)\nsummary(fm)\n## \n## Call:\n## ivreg(formula = log(wage) ~ educ + exper + I(exper^2) | exper + \n##     I(exper^2) + motheduc + fatheduc, data = df)\n## \n## Residuals:\n##     Min      1Q  Median      3Q     Max \n## -3.0986 -0.3196  0.0551  0.3689  2.3493 \n## \n## Coefficients:\n##               Estimate Std. Error t value Pr(&gt;|t|)   \n## (Intercept)  0.0481003  0.4003281   0.120  0.90442   \n## educ         0.0613966  0.0314367   1.953  0.05147 . \n## exper        0.0441704  0.0134325   3.288  0.00109 **\n## I(exper^2)  -0.0008990  0.0004017  -2.238  0.02574 * \n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n## \n## Residual standard error: 0.6747 on 424 degrees of freedom\n## Multiple R-Squared: 0.1357,  Adjusted R-squared: 0.1296 \n## Wald test: 8.141 on 3 and 424 DF,  p-value: 2.787e-05\n\n二段階最小二乗法の手順を lm() 関数を用いて手動で実行し、同じ係数推定値が得られることを確認できる。 ただし標準誤差の値が異なっている。 なぜなら残差は内生変数および外生変数から算出する必要があるが、以下のやり方だと内生変数の予測値および外生変数から算出するためである。\n以下では第一段階として lm() 関数で内生変数 educ を外生変数と操作変数に回帰し、fitted() 関数で予測値を取得する。 第二段階として被説明変数を外生変数と内生変数の予測値に回帰する。\n\nols1 &lt;- lm(educ~exper+I(exper^2)+motheduc+fatheduc,  data = df)\nols2 &lt;- lm(log(wage)~fitted(ols1)+exper+I(exper^2),  data = df)\nsummary(ols2)\n## \n## Call:\n## lm(formula = log(wage) ~ fitted(ols1) + exper + I(exper^2), data = df)\n## \n## Residuals:\n##     Min      1Q  Median      3Q     Max \n## -3.1631 -0.3539  0.0326  0.3818  2.3727 \n## \n## Coefficients:\n##                Estimate Std. Error t value Pr(&gt;|t|)   \n## (Intercept)   0.0481003  0.4197565   0.115  0.90882   \n## fitted(ols1)  0.0613966  0.0329624   1.863  0.06321 . \n## exper         0.0441704  0.0140844   3.136  0.00183 **\n## I(exper^2)   -0.0008990  0.0004212  -2.134  0.03338 * \n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n## \n## Residual standard error: 0.7075 on 424 degrees of freedom\n## Multiple R-squared:  0.04978,    Adjusted R-squared:  0.04306 \n## F-statistic: 7.405 on 3 and 424 DF,  p-value: 7.615e-05\n\n\n10.3.1 複数制約の検定\n帰無仮説が複数の係数制約を課す場合のワルド検定を実施する。 例えば、2つの外生変数 exper と I(exper^2) の係数がともにゼロであるという仮説を検定する。\nまず ivreg() 関数で制約モデル（外生変数を含まないモデル）を推定し、waldtest() 関数で制約なしモデルと比較する。 waldtest() 関数は2つのモデルを引数にとり、ワルド検定を実行する。\n\nfm0 &lt;- ivreg(log(wage)~educ|motheduc+fatheduc,data=df)\nwaldtest(fm0,fm)\n## Wald test\n## \n## Model 1: log(wage) ~ educ | motheduc + fatheduc\n## Model 2: log(wage) ~ educ + exper + I(exper^2) | exper + I(exper^2) + \n##     motheduc + fatheduc\n##   Res.Df Df  Chisq Pr(&gt;Chisq)    \n## 1    426                         \n## 2    424  2 19.639  5.439e-05 ***\n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nLM検定（ラグランジュ乗数検定）も実行可能である。 まず resid() 関数で制約モデルの残差を取得し、その残差を制約される説明変数に回帰する。 nrow() 関数で観測数を取得し、決定係数 r.squared を乗じてLM統計量を計算する。 最後に pchisq() 関数でカイ二乗分布のP値を計算する（自由度は制約の数3）。\n\nlmt &lt;- lm(resid(fm0)~educ + exper + I(exper^2) ,data=df)\n(lmt &lt;- nrow(df)*summary(lmt)$r.squared)\n## [1] 33.97987\n1-pchisq(lmt,df=3)\n## [1] 2.000665e-07",
    "crumbs": [
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>操作変数法</span>"
    ]
  },
  {
    "objectID": "09-ivreg.html#特定化検定",
    "href": "09-ivreg.html#特定化検定",
    "title": "10  操作変数法",
    "section": "10.4 特定化検定",
    "text": "10.4 特定化検定\n操作変数法が妥当かどうかを検証するために、複数の特定化検定を実施する。 summary() 関数にオプション diagnostics = TRUE を追加すると、弱操作変数検定（Weak instruments）、Wu-Hausman検定、Sargan検定を一度に実行できる。 これらの検定結果から、操作変数の妥当性、内生性の有無、操作変数の外生性を確認できる。\n\nsummary(fm, diagnostics = TRUE)\n## \n## Call:\n## ivreg(formula = log(wage) ~ educ + exper + I(exper^2) | exper + \n##     I(exper^2) + motheduc + fatheduc, data = df)\n## \n## Residuals:\n##     Min      1Q  Median      3Q     Max \n## -3.0986 -0.3196  0.0551  0.3689  2.3493 \n## \n## Coefficients:\n##               Estimate Std. Error t value Pr(&gt;|t|)   \n## (Intercept)  0.0481003  0.4003281   0.120  0.90442   \n## educ         0.0613966  0.0314367   1.953  0.05147 . \n## exper        0.0441704  0.0134325   3.288  0.00109 **\n## I(exper^2)  -0.0008990  0.0004017  -2.238  0.02574 * \n## \n## Diagnostic tests:\n##                  df1 df2 statistic p-value    \n## Weak instruments   2 423    55.400  &lt;2e-16 ***\n## Wu-Hausman         1 423     2.793  0.0954 .  \n## Sargan             1  NA     0.378  0.5386    \n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n## \n## Residual standard error: 0.6747 on 424 degrees of freedom\n## Multiple R-Squared: 0.1357,  Adjusted R-squared: 0.1296 \n## Wald test: 8.141 on 3 and 424 DF,  p-value: 2.787e-05\n\n\n10.4.1 Weak instruments\n操作変数が内生変数と弱い相関関係しかない場合、弱操作変数という。 弱操作変数の場合、推定量の性質が悪化するため、操作変数が十分に強い相関を持つかを検定する必要がある。\n検定手順は以下の通りである。 それぞれの内生変数に対して、帰無仮説を内生変数を外生変数のみに回帰させたモデルとし、対立仮説を内生変数を外生変数および操作変数に回帰させたモデルとし、F検定を実施する。\n以下のコマンドで lm() 関数による制約モデルを推定し、anova() 関数で第一段階の回帰モデル ols1 と比較してF検定を実行する。 この結果が先の diagnostics = TRUE で得られた弱操作変数検定と同じであることを確認されたい。\n\nols0 &lt;- lm(educ ~ exper + I(exper^2), data = df)\nanova(ols0, ols1)\n## Analysis of Variance Table\n## \n## Model 1: educ ~ exper + I(exper^2)\n## Model 2: educ ~ exper + I(exper^2) + motheduc + fatheduc\n##   Res.Df    RSS Df Sum of Sq    F    Pr(&gt;F)    \n## 1    425 2219.2                                \n## 2    423 1758.6  2    460.64 55.4 &lt; 2.2e-16 ***\n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\n10.4.2 Wu-Hausman 検定\nWu-Hausman 検定は帰無仮説が誤差項と説明変数が無相関、対立仮説が誤差項と説明変数が相関ありの検定を行う。 帰無仮説のもとでは、OLSも2SLSも一致推定量であるが、OLSの方が効率的である。 よって検定統計量のP値が十分小さいなら帰無仮説は棄却され、内生性があることになり操作変数法（2SLS）を選択する。 そうでなければより効率的な最小二乗法（OLS）を実施する。\n具体的には以下のF検定を実施する。\n\nlm() 関数でそれぞれの内生変数を外生変数に回帰し、resid() 関数で残差を得る (resid(ols1))\nlm() 関数で被説明変数を説明変数に回帰する (ols3)\nupdate() 関数で被説明変数を説明変数および先程の残差に回帰する (ols4)\nanova() 関数でこれらの残差の係数はゼロであるという帰無仮説のもとF検定を実施する\n\n以下のコマンドが先の diagnostics = TRUE で得られたWu-Hausman検定と同じであることを確認されたい。\n\nols3 &lt;- lm(log(wage) ~ educ  + exper + I(exper^2), data = df)\nols4 &lt;- update(ols3, . ~ . + resid(ols1))\nanova(ols3,ols4)\n## Analysis of Variance Table\n## \n## Model 1: log(wage) ~ educ + exper + I(exper^2)\n## Model 2: log(wage) ~ educ + exper + I(exper^2) + resid(ols1)\n##   Res.Df    RSS Df Sum of Sq      F  Pr(&gt;F)  \n## 1    424 188.31                              \n## 2    423 187.07  1     1.235 2.7926 0.09544 .\n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\n10.4.3 Sargan 検定\nSargan 検定は誤差項が操作変数（および外生変数）と相関しているかどうかを検定する。 帰無仮説は操作変数が外生的である（相関が無い）場合で、対立仮説は操作変数が内生的である（相関がある）場合である。 この検定は操作変数が過剰識別されている（操作変数の数が内生変数の数より多い）場合にのみ実施可能である。\nLM検定（ラグランジュ乗数検定）を以下の手順で実施する。\n\nresid() 関数で二段階最小二乗法を実施したときの残差を得る (resid(fm))\nlm() 関数で残差を外生変数および操作変数に回帰する\nnrow() 関数で観測数を取得し、回帰の決定係数 r.squared を乗じたLM統計量を得る\npchisq() 関数で検定統計量のP値を計算する。検定統計量は帰無仮説のもと、操作変数の数から内生変数の数を差し引いた自由度（この例では1）のカイ二乗分布にしたがう\n\n以下のコマンドが先の diagnostics = TRUE で得られたSargan検定と同じであることを確認されたい。\n\njt &lt;- lm(resid(fm)~exper+I(exper^2)+motheduc+fatheduc,data=df)\n(jt &lt;- nrow(df)*summary(jt)$r.squared)\n## [1] 0.3780714\n1-pchisq(jt,df=1)\n## [1] 0.5386372",
    "crumbs": [
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>操作変数法</span>"
    ]
  },
  {
    "objectID": "09-ivreg.html#ロバスト分散",
    "href": "09-ivreg.html#ロバスト分散",
    "title": "10  操作変数法",
    "section": "10.5 ロバスト分散",
    "text": "10.5 ロバスト分散\n以上の分析は、誤差項が操作変数と独立かつ均一分散の場合の分析である。 独立でない場合や分散不均一の場合、推定量の分散が変わりうる。 そうした場合に頑健な分散推定量をロバスト分散という。\nロバスト分散にもとづく推定結果を得るには、summary() 関数にオプション vcov = vcovHC を追加する。 vcovHC() 関数は不均一分散に頑健な分散共分散行列を計算する関数である。 オプション df = Inf は自由度を無限大とし、t分布ではなく正規分布を用いて検定を行う。\n\nsummary(fm, vcov = vcovHC, df = Inf)\n## \n## Call:\n## ivreg(formula = log(wage) ~ educ + exper + I(exper^2) | exper + \n##     I(exper^2) + motheduc + fatheduc, data = df)\n## \n## Residuals:\n##     Min      1Q  Median      3Q     Max \n## -3.0986 -0.3196  0.0551  0.3689  2.3493 \n## \n## Coefficients:\n##               Estimate Std. Error z value Pr(&gt;|z|)   \n## (Intercept)  0.0481003  0.4337795   0.111  0.91171   \n## educ         0.0613966  0.0336597   1.824  0.06815 . \n## exper        0.0441704  0.0157661   2.802  0.00508 **\n## I(exper^2)  -0.0008990  0.0004391  -2.047  0.04062 * \n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n## \n## Residual standard error: 0.6747 on Inf degrees of freedom\n## Multiple R-Squared: 0.1357,  Adjusted R-squared: 0.1296 \n## Wald test: 18.11 on 3 DF,  p-value: 0.0004168\n\n係数の検定結果のみを表示したい場合は、coeftest() 関数を用いる。 この関数は推定されたモデルオブジェクトと分散共分散行列を引数にとり、係数のt検定結果を表示する。\n\ncoeftest(fm, vcov=vcovHC)\n## \n## t test of coefficients:\n## \n##                Estimate  Std. Error t value Pr(&gt;|t|)   \n## (Intercept)  0.04810030  0.43377952  0.1109 0.911759   \n## educ         0.06139663  0.03365975  1.8240 0.068850 . \n## exper        0.04417039  0.01576605  2.8016 0.005318 **\n## I(exper^2)  -0.00089897  0.00043908 -2.0474 0.041233 * \n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nロバスト分散のもとでの複数制約のワルド検定を実施するには、waldtest() 関数にオプション vcov=vcovHC を追加する。\n\nwaldtest(fm0,fm, vcov=vcovHC)\n## Wald test\n## \n## Model 1: log(wage) ~ educ | motheduc + fatheduc\n## Model 2: log(wage) ~ educ + exper + I(exper^2) | exper + I(exper^2) + \n##     motheduc + fatheduc\n##   Res.Df Df  Chisq Pr(&gt;Chisq)    \n## 1    426                         \n## 2    424  2 14.582  0.0006816 ***\n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n最近開発されたパッケージ estimatr の iv_robust() 関数を用いるとロバスト分散のもとの推定値が簡単に計算できる。 この関数はデフォルトでロバスト標準誤差（HC2型）を計算し、オプション diagnostics = TRUE で特定化検定も同時に実行できる。 書式は ivreg() 関数と同じである。\n以下のコマンドで iv_robust() 関数による推定を実行し、summary() 関数で結果を表示する。\n\nfm2 &lt;- iv_robust(log(wage)~educ+exper+I(exper^2)|\n            exper+I(exper^2)+motheduc+fatheduc,\n            data=df,diagnostics =TRUE)\nsummary(fm2)\n## \n## Call:\n## iv_robust(formula = log(wage) ~ educ + exper + I(exper^2) | exper + \n##     I(exper^2) + motheduc + fatheduc, data = df, diagnostics = TRUE)\n## \n## Standard error type:  HC2 \n## \n## Coefficients:\n##              Estimate Std. Error t value Pr(&gt;|t|)  CI Lower   CI Upper  DF\n## (Intercept)  0.048100  0.4307514  0.1117 0.911141 -0.798574  8.948e-01 424\n## educ         0.061397  0.0334146  1.8374 0.066848 -0.004282  1.271e-01 424\n## exper        0.044170  0.0156233  2.8272 0.004918  0.013462  7.488e-02 424\n## I(exper^2)  -0.000899  0.0004337 -2.0730 0.038777 -0.001751 -4.658e-05 424\n## \n## Multiple R-squared:  0.1357 ,    Adjusted R-squared:  0.1296 \n## F-statistic: 6.117 on 3 and 424 DF,  p-value: 0.0004426\n## \n## Diagnostics:\n##                  numdf dendf  value p.value    \n## Weak instruments     2   423 49.374  &lt;2e-16 ***\n## Wu-Hausman           1   423  2.535   0.112    \n## Overidentifying      1    NA  0.443   0.505    \n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nオプション se_type = \"stata\" を用いればSTATAと同じ標準誤差の計算が可能である。 また、ロバスト分散のもとで特定化検定（弱操作変数検定、Wu-Hausman検定、Sargan検定）が実行される。\n分散均一性を仮定した古典的な標準誤差を計算したい場合は、オプション se_type = \"classical\" を追加する。\n\nfm3 &lt;- iv_robust(log(wage)~educ+exper+I(exper^2)|\n            exper+I(exper^2)+motheduc+fatheduc,\n            data=df,diagnostics =TRUE,se_type = \"classical\")\nsummary(fm3)\n## \n## Call:\n## iv_robust(formula = log(wage) ~ educ + exper + I(exper^2) | exper + \n##     I(exper^2) + motheduc + fatheduc, data = df, se_type = \"classical\", \n##     diagnostics = TRUE)\n## \n## Standard error type:  classical \n## \n## Coefficients:\n##              Estimate Std. Error t value Pr(&gt;|t|)   CI Lower   CI Upper  DF\n## (Intercept)  0.048100  0.4003281  0.1202 0.904419 -0.7387744  0.8349750 424\n## educ         0.061397  0.0314367  1.9530 0.051474 -0.0003945  0.1231878 424\n## exper        0.044170  0.0134325  3.2883 0.001092  0.0177679  0.0705729 424\n## I(exper^2)  -0.000899  0.0004017 -2.2380 0.025740 -0.0016885 -0.0001094 424\n## \n## Multiple R-squared:  0.1357 ,    Adjusted R-squared:  0.1296 \n## F-statistic: 8.141 on 3 and 424 DF,  p-value: 2.787e-05\n## \n## Diagnostics:\n##                  numdf dendf  value p.value    \n## Weak instruments     2   423 55.400  &lt;2e-16 ***\n## Wu-Hausman           1   423  2.793  0.0954 .  \n## Overidentifying      1    NA  0.378  0.5386    \n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n10.5.1 分散不均一の検定\n誤差項が操作変数と独立なら条件付き分散は操作変数に無関係で均一である。 これを利用して分散均一を帰無仮説に、分散不均一を対立仮説にしたBP検定（Breusch-Pagan検定）が実行可能である。 ただし、通常の bptest() 関数では正しく実行できないので、手動で実行する必要がある。\n以下の手順でBP検定を実行する。\n\nI() 関数と resid() 関数を用いて二段階最小二乗法の残差の二乗を計算する (I(resid(fm)^2))\nlm() 関数で残差の二乗を外生変数および操作変数に回帰する\nnrow() 関数で観測数を取得し、決定係数 r.squared を乗じてLM統計量を得る\npchisq() 関数で検定統計量のP値を計算する。検定統計量は帰無仮説のもと、説明変数の数（この例では4）の自由度のカイ二乗分布にしたがう\n\n\nbpt &lt;- lm(I(resid(fm)^2)~exper + I(exper^2) + motheduc + fatheduc,data=df)\n(bpt &lt;- nrow(df)*summary(bpt)$r.squared)\n## [1] 12.41758\n1-pchisq(bpt,df=4)\n## [1] 0.01450172",
    "crumbs": [
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>操作変数法</span>"
    ]
  },
  {
    "objectID": "04-dataframe.html",
    "href": "04-dataframe.html",
    "title": "5  データ構造",
    "section": "",
    "text": "5.1 リスト\n複数のオブジェクト（ベクトルや別のリストなど）をまとめたものがリストである。 型の異なるベクトルでも list() に渡すことで 1 つのリストにまとめられる。\nリストにも長さという属性があり、length() で要素数を確認できる。\n(lst &lt;- list(\"a\",c(3,3,2)))\n## [[1]]\n## [1] \"a\"\n## \n## [[2]]\n## [1] 3 3 2\ntypeof(lst)\n## [1] \"list\"\nlength(lst)\n## [1] 2\nclass() でオブジェクトのクラスを、str() で内部構造を確認できる。\nclass(lst)\n## [1] \"list\"\nstr(lst)\n## List of 2\n##  $ : chr \"a\"\n##  $ : num [1:3] 3 3 2\nリストは入れ子にすることもできる。これは単一の型しか持てないベクトルとの大きな違いである。\ntypeof(list(\"b\",lst))\n## [1] \"list\"\nリストをベクトルに変換するには unlist() を使う。構成要素の型が異なる場合は、ベクトルに変換できるように強制変換が行われる。\nlst&lt;-list(1:3,2:6)\nlst\n## [[1]]\n## [1] 1 2 3\n## \n## [[2]]\n## [1] 2 3 4 5 6\nunlist(lst)\n## [1] 1 2 3 2 3 4 5 6\nunlist(list(\"a\",1:4))\n## [1] \"a\" \"1\" \"2\" \"3\" \"4\"\n個々の要素の長さを調べたいときは lengths(lst) が便利で、各要素に同じ処理を施す場合は lapply() や sapply() を組み合わせるとよい。",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>データ構造</span>"
    ]
  },
  {
    "objectID": "04-dataframe.html#リスト",
    "href": "04-dataframe.html#リスト",
    "title": "5  データ構造",
    "section": "",
    "text": "5.1.1 リストのアクセス\nリストの要素も角括弧を用いて参照する。単一の角括弧 [] を使うと、要素を取り出してもリストのまま返る。以下は最初の要素（＝ 1 番目のリスト）を取得する例である。\n\nlst[1]\n## [[1]]\n## [1] 1 2 3\n\n名前属性を付けたリストであれば、文字列でアクセスできる。\n\n(lst &lt;- list(name=\"a\",num=c(3,3,2)))\n## $name\n## [1] \"a\"\n## \n## $num\n## [1] 3 3 2\nnames(lst)\n## [1] \"name\" \"num\"\n\nこの状態で次のように書けば 2 番目の要素を取り出せる。\n\nlst[\"num\"]\n## $num\n## [1] 3 3 2\n\nいずれの場合も [] で取り出した結果はリストである点に注意する。\n\ntypeof(lst[1])\n## [1] \"list\"\ntypeof(lst[\"num\"])\n## [1] \"list\"\n\nベクトルとして取り出したい場合は二重角括弧 [[ ]] を使う。これによりリスト要素の中身がそのまま返る。\n\nlst[[2]]\n## [1] 3 3 2\ntypeof(lst[[2]])\n## [1] \"double\"\n\n名前付きの場合は次のように書くこともできる。\n\nlst[[\"num\"]]\n## [1] 3 3 2\nlst$num\n## [1] 3 3 2\n\nリスト内のベクトルに対して関数を適用したいときは、二重括弧か $ 記法でベクトルを取り出してから利用する。次の例では $ 記法を使っているが、コメント行で示したように二重括弧を使っても結果は同じである。\n\n## mean(lst[[2]])\n## mean(lst[[\"num\"]])\nmean(lst$num)\n## [1] 2.666667\n\nwith() を使えば、リスト内の要素を名前だけで参照できる。\n\nwith(lst, mean(num))\n## [1] 2.666667\n\nリストの要素を削除したいときは、該当要素に NULL を代入する。\n\nlst$num &lt;- NULL\nlst\n## $name\n## [1] \"a\"",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>データ構造</span>"
    ]
  },
  {
    "objectID": "04-dataframe.html#因子ベクトル",
    "href": "04-dataframe.html#因子ベクトル",
    "title": "5  データ構造",
    "section": "5.2 因子ベクトル",
    "text": "5.2 因子ベクトル\n\n5.2.1 factor\n文字列ベクトルを factor() に渡すと、カテゴリ情報を持つ因子 (factor) ベクトルを作成できる。\n\n(x &lt;- c(\"L\",\"S\",\"M\",\"M\",\"L\"))\n## [1] \"L\" \"S\" \"M\" \"M\" \"L\"\n(x.fac &lt;- factor(x))\n## [1] L S M M L\n## Levels: L M S\n\n因子ベクトルの実体は、levels という属性を持つ整数ベクトルである。値そのものではなく水準の位置を保持している点に注意する。\n\ntypeof(x.fac)\n## [1] \"integer\"\nlength(x.fac)\n## [1] 5\nlevels(x.fac)\n## [1] \"L\" \"M\" \"S\"\n\nclass() で因子であることを確認し、str() で水準情報などの属性を詳しく確認できる。\n\nclass(x.fac)\n## [1] \"factor\"\nstr(x.fac)\n##  Factor w/ 3 levels \"L\",\"M\",\"S\": 1 3 2 2 1\n\n水準の表示順は既定ではアルファベット順に並ぶが、levels 引数を指定すれば任意の順に設定できる。\n\n(x.factor &lt;- factor(x,levels=c(\"S\",\"M\",\"L\")))\n## [1] L S M M L\n## Levels: S M L\n\nさらに ordered() を使うと、水準に大小関係（順序）を持たせた因子を作れる。\n\n(x.order &lt;- ordered(x,levels=c(\"S\",\"M\",\"L\")))\n## [1] L S M M L\n## Levels: S &lt; M &lt; L\n\n分析の途中で未使用の水準を落としたいときは droplevels(x.factor) を利用する。\n\n\n5.2.2 cut\n連続値を区間ごとに区分して因子化したい場合は cut() を用いる。まず 0 から 10 までの値を乱数で生成する。\n\nx &lt;- runif(10,0,10)\nx\n##  [1] 8.3664202 0.5872451 1.1116229 8.3665404 0.6668269 4.3685530 2.5409271\n##  [8] 1.6904684 3.8971879 5.3946613\n\nbreaks に分割数を指定すると、最小値から最大値までを等間隔に区切る。\n\ncut(x, breaks=5)\n##  [1] (6.81,8.37]  (0.579,2.14] (0.579,2.14] (6.81,8.37]  (0.579,2.14]\n##  [6] (3.7,5.25]   (2.14,3.7]   (0.579,2.14] (3.7,5.25]   (5.25,6.81] \n## Levels: (0.579,2.14] (2.14,3.7] (3.7,5.25] (5.25,6.81] (6.81,8.37]\n\nこれは観測値の最小値から最大値までの区間を 5 等分した結果を返している。\n区間境界を自分で指定したい場合は、breaks に数値ベクトルを渡す。\n\ncut(x,breaks=c(0,2,4,6,8,10))\n##  [1] (8,10] (0,2]  (0,2]  (8,10] (0,2]  (4,6]  (2,4]  (0,2]  (2,4]  (4,6] \n## Levels: (0,2] (2,4] (4,6] (6,8] (8,10]\n\n0 より大きく 2 以下、2 より大きく 4 以下、… のように区切られている。\n最初の区間に最小値を含めたいときは include.lowest = TRUE を指定する。\n\ncut(x, breaks=seq(0,10,2),include.lowest=TRUE)\n##  [1] (8,10] [0,2]  [0,2]  (8,10] [0,2]  (4,6]  (2,4]  [0,2]  (2,4]  (4,6] \n## Levels: [0,2] (2,4] (4,6] (6,8] (8,10]\n\n区間の右端を含めたくない場合（例: 0 以上 2 未満、2 以上 4 未満、…）は right = FALSE を指定する。\n\ncut(x, breaks=seq(0,10,2),right=FALSE,include.lowest=TRUE)\n##  [1] [8,10] [0,2)  [0,2)  [8,10] [0,2)  [4,6)  [2,4)  [0,2)  [2,4)  [4,6) \n## Levels: [0,2) [2,4) [4,6) [6,8) [8,10]\n\nこのときの include.lowest = TRUE は最大値を最後の区間に含める指定となる。\n水準名をわかりやすいラベルに変えたいときは labels 引数で指定する。\n\ncut(\n  x,\n  breaks = seq(0, 10, 2),\n  right = FALSE,\n  include.lowest = TRUE,\n  labels = c(\"A\", \"B\", \"C\", \"D\", \"E\")\n)\n##  [1] E A A E A C B A B C\n## Levels: A B C D E",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>データ構造</span>"
    ]
  },
  {
    "objectID": "04-dataframe.html#行列",
    "href": "04-dataframe.html#行列",
    "title": "5  データ構造",
    "section": "5.3 行列",
    "text": "5.3 行列\nベクトルに縦横の次元情報を与えることで行列 (matrix) を作成できる。\n\nmat &lt;- matrix(1:10, nrow=2,ncol=5)\nmat\n##      [,1] [,2] [,3] [,4] [,5]\n## [1,]    1    3    5    7    9\n## [2,]    2    4    6    8   10\n\nmatrix() は既定では列方向にデータを埋めていくため、1 列目が 1, 2、2 列目が 3, 4… のように配置される。\nbyrow = TRUE を指定すると、行方向にデータを埋めていく。\n\nmatrix(1:10, nrow=2,ncol=5,byrow = TRUE)\n##      [,1] [,2] [,3] [,4] [,5]\n## [1,]    1    2    3    4    5\n## [2,]    6    7    8    9   10\n\n行列は dim 属性を持つ数値ベクトルとして表現されている。\n\ntypeof(mat)\n## [1] \"integer\"\nlength(mat)\n## [1] 10\ndim(mat)\n## [1] 2 5\n\n行数・列数は nrow()、ncol() で取得できる。\n\nnrow(mat)\n## [1] 2\nncol(mat)\n## [1] 5\n\nclass() や str() を使えば、クラス名や内部構造を確認できる。\n\nclass(mat)\n## [1] \"matrix\" \"array\"\nstr(mat)\n##  int [1:2, 1:5] 1 2 3 4 5 6 7 8 9 10\n\n\n5.3.1 行列の演算\n行方向に結合するには rbind() を用いる。\n\nmata&lt;-matrix(1:5,nrow=1,ncol=5)\nrbind(mat,mata)\n##      [,1] [,2] [,3] [,4] [,5]\n## [1,]    1    3    5    7    9\n## [2,]    2    4    6    8   10\n## [3,]    1    2    3    4    5\n\n列方向に結合するには cbind() を用いる。\n\nmatb&lt;-matrix(1:4,nrow=2,ncol=2)\ncbind(mat,matb)\n##      [,1] [,2] [,3] [,4] [,5] [,6] [,7]\n## [1,]    1    3    5    7    9    1    3\n## [2,]    2    4    6    8   10    2    4\n\n転置行列は t() で得られる。\n\nt(mat)\n##      [,1] [,2]\n## [1,]    1    2\n## [2,]    3    4\n## [3,]    5    6\n## [4,]    7    8\n## [5,]    9   10\n\n* 演算子は要素ごとの積を計算する。線形代数で使う行列積を計算したい場合は %*% を使う。\n\nmatb %*% mat\n##      [,1] [,2] [,3] [,4] [,5]\n## [1,]    7   15   23   31   39\n## [2,]   10   22   34   46   58\n\nこのとき、行列の次元（内積をとる側の列数と行数）が一致している必要がある。\n列ごとの合計は colSums()、行ごとの合計は rowSums() が利用できる。\n\ncolSums(mat)\n## [1]  3  7 11 15 19\nrowSums(mat)\n## [1] 25 30\n\n返り値はいずれもベクトルである。行列全体の総和を求める場合は sum() を使えばよい。\n\nsum(mat)\n## [1] 55\n\n平均値についても同様に colMeans()、rowMeans() を使える。\n\ncolMeans(mat)\n## [1] 1.5 3.5 5.5 7.5 9.5\nrowMeans(mat)\n## [1] 5 6\n\n\n\n5.3.2 行列のアクセス\n行列から行や列を取り出すときも角括弧 [] を用いる。次の例では 2 行目を抽出している。\n\nmat[2,]\n## [1]  2  4  6  8 10\n\nこのままだとベクトルとして返されるが、drop = FALSE を指定すれば行列の形を保ったまま取り出せる。\n\nmat[, 3, drop=FALSE]\n##      [,1]\n## [1,]    5\n## [2,]    6\n\n連続した列を取り出す場合は、特に drop を指定しなくても行列として返される。\n\nmat[,2:3]\n##      [,1] [,2]\n## [1,]    3    5\n## [2,]    4    6\n\n特定の要素を取り出すには行番号と列番号を指定する。\n\nmat[2,3]\n## [1] 6\n\n行・列に名前を付けることもできる。\n\nrownames(mat) &lt;- letters[1:2]\ncolnames(mat) &lt;- 1:5\nmat\n##   1 2 3 4  5\n## a 1 3 5 7  9\n## b 2 4 6 8 10\n\n名前を付けると、名前でアクセスできるようになる。\n\nmat[\"a\",\"3\"]\n## [1] 5\n\ndimnames() を使えば、行名と列名をまとめて設定・上書きできる。\n\ndimnames(mat) &lt;- list(LETTERS[1:2],2:6)\nmat\n##   2 3 4 5  6\n## A 1 3 5 7  9\n## B 2 4 6 8 10",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>データ構造</span>"
    ]
  },
  {
    "objectID": "04-dataframe.html#データフレイム",
    "href": "04-dataframe.html#データフレイム",
    "title": "5  データ構造",
    "section": "5.4 データフレイム",
    "text": "5.4 データフレイム\n同じ長さのベクトルを組み合わせたリストがデータフレイム (data frame) である。 次のように data.frame() を使って作成できる。\n\ndf &lt;- data.frame(x = rnorm(10), y = letters[1:10])\n\nここでは letters[1:10] を使って 10 個の小文字アルファベットを列として追加している。 R 4.0 以降は既定で文字列が因子化されないが、古いコードを扱う際は stringsAsFactors = FALSE を明示すると安全な場合がある。\nデータフレイムは大規模になることが多いため、先頭数行だけを確認するには head() を使う。\n\nhead(df)\n##            x y\n## 1 -1.5904469 a\n## 2  0.8639329 b\n## 3 -0.9094748 c\n## 4  1.6147541 d\n## 5 -1.0407845 e\n## 6 -1.3168426 f\n\n要約統計量を手早く確認したい場合は summary() が便利である。\n\nsummary(df)\n##        x                y            \n##  Min.   :-1.5904   Length:10         \n##  1st Qu.:-1.0393   Class :character  \n##  Median :-0.7754   Mode  :character  \n##  Mean   :-0.3796                     \n##  3rd Qu.: 0.4716                     \n##  Max.   : 1.6148\n\n内部構造や型を調べたいときは str() を使う。\n\nstr(df)\n## 'data.frame':    10 obs. of  2 variables:\n##  $ x: num  -1.59 0.864 -0.909 1.615 -1.041 ...\n##  $ y: chr  \"a\" \"b\" \"c\" \"d\" ...\n\nデータフレイムの実体はリストである。\n\ntypeof(df)\n## [1] \"list\"\nclass(df)\n## [1] \"data.frame\"\n\nそのため、リスト同様に長さや名前の属性を持つ。\n\nlength(df)\n## [1] 2\nnames(df)\n## [1] \"x\" \"y\"\n\n一方で、行列と同じように次元情報も持っている。\n\ndim(df)\n## [1] 10  2\nncol(df)\n## [1] 2\nnrow(df)\n## [1] 10\n\nここで ncol(df) は length(df) と同じ値を返す。\n行列と同じく、行名・列名も持つ。\n\ndimnames(df)\n## [[1]]\n##  [1] \"1\"  \"2\"  \"3\"  \"4\"  \"5\"  \"6\"  \"7\"  \"8\"  \"9\"  \"10\"\n## \n## [[2]]\n## [1] \"x\" \"y\"\ncolnames(df)\n## [1] \"x\" \"y\"\nrownames(df)\n##  [1] \"1\"  \"2\"  \"3\"  \"4\"  \"5\"  \"6\"  \"7\"  \"8\"  \"9\"  \"10\"\n\ncolnames(df) と names(df) は同一結果になる。\n\n5.4.1 データフレイムの演算\nデータフレイムは内部的にはリストだが、数値・論理値のみで構成されている場合には多くの行列演算をそのまま適用できる。\n\nrbind(df, c(3, \"a\"))\n##                     x y\n## 1   -1.59044687979437 a\n## 2    0.86393292829801 b\n## 3  -0.909474811146383 c\n## 4    1.61475414815077 d\n## 5   -1.04078453727943 e\n## 6   -1.31684258870488 f\n## 7   0.813842814516403 g\n## 8   -1.03502966174611 h\n## 9  -0.555010836619845 i\n## 10 -0.641290099958665 j\n## 11                  3 a\n\nこの例では文字列を含めているため、列全体が文字列に変換される点に注意する。 また rbind() では列名が一致している必要があり、行名は自動で連番が振られる（既存の行名と重複すると make.unique() により調整される）。\n\ncbind(df, z = runif(10))\n##             x y          z\n## 1  -1.5904469 a 0.79869160\n## 2   0.8639329 b 0.35118441\n## 3  -0.9094748 c 0.89055824\n## 4   1.6147541 d 0.57836328\n## 5  -1.0407845 e 0.17851060\n## 6  -1.3168426 f 0.25929297\n## 7   0.8138428 g 0.82006635\n## 8  -1.0350297 h 0.21618446\n## 9  -0.5550108 i 0.10043653\n## 10 -0.6412901 j 0.04984035\n\n列方向に結合すると列数が増えるため、追加するベクトルの長さが行数と一致しているか確認しておくと安心である。長さが一致しない場合はリサイクル規則が働くか、条件によっては警告・エラーになる。\n転置をとると行列として出力される。データフレイムに文字列や因子が含まれている場合、すべて文字列に変換される点に注意する。\n\nt(df)\n##   [,1]         [,2]         [,3]         [,4]         [,5]         [,6]        \n## x \"-1.5904469\" \" 0.8639329\" \"-0.9094748\" \" 1.6147541\" \"-1.0407845\" \"-1.3168426\"\n## y \"a\"          \"b\"          \"c\"          \"d\"          \"e\"          \"f\"         \n##   [,7]         [,8]         [,9]         [,10]       \n## x \" 0.8138428\" \"-1.0350297\" \"-0.5550108\" \"-0.6412901\"\n## y \"g\"          \"h\"          \"i\"          \"j\"\n\n構成要素が数値または論理値のみであれば、同じ次元のデータフレイム同士で要素ごとの四則演算が可能となる。ただし、線形代数で使う行列演算を行いたい場合は as.matrix() で行列に変換してから計算する必要がある。\n同様に、列・行ごとの合計や平均も数値・論理値で構成されていれば利用できる。\n\ndff &lt;- data.frame(a = 1:5, b = c(TRUE, TRUE, TRUE, FALSE, FALSE))\ncolSums(dff)\n##  a  b \n## 15  3\nrowSums(dff)\n## [1] 2 3 4 4 5\n\n返り値はベクトルである。全要素の合計を求める場合は sum() を使えばよい。\n\nsum(dff)\n## [1] 18\n\n平均値も同様に計算できる。\n\ncolMeans(dff)\n##   a   b \n## 3.0 0.6\nrowMeans(dff)\n## [1] 1.0 1.5 2.0 2.0 2.5\n\n\n\n5.4.2 データフレイムのアクセス\nデータフレイムに対して 1 つの角括弧でインデックスを指定すると、常にデータフレイムとして戻ってくる。\n\ndf[\"x\"]\n##             x\n## 1  -1.5904469\n## 2   0.8639329\n## 3  -0.9094748\n## 4   1.6147541\n## 5  -1.0407845\n## 6  -1.3168426\n## 7   0.8138428\n## 8  -1.0350297\n## 9  -0.5550108\n## 10 -0.6412901\n\ndf[1] としても同じである。\nベクトルとして取り出したい場合は $ や二重角括弧を使う。\n\ndf$x\n##  [1] -1.5904469  0.8639329 -0.9094748  1.6147541 -1.0407845 -1.3168426\n##  [7]  0.8138428 -1.0350297 -0.5550108 -0.6412901\n\ndf[[\"x\"]]、df[[1]]、df[, \"x\"]、df[, 1] など、さまざまな書き方が選べる。\n変数 x の 5 番目の要素を取り出して別の値 100 を代入するには次のようにする。\n\ndf$x[5] &lt;- 100\n\n同様に df[[\"x\"]][5]、df[[1]][5]、df[5, \"x\"]、df[5, 1] でも操作できる。\nデータフレイム内の変数に関数を適用する例として、平均値を求める場合を示す。\n\nmean(df$x)\n## [1] 9.724444\n\nwith() を使えば、データフレイムを指定したうえで列名だけで参照することもできる。\n\nwith(df, mean(x))\n## [1] 9.724444\n\nなお attach() によってデータフレイムを検索パスに追加する方法もあるが、意図しない変数の上書きにつながるため現在では推奨されない。\n列を削除したい場合は NULL を代入する。\n\ndf$x &lt;- NULL\n\n複雑な条件で行や列を抽出したいときは、subset() や dplyr::filter()／select() といった関数を併用すると記述が読みやすくなる。",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>データ構造</span>"
    ]
  },
  {
    "objectID": "05-datainput.html",
    "href": "05-datainput.html",
    "title": "6  データ入力",
    "section": "",
    "text": "6.1 はじめに\nR においてデータ分析を行うには、まずデータを R に取り込む必要がある。 R や一部のパッケージにはサンプルデータが同梱されているものの、実務では外部ファイルから読み込むケースが主流である。読み込まれたデータは、基本的にデータフレーム (data.frame) として扱われる。\nデータフレームは、同じ長さのベクトルを組み合わせたリストである。たとえば次のように作成できる。\ndf &lt;- data.frame(x = rnorm(10), y = letters[1:10])\nstr(df)\n## 'data.frame':    10 obs. of  2 variables:\n##  $ x: num  -1.233 1.435 -0.111 -2.454 0.695 ...\n##  $ y: chr  \"a\" \"b\" \"c\" \"d\" ...\nかつての data.frame() は文字列を自動的に因子に変換していた。これを避けるには stringsAsFactors = FALSE を明示する。\ndf &lt;- data.frame(x = rnorm(10), y = letters[1:10], stringsAsFactors= FALSE)\nstr(df)\n## 'data.frame':    10 obs. of  2 variables:\n##  $ x: num  1.52 -1.39 -1.55 -1.35 0.47 ...\n##  $ y: chr  \"a\" \"b\" \"c\" \"d\" ...\nあるいは dplyr パッケージの data_frame()（現行では tibble() が推奨）を使えば、オプションなしで文字列を文字列のまま保持できる。\nlibrary(dplyr)\ndf &lt;- data_frame(x = rnorm(10), y = letters[1:10])\nstr(df)\n## tibble [10 × 2] (S3: tbl_df/tbl/data.frame)\n##  $ x: num [1:10] 0.0425 2.0436 -0.2087 -1.0898 -0.9212 ...\n##  $ y: chr [1:10] \"a\" \"b\" \"c\" \"d\" ...\ntibble() は列名にスペースが含まれていても自動補正せずに扱え、print() 時に一部だけ表示してくれるため大規模データの確認がしやすい。\n以下ではファイル形式ごとに読み込み方法をまとめる。共通して重要なのは、現在のワーキングディレクトリとファイルの所在を正しく把握することだ。\n現在のワーキングディレクトリは以下のコマンドで確認できる.\ngetwd()\nワーキングディレクトリを変更するには setwd() を使う。 プロジェクト内で常に同じ相対パスを使いたい場合は、here パッケージを使ってプロジェクトルートを基準に指定する方法も有効である。\n例えば、現在のワーキングディレクトリが C:/Users/kenji/work/project で、データ data.csv が C:/Users/kenji/work/project/data にあるとする。\ndf &lt;- read.table(\"work/data.csv\", header=TRUE, sep = \",\")\nこのまま読み込むか、先にワーキングディレクトリを目的のフォルダへ変更する必要がある。\nsetwd(\"C:/Users/kenji/work/project/data\")\ndf &lt;- read.table(\"data.csv\", header=TRUE, sep = \",\")\nRStudio ではメニューバーの「File」&gt;「Import Dataset」からウィザード形式でファイルを読み込める。 インポート時に生成されたコードは History ペインから確認できるため、再現性のためにも控えておくとよい。",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>データ入力</span>"
    ]
  },
  {
    "objectID": "05-datainput.html#csv-ファイル",
    "href": "05-datainput.html#csv-ファイル",
    "title": "6  データ入力",
    "section": "6.2 csv ファイル",
    "text": "6.2 csv ファイル\ncsv は comma-separated values の略で、その名の通りカンマ区切りのテキストファイルである。\nvar1, var2, var3\n3, 4,\"text\"\n4, 4, \"text\"\n...\n先頭行に列名が含まれることが多いが、ないケースもあるので事前確認が必要だ。他ソフトで作成したデータを CSV で保存すれば、R から容易に読み込める。\nCSV を読み込む基本的な手段は read.table() を使うこと（スペルに注意）。\n\ndf &lt;- read.table(\"data.csv\", header=TRUE, sep = \",\")\n\nこのコードでオブジェクト df にデータフレームとして読み込まれる。\nread.csv() を使えば、区切り文字やヘッダー有無の指定を省ける。\n\ndf &lt;- read.csv(\"data.csv\")\n\nただし read.csv() は列名に重複があると自動で X を付けて補正する。原データの列名をそのまま使いたい場合は check.names = FALSE を指定する。\n外部ファイルを読み込むと文字列が因子に変換される場合があるので、不要なら stringsAsFactors = FALSE を指定する。\n\ndf &lt;- read.csv(\"data.csv\", stringsAsFactors= FALSE)\n\n書き出すときは次のようにする。\n\nwrite.csv(df,\"data.csv\", row.names = FALSE)\n\nここでは行名が 1 列目に書き込まれないよう、row.names = FALSE を指定している。\n高速で柔軟な readr パッケージを使う方法もある。読み込みは次の通り。\n\nlibrary(readr)\ndf &lt;- read_csv(\"data.csv\")\n\nこちらは既定で文字列を因子化しない。 また read_csv() は列型を自動推定するが、必要に応じて col_types で明示的に指定できる。\n書き込みは次の通り。\n\nwrite_csv(df,\"data.csv\")\n\n特にオプションをつけなくても, rownames は書き込まない.\n日本語が含まれる CSV ファイルは文字コードに注意が必要である。詳細は次節で述べる。",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>データ入力</span>"
    ]
  },
  {
    "objectID": "05-datainput.html#excel-ファイル",
    "href": "05-datainput.html#excel-ファイル",
    "title": "6  データ入力",
    "section": "6.3 EXCEL ファイル",
    "text": "6.3 EXCEL ファイル\nExcel はビジネスで広く使われるスプレッドシートであり、R からもデータを扱える。\n最近の Excel ファイルは拡張子が xlsx で、readxl パッケージを使えば簡単に読み込める。\n\nlibrary(readxl)\ndf &lt;- read_excel(\"data.xlsx\",1)\n\nこの例では data.xlsx の 1 枚目のシートを読み込んでいる。\n直接シート名を指定することができる.\n\nread_excel(\"data.xlsx\",\"Revenues\")\n\nこちらは「Revenues」というシート名を指定している。\nExcel から取り込む場合は、1 行目を列名にし、各列でデータ型を揃えておく。最終行に合計行などがあると数値として取り込まれてしまうので注意。\nExcel ファイルを一度 CSV に変換してから読み込む方法もあるが、いくつか注意点がある。 主な注意点は 2 つある。 1 つ目は、桁区切りのカンマが入ったまま保存すると文字列として扱われること。read.csv() で数値として読み込みたい場合は、事前にカンマを削除して保存する（read_csv() なら自動で数値化されることが多い）。\n2 つ目は、ファイルを CSV に変換すると Shift_JIS で保存される場合がある点である。Linux や macOS（あるいは UTF-8 を標準とする環境）では文字化けするため、read.csv() で読み込む際は\n\ndf &lt;- read.csv(\"data.csv\", stringAsFactors=FALSE, fileEncoding=\"SJIS\")\n\nとし、read_csv() を使う場合は\n\ndf &lt;- read_csv(\"data.csv\", locale=locale(encoding = \"SJIS\"))\n\nと指定する。\n経験上、readxl は日本語を適切に扱ってくれるため、日本語が含まれる場合は無理に CSV に変換せず、Excel ファイルのまま読み込む方が安全である。 複数シートをまとめて読み込みたい場合は excel_sheets() でシート一覧を取得し、map() と組み合わせてループすると効率的である。",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>データ入力</span>"
    ]
  },
  {
    "objectID": "05-datainput.html#stata",
    "href": "05-datainput.html#stata",
    "title": "6  データ入力",
    "section": "6.4 STATA",
    "text": "6.4 STATA\nStata は実証研究で広く使われる統計ソフトで、R でもデータを読み込める。\nStata のデータは拡張子 .dta で、foreign パッケージなどを用いて読み込む。\n\nlibrary(foreign)\ndf &lt;- read.dta(\"data.dta\")\n\nただ, 最新の Stata には対応していない. 最新の Stata に対応するにはライブラリ haven を導入する.\n\nlibrary(haven)\ndf &lt;- read_dta(\"data.dta\")\n\nhaven では write_dta() を使って R のデータを Stata 形式で書き出すこともできる。\n他にも SAS や SPSS などの統計パッケージのデータも取り込むことができる. haven には read_sas() や read_sav() など、各種形式に対応した関数が揃っている。",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>データ入力</span>"
    ]
  },
  {
    "objectID": "05-datainput.html#r-に入っているデータ",
    "href": "05-datainput.html#r-に入っているデータ",
    "title": "6  データ入力",
    "section": "6.5 R に入っているデータ",
    "text": "6.5 R に入っているデータ\nR およびパッケージにはいくつかのデータがはいっている. どのようなデータが利用可能かは以下のコマンドで調べることができる.\n\ndata()\n\nそれがどのような変数が含まれているのかを調べるには, help を使えばよい.\n\nhelp(cars)\n\n\n\n\n\n\n\n\n\n\nパッケージに含まれるデータセットは data() を使ってロードする。\n\nlibrary(AER)\ndata(CPS1985)\nsummary(CPS1985)\n##       wage          education       experience         age       \n##  Min.   : 1.000   Min.   : 2.00   Min.   : 0.00   Min.   :18.00  \n##  1st Qu.: 5.250   1st Qu.:12.00   1st Qu.: 8.00   1st Qu.:28.00  \n##  Median : 7.780   Median :12.00   Median :15.00   Median :35.00  \n##  Mean   : 9.024   Mean   :13.02   Mean   :17.82   Mean   :36.83  \n##  3rd Qu.:11.250   3rd Qu.:15.00   3rd Qu.:26.00   3rd Qu.:44.00  \n##  Max.   :44.500   Max.   :18.00   Max.   :55.00   Max.   :64.00  \n##     ethnicity     region       gender         occupation            sector   \n##  cauc    :440   south:156   male  :289   worker    :156   manufacturing: 99  \n##  hispanic: 27   other:378   female:245   technical :105   construction : 24  \n##  other   : 67                            services  : 83   other        :411  \n##                                          office    : 97                      \n##                                          sales     : 38                      \n##                                          management: 55                      \n##  union     married  \n##  no :438   no :184  \n##  yes: 96   yes:350  \n##                     \n##                     \n##                     \n##",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>データ入力</span>"
    ]
  },
  {
    "objectID": "05-datainput.html#インターネットからデータ入力",
    "href": "05-datainput.html#インターネットからデータ入力",
    "title": "6  データ入力",
    "section": "6.6 インターネットからデータ入力",
    "text": "6.6 インターネットからデータ入力\nWeb スクレイピングや公式 API を利用すれば、インターネット上のデータを直接取得できる。代表的なデータベースと対応パッケージをいくつか挙げておく。\n\nYahoo! Finance (quantmod)\nYahoo! Finance Japan (RFinanceYJ)\nWorld Development Indicators (WDI)\nEurostat (eurostat)\ne-stat (estatap) 金融データの取得には tidyquant、世界銀行の指標には WDI、地理統計には sf パッケージなど、用途に応じたラッパーが多数存在する。\n\nURL を直接指定してファイルを読み込むことも可能である。\n\nlibrary(haven)\nURL &lt;- \"http://fmwww.bc.edu/ec-p/data/wooldridge/attend.dta\"\ndf &lt;-read_dta(URL)\n\nローカルに保存しておきたい場合は download.file() を併用するとよい。\n\nif(!file.exists(\"mroz.dta\")) download.file(URL, \"mroz.dta\",method=\"curl\")\nlibrary(haven)\ndf &lt;- read_dta(\"mroz.dta\")\n\nダウンロードに時間がかかる場合は、destfile を分かりやすいパスに設定し、mode = \"wb\"（バイナリモード）を指定するのが安全である。",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>データ入力</span>"
    ]
  },
  {
    "objectID": "05-datainput.html#その他のデータ入力",
    "href": "05-datainput.html#その他のデータ入力",
    "title": "6  データ入力",
    "section": "6.7 その他のデータ入力",
    "text": "6.7 その他のデータ入力\nR 専用のバイナリファイル（.RData や .rds）として保存していれば、load() や readRDS() で高速に読み込むことができる。\nさらに、DBI・RSQLite・odbc などのパッケージを使えばリレーショナルデータベースに接続してデータを取得できる。環境やニーズに応じて適切なドライバーを選ぶとよい。",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>データ入力</span>"
    ]
  },
  {
    "objectID": "07-regression1.html",
    "href": "07-regression1.html",
    "title": "8  古典的仮定のもとでの最小二乗法",
    "section": "",
    "text": "8.1 単回帰モデル\nまず次の単回帰モデルを考える。\n\\[\ny = \\alpha + \\beta x + u\n\\] ここで \\(x\\) は説明変数、\\(y\\) は被説明変数、\\(u\\) は誤差項である。 パラメータとして \\(\\alpha\\) は切片パラメータ、\\(\\beta\\) は傾きパラメータである。\n以下の仮定を置く。\nこれらの仮定の下では、最小二乗推定量は一致性と不偏性を持ち、さらに正規分布に従う。 一致（consistency）とは、観測数が多くなるにつれて推定量が真のパラメータに確率収束する性質である。 不偏性とは、推定量の期待値が真のパラメータに等しくなることである。 さらに、他の線形不偏推定量の中で最小の分散を持つ（BLUE: best linear unbiased estimator）。\n以降ではシミュレーションデータを用いて具体的に確認する。 ここでは標本サイズを100とし、説明変数 \\(x\\) は0から1の一様分布から生成する。 被説明変数 \\(y\\) は真の切片パラメータを10, 真の傾きパラメータを2として、正規分布の誤差項を加えて生成する。 最後にこれらのデータを data.frame 関数でデータフレームにまとめる。\nN &lt;- 100\nx &lt;- runif(N)\ny &lt;- 10 + 2*x + rnorm(N)\ndf &lt;- data.frame(x,y)\n散布図を描くと次のようになる。 plot に y ~ x と指定すると、横軸に説明変数、縦軸に被説明変数を取った散布図が描かれる。\nplot(y~x)\nR で回帰分析を実施するには lm 関数を使用する。 第一引数には回帰式を y ~ x という形式で指定し、data 引数にはデータフレームを指定する。 推定結果は fm というオブジェクトに保存する。\nfm &lt;- lm(y ~ x, data=df)\nfm はリストとして保存されており、以下のような要素を持つ。 typeof() でオブジェクトの型を、names() で各要素名を確認できる。\ntypeof(fm)\n## [1] \"list\"\nnames(fm)\n##  [1] \"coefficients\"  \"residuals\"     \"effects\"       \"rank\"         \n##  [5] \"fitted.values\" \"assign\"        \"qr\"            \"df.residual\"  \n##  [9] \"xlevels\"       \"call\"          \"terms\"         \"model\"\n推定された係数（切片と傾き）を取り出すには coef() 関数を使用する。 coefficients() 関数でも同じ結果が得られる（コメントアウトしている）。\ncoef(fm)\n## (Intercept)           x \n##    9.568045    2.549923\n# coefficients(fm)\n傾きの推定値は、説明変数と被説明変数の共分散を説明変数の分散で割ることで求められる。 with() 関数を使ってデータフレーム内の変数を直接参照し、cov() 関数で共分散、var() 関数で分散を計算する。\nwith(df, cov(x,y)/var(x))\n## [1] 2.549923\n散布図に推定直線を重ねるには、まず plot() 関数で散布図を描き、続いて abline() 関数に lm オブジェクトを渡す。 abline() 関数に lm オブジェクトを渡すと自動的に回帰直線が描画される。\nplot(y~x,data=df)\nabline(fm)\n残差（実際の値と予測値の差）は resid() 関数で取得できる。 ここでは head() 関数で最初の6つの値のみを表示している。 residuals() 関数でも同じ結果が得られる（コメントアウトしている）。\nhead(resid(fm))\n##           1           2           3           4           5           6 \n## -0.48971014 -0.05244463  0.47292468  0.83442222  0.25085401 -0.24516296\n# residuals(fm)\n# with(fm, residuals)\n予測値（\\(\\hat{y}\\)）は fitted() 関数によって得られる。 ここでは head() 関数で最初の6つの値のみを表示している。 fitted.values でも同じ結果が得られる（コメントアウトしている）。\nhead(fitted(fm))\n##        1        2        3        4        5        6 \n## 11.59105 11.50346 12.10791 10.45049 11.17337 10.68755\n# fitted.values(fm)\n# with(fm, fitted.values)\n最小二乗法の性質として、予測値の平均は被説明変数の平均と等しいことが知られている。 以下のコマンドで両者が一致することを確認できる。\nmean(fitted(fm))\n## [1] 10.79963\nmean(df$y)\n## [1] 10.79963\n残差自乗和（residual sum of squares）を計算するには deviance() 関数を使用する。 これは残差を二乗して合計した値であり、sum(resid(fm)^2) で直接計算することもできる。\ndeviance(fm)\n## [1] 78.57132\nsum(resid(fm)^2)\n## [1] 78.57132\n残差自乗和は残差変動とも呼ばれる。 予測値の偏差の自乗和を回帰変動、被説明変数の偏差の自乗和を全変動という。 全変動は回帰変動と残差変動に分解できる（変動の分解）。 以下のコマンドで、左辺の全変動が右辺の回帰変動と残差変動の和に等しいことを確認できる。\nsum((df$y-mean(df$y))^2)\n## [1] 138.4464\nsum((fitted(fm)-mean(df$y))^2)+deviance(fm)\n## [1] 138.4464",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>古典的仮定のもとでの最小二乗法</span>"
    ]
  },
  {
    "objectID": "07-regression1.html#単回帰モデル",
    "href": "07-regression1.html#単回帰モデル",
    "title": "8  古典的仮定のもとでの最小二乗法",
    "section": "",
    "text": "\\((x_i, y_i)\\) は独立同一分布に従う。\n\\(E[u_i] = 0\\) である。\n\\(u_i\\) と \\(x_i\\) は独立である。\n\\(u_i\\) は正規分布に従う。\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n8.1.1 ティー検定\n推定結果を詳しく確認するには summary() 関数を利用する。 これにより係数の推定値、標準誤差、t値、p値などが表示される。\n\nsummary(fm)\n## \n## Call:\n## lm(formula = y ~ x, data = df)\n## \n## Residuals:\n##     Min      1Q  Median      3Q     Max \n## -1.9347 -0.5552 -0.1446  0.5642  2.5379 \n## \n## Coefficients:\n##             Estimate Std. Error t value Pr(&gt;|t|)    \n## (Intercept)   9.5680     0.1683  56.848  &lt; 2e-16 ***\n## x             2.5499     0.2951   8.642 1.06e-13 ***\n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n## \n## Residual standard error: 0.8954 on 98 degrees of freedom\n## Multiple R-squared:  0.4325, Adjusted R-squared:  0.4267 \n## F-statistic: 74.68 on 1 and 98 DF,  p-value: 1.064e-13\n\n出力には主に次の指標が含まれる。\n\nCoefficients: 係数の推定値、標準誤差、t値、p値（係数がゼロであるとの仮説に対する t 検定）\nResidual standard error: 残差標準誤差\nMultiple R-squared: 決定係数（当てはまりの良さ）\nAdjusted R-squared: 修正済み決定係数（説明変数の数を考慮した指標）\nF-statistic: 全係数がゼロであるとの仮説に対する F 検定\n\nsummary(fm) もリストであり、typeof() 関数と names() 関数でその構造を確認できる。\n\ntypeof(summary(fm))\n## [1] \"list\"\nnames(summary(fm))\n##  [1] \"call\"          \"terms\"         \"residuals\"     \"coefficients\" \n##  [5] \"aliased\"       \"sigma\"         \"df\"            \"r.squared\"    \n##  [9] \"adj.r.squared\" \"fstatistic\"    \"cov.unscaled\"\n\n単なる fm と同じ名前の要素もあるが、中身が違っている場合がある。 たとえば residuals は同じだが、係数には標準誤差やt値などの情報が付与される。 coef() 関数を summary(fm) に適用すると、これらの情報を含む行列が得られる。\n\ncoef(summary(fm))\n##             Estimate Std. Error   t value     Pr(&gt;|t|)\n## (Intercept) 9.568045  0.1683090 56.848105 7.651686e-77\n## x           2.549923  0.2950685  8.641799 1.063759e-13\n# coefficients(summary(fm))\n\n残差標準誤差（residual standard error）は summary(fm)$sigma から取得できる。 これは残差自乗和を残差の自由度で割った値の平方根である。\n\nwith(summary(fm),sigma)\n## [1] 0.8954039\nsqrt(deviance(fm)/df.residual(fm))\n## [1] 0.8954039\n\n決定係数（R-squared）は summary(fm)$r.squared に格納されている。 これは 1 から (残差変動/全変動) を引いた値として計算される。\n\nwith(summary(fm),r.squared)\n## [1] 0.4324785\n1-deviance(fm)/with(df, sum((y-mean(y))^2))\n## [1] 0.4324785\n\n調整済み決定係数（adjusted R-squared）は summary(fm)$adj.r.squared から得られる。 これは決定係数を自由度で調整した値であり、説明変数の数が増えても必ずしも増加しない性質を持つ。\n\nwith(summary(fm),adj.r.squared)\n## [1] 0.4266875\n1-(deviance(fm)/df.residual(fm))/with(df, sum((y-mean(y))^2/(nrow(df)-1)))\n## [1] 0.4266875\n\n\n\n8.1.2 対数変換\n次のモデルを考える。 \\[\ny = \\alpha + \\beta \\log(x) + u\n\\]\n説明変数を対数変換する場合、lm() 関数の式の中で直接 log() 関数を使用できる。 この場合、係数 \\(\\beta\\) は \\(x\\) が1%変化したときの \\(y\\) の変化量 (の近似値) を表す。\n\nfm &lt;- lm(y~log(x),data=df)\nsummary(fm)\n## \n## Call:\n## lm(formula = y ~ log(x), data = df)\n## \n## Residuals:\n##      Min       1Q   Median       3Q      Max \n## -1.92314 -0.63915 -0.04109  0.48261  2.82712 \n## \n## Coefficients:\n##             Estimate Std. Error t value Pr(&gt;|t|)    \n## (Intercept) 11.45581    0.13720  83.497  &lt; 2e-16 ***\n## log(x)       0.59499    0.08719   6.824 7.41e-10 ***\n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n## \n## Residual standard error: 0.9786 on 98 degrees of freedom\n## Multiple R-squared:  0.3221, Adjusted R-squared:  0.3152 \n## F-statistic: 46.56 on 1 and 98 DF,  p-value: 7.41e-10\n\n散布図と回帰直線を描くと以下のようになる。 横軸が対数変換された \\(x\\) になっている点に注意。\n\nplot(y~log(x),data=df)\nabline(fm)\n\n\n\n\n\n\n\n\n被説明変数を対数変換する場合も同様に、lm() 関数の式の中で log() 関数を使用する。 この場合、係数 \\(\\beta\\) は \\(x\\) が1単位変化したときの \\(y\\) の変化率 (%) の近似値を表す。\n\nfm &lt;- lm(log(y)~x,data=df)\nsummary(fm)\n## \n## Call:\n## lm(formula = log(y) ~ x, data = df)\n## \n## Residuals:\n##       Min        1Q    Median        3Q       Max \n## -0.184230 -0.050112 -0.009799  0.057518  0.201141 \n## \n## Coefficients:\n##             Estimate Std. Error t value Pr(&gt;|t|)    \n## (Intercept)  2.26013    0.01542 146.567  &lt; 2e-16 ***\n## x            0.23503    0.02703   8.694 8.22e-14 ***\n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n## \n## Residual standard error: 0.08204 on 98 degrees of freedom\n## Multiple R-squared:  0.4354, Adjusted R-squared:  0.4297 \n## F-statistic: 75.58 on 1 and 98 DF,  p-value: 8.22e-14\n\n散布図と回帰直線を描くと以下のようになる。 縦軸が対数変換された \\(y\\) になっている点に注意。\n\nplot(log(y)~x,data=df)\nabline(fm)\n\n\n\n\n\n\n\n\n被説明変数と説明変数の両方を対数変換する場合 (対数線形モデル) は以下のようにする。 この場合、係数 \\(\\beta\\) は弾力性を表し、\\(x\\) が1%変化したときの \\(y\\) の変化率 (%) を表す。\n\nfm &lt;- lm(log(y)~log(x),data=df)\nsummary(fm)\n## \n## Call:\n## lm(formula = log(y) ~ log(x), data = df)\n## \n## Residuals:\n##       Min        1Q    Median        3Q       Max \n## -0.183934 -0.056842 -0.001139  0.048238  0.227008 \n## \n## Coefficients:\n##             Estimate Std. Error t value Pr(&gt;|t|)    \n## (Intercept) 2.435113   0.012483 195.071  &lt; 2e-16 ***\n## log(x)      0.055733   0.007933   7.025 2.85e-10 ***\n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n## \n## Residual standard error: 0.08904 on 98 degrees of freedom\n## Multiple R-squared:  0.3349, Adjusted R-squared:  0.3281 \n## F-statistic: 49.35 on 1 and 98 DF,  p-value: 2.852e-10\n\n散布図と回帰直線を描くと以下のようになる。 両軸とも対数変換されている点に注意。\n\nplot(log(y)~log(x),data=df)\nabline(fm)\n\n\n\n\n\n\n\n\n\n\n8.1.3 切片なし回帰モデル\n次のモデルを考える。 \\[\ny = \\beta x + u\n\\]\n切片を含まないモデルを推定したい場合は、式の中に -1 を加える。 これにより切片項が除外され、原点を通る回帰直線が推定される。\n\nfm &lt;- lm(y~x-1,data=df)\nsummary(fm)\n## \n## Call:\n## lm(formula = y ~ x - 1, data = df)\n## \n## Residuals:\n##    Min     1Q Median     3Q    Max \n## -4.817 -1.456  3.107  6.547  9.763 \n## \n## Coefficients:\n##   Estimate Std. Error t value Pr(&gt;|t|)    \n## x  16.7533     0.9104    18.4   &lt;2e-16 ***\n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n## \n## Residual standard error: 5.193 on 99 degrees of freedom\n## Multiple R-squared:  0.7738, Adjusted R-squared:  0.7715 \n## F-statistic: 338.7 on 1 and 99 DF,  p-value: &lt; 2.2e-16\n\n+0 を加えても同じ効果が得られる。\n\nfm &lt;- lm(y~x+0,data=df)\nsummary(fm)\n## \n## Call:\n## lm(formula = y ~ x + 0, data = df)\n## \n## Residuals:\n##    Min     1Q Median     3Q    Max \n## -4.817 -1.456  3.107  6.547  9.763 \n## \n## Coefficients:\n##   Estimate Std. Error t value Pr(&gt;|t|)    \n## x  16.7533     0.9104    18.4   &lt;2e-16 ***\n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n## \n## Residual standard error: 5.193 on 99 degrees of freedom\n## Multiple R-squared:  0.7738, Adjusted R-squared:  0.7715 \n## F-statistic: 338.7 on 1 and 99 DF,  p-value: &lt; 2.2e-16",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>古典的仮定のもとでの最小二乗法</span>"
    ]
  },
  {
    "objectID": "07-regression1.html#重回帰モデル",
    "href": "07-regression1.html#重回帰モデル",
    "title": "8  古典的仮定のもとでの最小二乗法",
    "section": "8.2 重回帰モデル",
    "text": "8.2 重回帰モデル\n説明変数として \\(w\\) を加えたモデルを考える。 \\[\ny = \\alpha + \\beta x +\\gamma w+ u\n\\]\n暗黙に以下の仮定を置く。\n\n\\((w_i, x_i,y_i)\\) は独立同一分布にしたがう。\n誤差項の期待値はゼロである。\\(E[u_i]=0\\) である。\n誤差項 \\(u_i\\) は説明変数 \\((x_i, w_i)\\) に対して独立である。\n誤差項 \\(u_i\\) は正規分布にしたがう。\n説明変数間に多重共線性は存在しない。つまり \\(x_i\\) は \\(w_i\\) の一次変換で表せない。\n\n以降ではシミュレーションデータを用いて具体的に確認する。 標本サイズを100とし、説明変数 \\(x\\) は0から1の一様分布から、\\(w\\) は「H」と「T」からランダムに生成する。 被説明変数 \\(y\\) は、真の切片を10, \\(x\\) の係数を2, \\(w\\) が「H」のときに1を加算し、正規分布の誤差項を加えて生成する。\n\nN &lt;- 100\nx&lt;-runif(N)\nw&lt;-sample(c(\"H\",\"T\"),N,replace=TRUE)\ny &lt;- 10 + 2*x + ifelse(w==\"H\",1,0) + rnorm(N)\ndf &lt;- data.frame(w,x,y)\n\n複数の説明変数を含むモデルを推定するには、+ 記号で変数を連結する。 式 y~x+w は被説明変数 \\(y\\) を説明変数 \\(x\\) と \\(w\\) で回帰することを意味する。\n\nfm &lt;- lm(y~x+w,data=df)\nsummary(fm)\n## \n## Call:\n## lm(formula = y ~ x + w, data = df)\n## \n## Residuals:\n##     Min      1Q  Median      3Q     Max \n## -2.2017 -0.6185 -0.0443  0.7154  2.7084 \n## \n## Coefficients:\n##             Estimate Std. Error t value Pr(&gt;|t|)    \n## (Intercept)  11.0085     0.2203  49.966  &lt; 2e-16 ***\n## x             1.8553     0.3567   5.202 1.10e-06 ***\n## wT           -0.9209     0.2058  -4.475 2.08e-05 ***\n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n## \n## Residual standard error: 1.013 on 97 degrees of freedom\n## Multiple R-squared:  0.2944, Adjusted R-squared:  0.2799 \n## F-statistic: 20.24 on 2 and 97 DF,  p-value: 4.51e-08\n\nR の特徴として、因子型 (factor) やカテゴリカル変数 (文字列) を特に変換することなく自動的にダミー変数として扱える。 ここでは \\(w\\) が「H」と「T」の2値をとるが、自動的に一方 (「H」) のダミー変数が作成され、「T」が基準カテゴリとなる。\n\n8.2.1 自乗項\n説明変数として自乗項を加えたモデルを考える。 \\[\ny = \\alpha + \\beta x + \\gamma x^2 + u\n\\]\n自乗項を含めるときは I(x^2) のように I() で囲む。 これは ^ が式中で特別扱いされるため、通常の演算として解釈させる工夫である。\n\nfm &lt;- lm(y~x+I(x^2),data=df)\nsummary(fm)\n## \n## Call:\n## lm(formula = y ~ x + I(x^2), data = df)\n## \n## Residuals:\n##      Min       1Q   Median       3Q      Max \n## -2.29644 -0.74171 -0.09684  0.87885  3.08989 \n## \n## Coefficients:\n##              Estimate Std. Error t value Pr(&gt;|t|)    \n## (Intercept) 10.897947   0.328395  33.185   &lt;2e-16 ***\n## x            0.004945   1.610615   0.003    0.998    \n## I(x^2)       1.650161   1.627752   1.014    0.313    \n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n## \n## Residual standard error: 1.107 on 97 degrees of freedom\n## Multiple R-squared:  0.1577, Adjusted R-squared:  0.1403 \n## F-statistic: 9.079 on 2 and 97 DF,  p-value: 0.0002431\n\n\n\n8.2.2 交差項\n説明変数として交差項 (interaction term) を加えたモデルを考える。 \\[\ny = \\alpha + \\beta x + \\gamma w + \\delta xw + u\n\\]\n交差項（interaction）は : を使って x:w と表記する。 このモデルでは主効果 x と w に加えて、交差項 x:w を明示的に指定している。\n\nfm&lt;-lm(y~x+w+x:w,data=df)\nsummary(fm)\n## \n## Call:\n## lm(formula = y ~ x + w + x:w, data = df)\n## \n## Residuals:\n##      Min       1Q   Median       3Q      Max \n## -2.10137 -0.64568 -0.06997  0.72200  2.62761 \n## \n## Coefficients:\n##             Estimate Std. Error t value Pr(&gt;|t|)    \n## (Intercept)  11.1460     0.2638  42.246  &lt; 2e-16 ***\n## x             1.5554     0.4769   3.262  0.00153 ** \n## wT           -1.2698     0.4217  -3.011  0.00332 ** \n## x:wT          0.6816     0.7189   0.948  0.34544    \n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n## \n## Residual standard error: 1.013 on 96 degrees of freedom\n## Multiple R-squared:  0.301,  Adjusted R-squared:  0.2791 \n## F-statistic: 13.78 on 3 and 96 DF,  p-value: 1.518e-07\n\n* を使えば主要効果と交差項をまとめて指定できる。 x*w は自動的に x + w + x:w に展開される。\n\nfm &lt;- lm(y~x*w,data=df)\nsummary(fm)\n## \n## Call:\n## lm(formula = y ~ x * w, data = df)\n## \n## Residuals:\n##      Min       1Q   Median       3Q      Max \n## -2.10137 -0.64568 -0.06997  0.72200  2.62761 \n## \n## Coefficients:\n##             Estimate Std. Error t value Pr(&gt;|t|)    \n## (Intercept)  11.1460     0.2638  42.246  &lt; 2e-16 ***\n## x             1.5554     0.4769   3.262  0.00153 ** \n## wT           -1.2698     0.4217  -3.011  0.00332 ** \n## x:wT          0.6816     0.7189   0.948  0.34544    \n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n## \n## Residual standard error: 1.013 on 96 degrees of freedom\n## Multiple R-squared:  0.301,  Adjusted R-squared:  0.2791 \n## F-statistic: 13.78 on 3 and 96 DF,  p-value: 1.518e-07\n\n\n\n8.2.3 エフ検定\n今、帰無仮説が \\[\ny = \\alpha + \\beta x + u\n\\] で、対立仮説が \\[\ny = \\alpha + \\beta x + \\gamma w + \\delta xw + u\n\\] となる検定を実施したい。\nこれは複数の係数（ここでは \\(\\gamma\\) と \\(\\delta\\)）が同時にゼロかどうかを調べる F 検定である。 制約付き検定は、制約のあるモデル（帰無仮説）とないモデル（対立仮説）の残差自乗和を比較することで実施できる。 対立仮説（制約なしモデル）の残差自乗和を \\(SSR\\)、自由度を \\(df\\) とする。 自由度は観測数から推定されるパラメータの数 (説明変数の数と切片) を減じた数である。 帰無仮説（制約付きモデル）の残差自乗和を \\(SSR_0\\)、制約の数を \\(q\\) とする。 制約の数は帰無仮説の自由度から対立仮説の自由度を差し引いた数である。 このとき、以下のF値は帰無仮説が正しいもとで自由度 \\((q, df)\\) のF分布にしたがう。 \\[\nF = \\frac{(SSR_0-SSR)/q}{SSR/df}\n\\]\nR でF値を手動で計算するには以下のようにする。 まず両方のモデルを推定し、それぞれの自由度 ($df) と残差自乗和 (deviance) を取り出す。 制約の数 \\(q\\) は両モデルの自由度の差である。 F値は上記の式に従って計算する。\n\nfm0 &lt;- lm(y~x,data=df)\nfm1 &lt;- lm(y~x*w,data=df)\ndof &lt;- fm1$df\nq &lt;- fm0$df-dof\nSSR0 &lt;- deviance(fm0)\nSSR &lt;- deviance(fm1)\n(F &lt;- ((SSR0-SSR)/q)/(SSR/dof))\n## [1] 10.45309\n\nF 値に対する p 値は pf() で計算できる。 pf() は F 分布の累積分布関数で、1 - pf(F, df1, df2) が上側確率（p 値）となる。 第一自由度 (df1) は制約の数 \\(q\\), 第二自由度 (df2) は対立仮説の自由度である。\n\n1-pf(F,df1=q,df2=dof)\n## [1] 7.813076e-05\n\nこれらの手順は anova() 関数を使えば自動で計算できる。 anova() 関数に2つのモデルを渡すと、自動的にF検定を実施し、F値とp値を表示してくれる。\n\nanova(fm0,fm1)\n## Analysis of Variance Table\n## \n## Model 1: y ~ x\n## Model 2: y ~ x * w\n##   Res.Df     RSS Df Sum of Sq      F    Pr(&gt;F)    \n## 1     98 120.039                                  \n## 2     96  98.573  2    21.466 10.453 7.813e-05 ***\n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nモデルの順序を入れ替えても検定統計量や p 値に変わりはない。 ただし残差自乗和の差の符号が変わるため、出力の一部が入れ替わって見える。\n\nanova(fm1,fm0)\n## Analysis of Variance Table\n## \n## Model 1: y ~ x * w\n## Model 2: y ~ x\n##   Res.Df     RSS Df Sum of Sq      F    Pr(&gt;F)    \n## 1     96  98.573                                  \n## 2     98 120.039 -2   -21.466 10.453 7.813e-05 ***\n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>古典的仮定のもとでの最小二乗法</span>"
    ]
  }
]