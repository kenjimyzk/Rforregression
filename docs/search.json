[
  {
    "objectID": "06-datawrangling.html",
    "href": "06-datawrangling.html",
    "title": "7  整然データ",
    "section": "",
    "text": "7.1 データ整形\nまずデータセット mtcars を例に取り、整形の基本操作を確認する。as_tibble() を介して行名を列に移すと、後続の操作が行いやすくなる。\nmtcars_tbl &lt;- mtcars |&gt; \n  as_tibble(rownames = \"model\")\n\nmtcars_tbl |&gt; slice_head(n = 6)\n## # A tibble: 6 × 12\n##   model          mpg   cyl  disp    hp  drat    wt  qsec    vs    am  gear  carb\n##   &lt;chr&gt;        &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n## 1 Mazda RX4     21       6   160   110  3.9   2.62  16.5     0     1     4     4\n## 2 Mazda RX4 W…  21       6   160   110  3.9   2.88  17.0     0     1     4     4\n## 3 Datsun 710    22.8     4   108    93  3.85  2.32  18.6     1     1     4     1\n## 4 Hornet 4 Dr…  21.4     6   258   110  3.08  3.22  19.4     1     0     3     1\n## 5 Hornet Spor…  18.7     8   360   175  3.15  3.44  17.0     0     0     3     2\n## 6 Valiant       18.1     6   225   105  2.76  3.46  20.2     1     0     3     1\nここでは R 4.1 から導入されたパイプ演算子 |&gt; を利用している。従来の %&gt;% と同様に、左辺の結果を右辺の関数に渡す構文である。\ndplyr を使うとデータフレームの処理が大幅に簡潔になる。 変数の抽出には select() を使う。\nmtcars_tbl |&gt; \n  select(model, mpg, disp) |&gt; \n  slice_head(n = 6)\n## # A tibble: 6 × 3\n##   model               mpg  disp\n##   &lt;chr&gt;             &lt;dbl&gt; &lt;dbl&gt;\n## 1 Mazda RX4          21     160\n## 2 Mazda RX4 Wag      21     160\n## 3 Datsun 710         22.8   108\n## 4 Hornet 4 Drive     21.4   258\n## 5 Hornet Sportabout  18.7   360\n## 6 Valiant            18.1   225\n条件に合致した行だけを抽出したい場合は filter() が便利である。\nmtcars_tbl |&gt; \n  select(model, mpg, disp) |&gt; \n  filter(disp &gt; 300)\n## # A tibble: 11 × 3\n##    model                 mpg  disp\n##    &lt;chr&gt;               &lt;dbl&gt; &lt;dbl&gt;\n##  1 Hornet Sportabout    18.7   360\n##  2 Duster 360           14.3   360\n##  3 Cadillac Fleetwood   10.4   472\n##  4 Lincoln Continental  10.4   460\n##  5 Chrysler Imperial    14.7   440\n##  6 Dodge Challenger     15.5   318\n##  7 AMC Javelin          15.2   304\n##  8 Camaro Z28           13.3   350\n##  9 Pontiac Firebird     19.2   400\n## 10 Ford Pantera L       15.8   351\n## 11 Maserati Bora        15     301\nrename() を使えば変数名を変更できる。日本語の列名にも対応している。\nmtcars_tbl |&gt; \n  select(model, mpg, disp) |&gt; \n  rename(`速度` = mpg, `距離` = disp) |&gt; \n  slice_head(n = 6)\n## # A tibble: 6 × 3\n##   model              速度  距離\n##   &lt;chr&gt;             &lt;dbl&gt; &lt;dbl&gt;\n## 1 Mazda RX4          21     160\n## 2 Mazda RX4 Wag      21     160\n## 3 Datsun 710         22.8   108\n## 4 Hornet 4 Drive     21.4   258\n## 5 Hornet Sportabout  18.7   360\n## 6 Valiant            18.1   225\n並べ替えは arrange() で行う。\nmtcars_tbl |&gt; \n  select(model, mpg, disp) |&gt; \n  arrange(mpg) |&gt; \n  slice_head(n = 6)\n## # A tibble: 6 × 3\n##   model                 mpg  disp\n##   &lt;chr&gt;               &lt;dbl&gt; &lt;dbl&gt;\n## 1 Cadillac Fleetwood   10.4   472\n## 2 Lincoln Continental  10.4   460\n## 3 Camaro Z28           13.3   350\n## 4 Duster 360           14.3   360\n## 5 Chrysler Imperial    14.7   440\n## 6 Maserati Bora        15     301\n降順に並べる場合は desc() と組み合わせる。\nmtcars_tbl |&gt; \n  select(model, mpg, disp) |&gt; \n  arrange(desc(mpg)) |&gt; \n  slice_head(n = 6)\n## # A tibble: 6 × 3\n##   model            mpg  disp\n##   &lt;chr&gt;          &lt;dbl&gt; &lt;dbl&gt;\n## 1 Toyota Corolla  33.9  71.1\n## 2 Fiat 128        32.4  78.7\n## 3 Honda Civic     30.4  75.7\n## 4 Lotus Europa    30.4  95.1\n## 5 Fiat X1-9       27.3  79  \n## 6 Porsche 914-2   26   120.\nmutate() を使うと新しい列を追加できる。\nmtcars_tbl |&gt; \n  mutate(gpm = 1 / mpg) |&gt; \n  select(model, mpg, gpm) |&gt; \n  slice_head(n = 6)\n## # A tibble: 6 × 3\n##   model               mpg    gpm\n##   &lt;chr&gt;             &lt;dbl&gt;  &lt;dbl&gt;\n## 1 Mazda RX4          21   0.0476\n## 2 Mazda RX4 Wag      21   0.0476\n## 3 Datsun 710         22.8 0.0439\n## 4 Hornet 4 Drive     21.4 0.0467\n## 5 Hornet Sportabout  18.7 0.0535\n## 6 Valiant            18.1 0.0552\nmutate() は既存列の上書きや複数列の同時作成も可能で、計算や条件分岐をまとめて記述できる点が強みである。\n次の例では、mpg が 20 を超える場合に TRUE を返すブール列を追加している。\nmtcars_tbl |&gt; \n  mutate(is_high_mileage = mpg &gt; 20) |&gt; \n  select(model, mpg, is_high_mileage) |&gt; \n  slice_head(n = 6)\n## # A tibble: 6 × 3\n##   model               mpg is_high_mileage\n##   &lt;chr&gt;             &lt;dbl&gt; &lt;lgl&gt;          \n## 1 Mazda RX4          21   TRUE           \n## 2 Mazda RX4 Wag      21   TRUE           \n## 3 Datsun 710         22.8 TRUE           \n## 4 Hornet 4 Drive     21.4 TRUE           \n## 5 Hornet Sportabout  18.7 FALSE          \n## 6 Valiant            18.1 FALSE\nsummarise() で基本統計量を算出できる。\nmtcars_tbl |&gt; \n  summarise(avg = mean(mpg), \n            sd  = sd(mpg), \n            .groups = \"drop\")\n## # A tibble: 1 × 2\n##     avg    sd\n##   &lt;dbl&gt; &lt;dbl&gt;\n## 1  20.1  6.03\n列名を任意に付けておけば、後続の処理で指標を参照しやすくなる。\nsummarise() に .by を指定すれば、グループごとの集計も容易である。\nmtcars_tbl |&gt; \n  summarise(\n    n   = n(),\n    avg = mean(mpg),\n    sd  = sd(mpg),\n    .by = cyl\n  )\n## # A tibble: 3 × 4\n##     cyl     n   avg    sd\n##   &lt;dbl&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt;\n## 1     6     7  19.7  1.45\n## 2     4    11  26.7  4.51\n## 3     8    14  15.1  2.56",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>整然データ</span>"
    ]
  },
  {
    "objectID": "06-datawrangling.html#データ結合",
    "href": "06-datawrangling.html#データ結合",
    "title": "7  整然データ",
    "section": "7.2 データ結合",
    "text": "7.2 データ結合\ndplyr にはデータフレームを縦横方向に結合したり、キーを用いて結合したりするための関数が揃っている。\n縦方向に結合するには bind_rows() を使う。\n\ndf1 &lt;- tibble(X = 1:2, Y = 1:2)\ndf2 &lt;- tibble(X = 4,   Y = 4)\n\nbind_rows(df1, df2)\n## # A tibble: 3 × 2\n##       X     Y\n##   &lt;dbl&gt; &lt;dbl&gt;\n## 1     1     1\n## 2     2     2\n## 3     4     4\n\n列名と型が一致していれば、欠けている列には自動で NA が補われる。\n横方向に結合する場合は bind_cols() を利用する。\n\ndf3 &lt;- tibble(Z = 5:6)\nbind_cols(df1, df3)\n## # A tibble: 2 × 3\n##       X     Y     Z\n##   &lt;int&gt; &lt;int&gt; &lt;int&gt;\n## 1     1     1     5\n## 2     2     2     6\n\n行数が一致していないとリサイクルされるか警告が出るので注意する。\nキーを用いた結合には四種類の join 関数が利用できる。\n\ndfx &lt;- tibble(id = c(\"A\", \"B\", \"C\"), X = 1:3)\ndfy &lt;- tibble(id = c(\"A\", \"B\", \"D\"), Y = c(TRUE, FALSE, TRUE))\n\n左側データ（dfx）の行をすべて保持して結合するには left_join() を用いる。\n\nleft_join(dfx, dfy, by = \"id\")\n## # A tibble: 3 × 3\n##   id        X Y    \n##   &lt;chr&gt; &lt;int&gt; &lt;lgl&gt;\n## 1 A         1 TRUE \n## 2 B         2 FALSE\n## 3 C         3 NA\n\n右側データ（dfy）の行をすべて保持するなら right_join()。\n\nright_join(dfx, dfy, by = \"id\")\n## # A tibble: 3 × 3\n##   id        X Y    \n##   &lt;chr&gt; &lt;int&gt; &lt;lgl&gt;\n## 1 A         1 TRUE \n## 2 B         2 FALSE\n## 3 D        NA TRUE\n\n両方の行をすべて保持するなら full_join()。\n\nfull_join(dfx, dfy, by = \"id\")\n## # A tibble: 4 × 3\n##   id        X Y    \n##   &lt;chr&gt; &lt;int&gt; &lt;lgl&gt;\n## 1 A         1 TRUE \n## 2 B         2 FALSE\n## 3 C         3 NA   \n## 4 D        NA TRUE\n\ninner_join() は共通部分のみを抽出する。\n\ninner_join(dfx, dfy, by = \"id\")\n## # A tibble: 2 × 3\n##   id        X Y    \n##   &lt;chr&gt; &lt;int&gt; &lt;lgl&gt;\n## 1 A         1 TRUE \n## 2 B         2 FALSE\n\n複雑な条件で結合する場合は join_by() を使うと柔軟に定義できる。",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>整然データ</span>"
    ]
  },
  {
    "objectID": "06-datawrangling.html#tidyr",
    "href": "06-datawrangling.html#tidyr",
    "title": "7  整然データ",
    "section": "7.3 tidyr",
    "text": "7.3 tidyr\nここからは tidyr による整形の例を紹介する。まず次のデータセットを用意する。\n\ndf &lt;- tibble(\n  time = 2010:2014,\n  X = rnorm(5, 0, 1),\n  Y = rnorm(5, 0, 2),\n  Z = rnorm(5, 0, 4)\n)\n# `tibble()` なら列の型を意識しつつ手早くサンプル値を用意できる\ndf |&gt; slice_head(n = 6)\n## # A tibble: 5 × 4\n##    time      X      Y      Z\n##   &lt;int&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;\n## 1  2010 -1.79   0.650 -1.51 \n## 2  2011 -1.07   3.07   1.04 \n## 3  2012  0.214 -1.98  -4.14 \n## 4  2013 -1.30   2.21  -2.19 \n## 5  2014 -0.458  0.318  0.542\n\n列名をキーにして縦長へ変換するときは pivot_longer() を用いる。\n\ndf_long &lt;- df |&gt; \n  pivot_longer(-time, names_to = \"key\", values_to = \"value\")\n# names_to / values_to を指定しておくと後続処理が読みやすい\ndf_long\n## # A tibble: 15 × 3\n##     time key    value\n##    &lt;int&gt; &lt;chr&gt;  &lt;dbl&gt;\n##  1  2010 X     -1.79 \n##  2  2010 Y      0.650\n##  3  2010 Z     -1.51 \n##  4  2011 X     -1.07 \n##  5  2011 Y      3.07 \n##  6  2011 Z      1.04 \n##  7  2012 X      0.214\n##  8  2012 Y     -1.98 \n##  9  2012 Z     -4.14 \n## 10  2013 X     -1.30 \n## 11  2013 Y      2.21 \n## 12  2013 Z     -2.19 \n## 13  2014 X     -0.458\n## 14  2014 Y      0.318\n## 15  2014 Z      0.542\n\npivot_wider() を使えば再び元の構造に戻すことができる。\n\ndf_long |&gt; \n  pivot_wider(names_from = \"key\", values_from = \"value\")\n## # A tibble: 5 × 4\n##    time      X      Y      Z\n##   &lt;int&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;\n## 1  2010 -1.79   0.650 -1.51 \n## 2  2011 -1.07   3.07   1.04 \n## 3  2012  0.214 -1.98  -4.14 \n## 4  2013 -1.30   2.21  -2.19 \n## 5  2014 -0.458  0.318  0.542\n\n列数を増やして見せたいときや、プレゼン資料で横持ちの表が必要なときに役立つ。\ntime を列方向に展開すれば、年次を横持ちした表へ変換できる。\n\ndf_wide &lt;- df_long |&gt; \n  pivot_wider(names_from = \"time\", values_from = \"value\")\ndf_wide\n## # A tibble: 3 × 6\n##   key   `2010` `2011` `2012` `2013` `2014`\n##   &lt;chr&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;\n## 1 X     -1.79   -1.07  0.214  -1.30 -0.458\n## 2 Y      0.650   3.07 -1.98    2.21  0.318\n## 3 Z     -1.51    1.04 -4.14   -2.19  0.542\n\n再び縦長に戻す場合は次のとおりである。\n\ndf_wide |&gt; \n  pivot_longer(-key, names_to = \"time\", values_to = \"value\")\n## # A tibble: 15 × 3\n##    key   time   value\n##    &lt;chr&gt; &lt;chr&gt;  &lt;dbl&gt;\n##  1 X     2010  -1.79 \n##  2 X     2011  -1.07 \n##  3 X     2012   0.214\n##  4 X     2013  -1.30 \n##  5 X     2014  -0.458\n##  6 Y     2010   0.650\n##  7 Y     2011   3.07 \n##  8 Y     2012  -1.98 \n##  9 Y     2013   2.21 \n## 10 Y     2014   0.318\n## 11 Z     2010  -1.51 \n## 12 Z     2011   1.04 \n## 13 Z     2012  -4.14 \n## 14 Z     2013  -2.19 \n## 15 Z     2014   0.542\n\npivot_longer() と summarise() を組み合わせると、変数別の記述統計を簡潔にまとめられる。\n\ncars |&gt; \n  as_tibble() |&gt; \n  pivot_longer(everything(), names_to = \"variable\", values_to = \"value\") |&gt; \n  group_by(variable) |&gt;\n  summarise(\n    nobs = n(),\n    avg  = mean(value),\n    sd   = sd(value)\n  ) |&gt;\n  ungroup()\n## # A tibble: 2 × 4\n##   variable  nobs   avg    sd\n##   &lt;chr&gt;    &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt;\n## 1 dist        50  43.0 25.8 \n## 2 speed       50  15.4  5.29\n# 欠損を除外したいときは mean(value, na.rm = TRUE) のように na.rm を付ける\n\n日本語の列名でも同じ操作が可能である。\n\ntab &lt;- cars |&gt; \n  as_tibble() |&gt; \n  pivot_longer(c(dist, speed), names_to = \"variable\", values_to = \"value\") |&gt; \n  group_by(variable) |&gt;\n  summarise(\n    nobs = n(),\n    avg  = mean(value),\n    sd   = sd(value)\n  ) |&gt;\n  ungroup() |&gt;\n  mutate(\n    `変数` = dplyr::recode(variable, dist = \"距離\", speed = \"速度\")\n  ) |&gt;\n  select(\n    `変数`,\n    `観測数`   = nobs,\n    `平均`     = avg,\n    `標準偏差` = sd\n  )\ntab |&gt; slice_head(n = 6)\n## # A tibble: 2 × 4\n##   変数  観測数  平均 標準偏差\n##   &lt;chr&gt;  &lt;int&gt; &lt;dbl&gt;    &lt;dbl&gt;\n## 1 距離      50  43.0    25.8 \n## 2 速度      50  15.4     5.29",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>整然データ</span>"
    ]
  },
  {
    "objectID": "06-datawrangling.html#実践例",
    "href": "06-datawrangling.html#実践例",
    "title": "7  整然データ",
    "section": "7.4 実践例",
    "text": "7.4 実践例\ntidyr を用いた別の例を見てみよう。横軸を年としたデータセット df がある。\n\ndf &lt;- tibble(\n  name  = letters,\n  `2010` = rnorm(26),\n  `2011` = rnorm(26),\n  `2012` = rnorm(26)\n) \ndf |&gt; slice_head(n = 6)\n## # A tibble: 6 × 4\n##   name  `2010`  `2011` `2012`\n##   &lt;chr&gt;  &lt;dbl&gt;   &lt;dbl&gt;  &lt;dbl&gt;\n## 1 a     -0.676  0.819   0.210\n## 2 b      0.343  0.561  -0.657\n## 3 c     -0.639  1.29    0.105\n## 4 d      0.768  0.0704  1.95 \n## 5 e     -0.606 -1.23    0.233\n## 6 f      3.15  -1.11   -1.22\n\nさらに、年ごとのデータセット df_2010、df_2011、df_2012 の 3 つも用意する。\n\ndf_2010 &lt;- tibble(name = letters, runif = runif(26))\ndf_2011 &lt;- tibble(name = letters, runif = runif(26))\ndf_2012 &lt;- tibble(name = letters, runif = runif(26))\n\nこれら 4 つのデータセットを統合して整然データにする。\nまず df を pivot_longer() で縦長に変換する。\n\ndf_rnorm &lt;- df |&gt; \n  pivot_longer(-name, names_to = \"time\", values_to = \"rnorm\") |&gt; \n  mutate(time = as.numeric(time))\ndf_rnorm |&gt; slice_head(n = 6)\n## # A tibble: 6 × 3\n##   name   time  rnorm\n##   &lt;chr&gt; &lt;dbl&gt;  &lt;dbl&gt;\n## 1 a      2010 -0.676\n## 2 a      2011  0.819\n## 3 a      2012  0.210\n## 4 b      2010  0.343\n## 5 b      2011  0.561\n## 6 b      2012 -0.657\n\nここでは time 列を数値に変換している。\n次に、3 つの年別データセットを bind_rows() で縦に結合する。\n\ndf_runif &lt;- bind_rows(\n  \"2010\" = df_2010,\n  \"2011\" = df_2011,\n  \"2012\" = df_2012,\n  .id    = \"time\"\n) |&gt; \n  mutate(time = as.numeric(time))\ndf_runif |&gt; slice_head(n = 6)\n## # A tibble: 6 × 3\n##    time name  runif\n##   &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt;\n## 1  2010 a     0.751\n## 2  2010 b     0.315\n## 3  2010 c     0.779\n## 4  2010 d     0.132\n## 5  2010 e     0.782\n## 6  2010 f     0.364\n\n.id で追加された列を数値に変換して年情報として利用している。\n最後に full_join() を使って 2 つのデータを結合する。\n\ndf_full &lt;- full_join(df_rnorm, df_runif, by = c(\"name\", \"time\"))\ndf_full |&gt; slice_head(n = 6)\n## # A tibble: 6 × 4\n##   name   time  rnorm runif\n##   &lt;chr&gt; &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt;\n## 1 a      2010 -0.676 0.751\n## 2 a      2011  0.819 0.459\n## 3 a      2012  0.210 0.545\n## 4 b      2010  0.343 0.315\n## 5 b      2011  0.561 0.409\n## 6 b      2012 -0.657 0.480\n\n整然データにまとめておけば、ggplot2 やモデリング関数へそのまま渡せるため、後続処理がスムーズになり再現性も高まる。",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>整然データ</span>"
    ]
  },
  {
    "objectID": "10-panel.html",
    "href": "10-panel.html",
    "title": "11  パネル分析",
    "section": "",
    "text": "11.1 データ\nパネル分析に必要なパッケージを読み込み, データセットを準備する. library(AER) コマンドで AER パッケージを, library(plm) コマンドで plm パッケージを読み込む. 次に data(\"Grunfeld\", package = \"plm\") コマンドで Grunfeld データセットを読み込む. Grunfeld データは企業の投資, 企業価値, 資本ストックに関するパネルデータである. head(Grunfeld) コマンドでデータの最初の数行を表示する.\nlibrary(AER)\nlibrary(plm)\ndata(\"Grunfeld\", package = \"plm\")\nhead(Grunfeld)\n##   firm year   inv  value capital\n## 1    1 1935 317.6 3078.5     2.8\n## 2    1 1936 391.8 4661.7    52.6\n## 3    1 1937 410.6 5387.1   156.9\n## 4    1 1938 257.7 2792.2   209.2\n## 5    1 1939 330.8 4313.2   203.4\n## 6    1 1940 461.2 4643.9   207.2\n次にパネルデータとして扱うために, pdata.frame() 関数を使用する. pdata.frame(Grunfeld, index = c(\"firm\", \"year\")) コマンドで, firm (企業) と year (年) をインデックスとしてパネルデータフレームを作成し, pdata に格納する. pdim(pdata) コマンドでパネルデータの次元 (企業数, 時間数, 総観測数) を確認する.\npdata &lt;- pdata.frame(Grunfeld, index = c(\"firm\", \"year\"))\npdim(pdata)\n## Balanced Panel: n = 10, T = 20, N = 200",
    "crumbs": [
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>パネル分析</span>"
    ]
  },
  {
    "objectID": "10-panel.html#プーリングols",
    "href": "10-panel.html#プーリングols",
    "title": "11  パネル分析",
    "section": "11.2 プーリングOLS",
    "text": "11.2 プーリングOLS\n次の重回帰モデルを考える.\n\\[\ninv_{it} = \\beta_0 + \\beta_1 value_{it} + \\beta_2 capital_{it} + u_{it}\n\\]\n誤差項 \\(u_{it}\\) は \\(i\\) についても \\(t\\) についても独立同一分布と仮定する. さらに誤差項は説明変数と独立である. この時、パネルデータにおいてもOLS推定法でパラメータは不偏である. ここでの重回帰モデルをプーリングOLSモデルと呼ぶことにする.\nプーリングOLS推定を実行するには, plm() 関数で model = \"pooling\" を指定する. plm(inv ~ value + capital, data = pdata, model = \"pooling\") コマンドで, inv を被説明変数, value と capital を説明変数としてプーリングOLS推定を行い, 結果を gp に格納する. summary(gp) コマンドで推定結果の詳細を表示する.\n\ngp &lt;- plm(inv ~ value + capital, data = pdata, model = \"pooling\")\nsummary(gp)\n## Pooling Model\n## \n## Call:\n## plm(formula = inv ~ value + capital, data = pdata, model = \"pooling\")\n## \n## Balanced Panel: n = 10, T = 20, N = 200\n## \n## Residuals:\n##      Min.   1st Qu.    Median   3rd Qu.      Max. \n## -291.6757  -30.0137    5.3033   34.8293  369.4464 \n## \n## Coefficients:\n##                Estimate  Std. Error t-value  Pr(&gt;|t|)    \n## (Intercept) -42.7143694   9.5116760 -4.4907 1.207e-05 ***\n## value         0.1155622   0.0058357 19.8026 &lt; 2.2e-16 ***\n## capital       0.2306785   0.0254758  9.0548 &lt; 2.2e-16 ***\n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n## \n## Total Sum of Squares:    9359900\n## Residual Sum of Squares: 1755900\n## R-Squared:      0.81241\n## Adj. R-Squared: 0.8105\n## F-statistic: 426.576 on 2 and 197 DF, p-value: &lt; 2.22e-16\n\nこのプーリングOLS推定は, 通常の lm() 関数を使った回帰分析と同じ結果を得る. lm(inv ~ value + capital, data = pdata) コマンドで通常のOLS推定を行い, summary() コマンドで結果を表示すると, 上記の plm() による結果と同一であることが確認できる.\n\nsummary(lm(inv ~ value + capital, data = pdata))\n## \n## Call:\n## lm(formula = inv ~ value + capital, data = pdata)\n## \n## Residuals:\n##     Min      1Q  Median      3Q     Max \n## -291.68  -30.01    5.30   34.83  369.45 \n## \n## Coefficients:\n##               Estimate Std. Error t value Pr(&gt;|t|)    \n## (Intercept) -42.714369   9.511676  -4.491 1.21e-05 ***\n## value         0.115562   0.005836  19.803  &lt; 2e-16 ***\n## capital       0.230678   0.025476   9.055  &lt; 2e-16 ***\n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n## \n## Residual standard error: 94.41 on 197 degrees of freedom\n## Multiple R-squared:  0.8124, Adjusted R-squared:  0.8105 \n## F-statistic: 426.6 on 2 and 197 DF,  p-value: &lt; 2.2e-16",
    "crumbs": [
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>パネル分析</span>"
    ]
  },
  {
    "objectID": "10-panel.html#固定効果-平均差分法",
    "href": "10-panel.html#固定効果-平均差分法",
    "title": "11  パネル分析",
    "section": "11.3 固定効果 (平均差分法)",
    "text": "11.3 固定効果 (平均差分法)\n次の重回帰モデルを考える. \\[\ninv_{it} = \\beta_1 value_{it} + \\beta_2 capital_{it} +\\alpha_i + u_{it}\n\\] この \\(\\alpha_i\\) は個別固定効果と呼ばれている. \\(\\alpha_i\\) は時間 \\(t\\) に対して一定である. \\(\\alpha_i\\) は誤差項と相関があるもしれない. この個別固定効果を持つ重回帰モデルを固定効果モデルと呼ぶことにする.\nそれぞれの時間平均をとれば以下になる. \\[\n\\bar{inv}_{i} = \\beta_1 \\bar{value}_{i} + \\beta_2 \\bar{capital}_{i} +\\alpha_i  + \\bar{u}_{i}\n\\]\nそして、それぞれの観測値を時間平均で差し引けば以下のように \\(\\alpha_i\\) は消去される. \\[\ninv_{it}-\\overline{inv}_{i} = \\beta_1 (value_{it}-\\overline{value}_{i}) + \\beta_2 (capital_{it}-\\overline{capital}_{i})  + \\bar{u}_{i} -\\bar{u}_{i}\n\\] このように変換して回帰分析すれば \\(\\alpha_i\\) は誤差項と相関があっても一致推定量である. このような推定方法を平均差分法という.\n固定効果モデルを平均差分法で推定するには, plm() 関数で model = \"within\" を指定する. plm(inv ~ value + capital, data = pdata, model = \"within\") コマンドで固定効果推定を行い, 結果を gi に格納する. summary(gi) コマンドで推定結果の詳細を表示する.\n\ngi &lt;- plm(inv ~ value + capital, data = pdata, model = \"within\")\nsummary(gi)\n## Oneway (individual) effect Within Model\n## \n## Call:\n## plm(formula = inv ~ value + capital, data = pdata, model = \"within\")\n## \n## Balanced Panel: n = 10, T = 20, N = 200\n## \n## Residuals:\n##       Min.    1st Qu.     Median    3rd Qu.       Max. \n## -184.00857  -17.64316    0.56337   19.19222  250.70974 \n## \n## Coefficients:\n##         Estimate Std. Error t-value  Pr(&gt;|t|)    \n## value   0.110124   0.011857  9.2879 &lt; 2.2e-16 ***\n## capital 0.310065   0.017355 17.8666 &lt; 2.2e-16 ***\n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n## \n## Total Sum of Squares:    2244400\n## Residual Sum of Squares: 523480\n## R-Squared:      0.76676\n## Adj. R-Squared: 0.75311\n## F-statistic: 309.014 on 2 and 188 DF, p-value: &lt; 2.22e-16\n\n推定された個別固定効果 \\(\\alpha_i\\) の値を確認するには, fixef() 関数を使用する. fixef(gi) コマンドで各企業の固定効果の推定値を表示する.\n\nfixef(gi)\n##         1         2         3         4         5         6         7         8 \n##  -70.2967  101.9058 -235.5718  -27.8093 -114.6168  -23.1613  -66.5535  -57.5457 \n##         9        10 \n##  -87.2223   -6.5678\n\nこの固定効果推定は, lm() 関数で企業ダミーを含めた回帰分析と同等である. lm(inv ~ value + capital+0+factor(firm), data = pdata) コマンドで, 定数項を除外 (+0) し企業ダミー (factor(firm)) を含めた推定を行い, summary() コマンドで結果を表示する. 係数の推定値は同じであるが, 決定係数が大きく異なっていることに注意されたい.\n\nsummary(lm(inv ~ value + capital+0+factor(firm), data = pdata))\n## \n## Call:\n## lm(formula = inv ~ value + capital + 0 + factor(firm), data = pdata)\n## \n## Residuals:\n##      Min       1Q   Median       3Q      Max \n## -184.009  -17.643    0.563   19.192  250.710 \n## \n## Coefficients:\n##                  Estimate Std. Error t value Pr(&gt;|t|)    \n## value             0.11012    0.01186   9.288  &lt; 2e-16 ***\n## capital           0.31007    0.01735  17.867  &lt; 2e-16 ***\n## factor(firm)1   -70.29672   49.70796  -1.414   0.1590    \n## factor(firm)2   101.90581   24.93832   4.086 6.49e-05 ***\n## factor(firm)3  -235.57184   24.43162  -9.642  &lt; 2e-16 ***\n## factor(firm)4   -27.80929   14.07775  -1.975   0.0497 *  \n## factor(firm)5  -114.61681   14.16543  -8.091 7.14e-14 ***\n## factor(firm)6   -23.16130   12.66874  -1.828   0.0691 .  \n## factor(firm)7   -66.55347   12.84297  -5.182 5.63e-07 ***\n## factor(firm)8   -57.54566   13.99315  -4.112 5.85e-05 ***\n## factor(firm)9   -87.22227   12.89189  -6.766 1.63e-10 ***\n## factor(firm)10   -6.56784   11.82689  -0.555   0.5793    \n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n## \n## Residual standard error: 52.77 on 188 degrees of freedom\n## Multiple R-squared:  0.9616, Adjusted R-squared:  0.9591 \n## F-statistic:   392 on 12 and 188 DF,  p-value: &lt; 2.2e-16\n\n個別固定効果が統計的に有効かどうか (すなわち, 固定効果モデルとプーリングOLSモデルのどちらが適切か) を検定するには, F検定を実施する. pFtest(gi,gp) コマンドで, 固定効果モデル (gi) とプーリングOLSモデル (gp) を比較するF検定を実行する.\n\npFtest(gi,gp)\n## \n##  F test for individual effects\n## \n## data:  inv ~ value + capital\n## F = 49.177, df1 = 9, df2 = 188, p-value &lt; 2.2e-16\n## alternative hypothesis: significant effects\n\n\n11.3.1 時間効果モデル\n次のモデルを考える. \\[\ninv_{it} = \\beta_1 value_{it} + \\beta_2 capital_{it}+ \\gamma_t +\\alpha_i + u_{it}\n\\] この \\(\\gamma_t\\) は時間固定効果と呼ばれている. ここでは個別固定効果と時間固定効果の2つの固定効果を持つ重回帰モデルを時間効果モデルと呼ぶことにする.\n時間効果モデルを推定するには, plm() 関数で effect=\"twoways\" と model = \"within\" を指定する. plm(inv ~ value + capital, data = pdata, effect=\"twoways\", model = \"within\") コマンドで, 個別固定効果と時間固定効果の両方を含むモデルを推定し, 結果を gi2 に格納する. summary(gi2) コマンドで推定結果の詳細を表示する.\n\ngi2 &lt;- plm(inv ~ value + capital, data = pdata, effect=\"twoways\",model = \"within\")\nsummary(gi2)\n## Twoways effects Within Model\n## \n## Call:\n## plm(formula = inv ~ value + capital, data = pdata, effect = \"twoways\", \n##     model = \"within\")\n## \n## Balanced Panel: n = 10, T = 20, N = 200\n## \n## Residuals:\n##      Min.   1st Qu.    Median   3rd Qu.      Max. \n## -162.6094  -19.4710   -1.2669   19.1277  211.8420 \n## \n## Coefficients:\n##         Estimate Std. Error t-value  Pr(&gt;|t|)    \n## value   0.117716   0.013751  8.5604 6.653e-15 ***\n## capital 0.357916   0.022719 15.7540 &lt; 2.2e-16 ***\n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n## \n## Total Sum of Squares:    1615600\n## Residual Sum of Squares: 452150\n## R-Squared:      0.72015\n## Adj. R-Squared: 0.67047\n## F-statistic: 217.442 on 2 and 169 DF, p-value: &lt; 2.22e-16\n\n推定された個別固定効果と時間固定効果をそれぞれ確認するには, fixef() 関数で effect 引数を指定する. fixef(gi2, effect = \"individual\") コマンドで各企業の固定効果を, fixef(gi2, effect = \"time\") コマンドで各年の固定効果を表示する.\n\nfixef(gi2, effect = \"individual\")\n##         1         2         3         4         5         6         7         8 \n##  -86.9002  120.1540 -222.1310    8.4536  -92.3388   15.9884  -35.4336  -19.4097 \n##         9        10 \n##  -56.6827   39.9369\nfixef(gi2, effect = \"time\")\n##    1935    1936    1937    1938    1939    1940    1941    1942    1943    1944 \n##  -86.90 -106.10 -127.59 -126.13 -156.37 -131.14 -105.70 -108.04 -129.88 -130.00 \n##    1945    1946    1947    1948    1949    1950    1951    1952    1953    1954 \n## -142.58 -118.07 -126.29 -130.62 -160.40 -162.80 -149.38 -151.53 -154.62 -180.43\n\nこの時間効果モデルの推定は, lm() 関数で企業ダミーと年ダミーの両方を含めた回帰分析と同等である. lm(inv ~ value + capital+0+factor(firm)+factor(year), data = pdata) コマンドで, 定数項を除外し企業ダミーと年ダミーを含めた推定を行い, summary() コマンドで結果を表示する. 係数の推定値は同じであるが, 決定係数が大きく異なっていることに注意されたい.\n\nsummary(lm(inv ~ value + capital+0+factor(firm)+factor(year), data = pdata))\n## \n## Call:\n## lm(formula = inv ~ value + capital + 0 + factor(firm) + factor(year), \n##     data = pdata)\n## \n## Residuals:\n##      Min       1Q   Median       3Q      Max \n## -162.609  -19.471   -1.267   19.128  211.842 \n## \n## Coefficients:\n##                    Estimate Std. Error t value Pr(&gt;|t|)    \n## value               0.11772    0.01375   8.560 6.65e-15 ***\n## capital             0.35792    0.02272  15.754  &lt; 2e-16 ***\n## factor(firm)1     -86.90023   56.04663  -1.550 0.122893    \n## factor(firm)2     120.15401   29.16688   4.120 5.93e-05 ***\n## factor(firm)3    -222.13103   28.59744  -7.768 7.37e-13 ***\n## factor(firm)4       8.45361   20.41784   0.414 0.679377    \n## factor(firm)5     -92.33883   20.91106  -4.416 1.79e-05 ***\n## factor(firm)6      15.98841   19.88487   0.804 0.422498    \n## factor(firm)7     -35.43362   20.17003  -1.757 0.080772 .  \n## factor(firm)8     -19.40972   20.49076  -0.947 0.344868    \n## factor(firm)9     -56.68267   19.81211  -2.861 0.004756 ** \n## factor(firm)10     39.93689   20.40337   1.957 0.051951 .  \n## factor(year)1936  -19.19741   23.67586  -0.811 0.418596    \n## factor(year)1937  -40.69001   24.69541  -1.648 0.101277    \n## factor(year)1938  -39.22640   23.23594  -1.688 0.093221 .  \n## factor(year)1939  -69.47029   23.65607  -2.937 0.003780 ** \n## factor(year)1940  -44.23508   23.80979  -1.858 0.064930 .  \n## factor(year)1941  -18.80446   23.69400  -0.794 0.428519    \n## factor(year)1942  -21.13979   23.38163  -0.904 0.367219    \n## factor(year)1943  -42.97762   23.55287  -1.825 0.069808 .  \n## factor(year)1944  -43.09877   23.61020  -1.825 0.069701 .  \n## factor(year)1945  -55.68304   23.89562  -2.330 0.020974 *  \n## factor(year)1946  -31.16928   24.11598  -1.292 0.197957    \n## factor(year)1947  -39.39224   23.78368  -1.656 0.099522 .  \n## factor(year)1948  -43.71651   23.96965  -1.824 0.069945 .  \n## factor(year)1949  -73.49510   24.18292  -3.039 0.002750 ** \n## factor(year)1950  -75.89611   24.34553  -3.117 0.002144 ** \n## factor(year)1951  -62.48091   24.86425  -2.513 0.012911 *  \n## factor(year)1952  -64.63234   25.34950  -2.550 0.011672 *  \n## factor(year)1953  -67.71797   26.61108  -2.545 0.011832 *  \n## factor(year)1954  -93.52622   27.10786  -3.450 0.000708 ***\n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n## \n## Residual standard error: 51.72 on 169 degrees of freedom\n## Multiple R-squared:  0.9668, Adjusted R-squared:  0.9607 \n## F-statistic: 158.8 on 31 and 169 DF,  p-value: &lt; 2.2e-16\n\n時間固定効果が統計的に有効かどうか (すなわち, 時間効果モデルと個別固定効果のみのモデルのどちらが適切か) を検定するには, F検定を実施する. pFtest(gi2, gi) コマンドで, 時間効果モデル (gi2) と個別固定効果のみのモデル (gi) を比較するF検定を実行する.\n\npFtest(gi2, gi)\n## \n##  F test for twoways effects\n## \n## data:  inv ~ value + capital\n## F = 1.4032, df1 = 19, df2 = 169, p-value = 0.1309\n## alternative hypothesis: significant effects",
    "crumbs": [
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>パネル分析</span>"
    ]
  },
  {
    "objectID": "10-panel.html#固定効果-一階差分法",
    "href": "10-panel.html#固定効果-一階差分法",
    "title": "11  パネル分析",
    "section": "11.4 固定効果 (一階差分法)",
    "text": "11.4 固定効果 (一階差分法)\n次のモデルを考える. \\[\ninv_{it} = \\beta_1 value_{it} + \\beta_2 capital_{it} +\\alpha_i + u_{it}\n\\] この \\(\\alpha_i\\) は固定効果と呼ばれている. \\(\\alpha_i\\) は時間 \\(t\\) に対して一定である. \\(\\alpha_i\\) は誤差項と相関があるもしれない.\nそれぞれの階差をとれば \\(\\alpha_i\\) は消去できる. \\[\n\\Delta inv_{it} = \\beta_1 \\Delta value_{it} + \\beta_2 \\Delta capital_{it} + \\Delta u_{it}\n\\]\nこのように変換して回帰分析すれば \\(\\alpha_i\\) は誤差項と相関があっても一致推定量である.\n一階差分法による固定効果推定を実行するには, plm() 関数で model = \"fd\" を指定する. plm(inv ~ value + capital+0, data = pdata, model = \"fd\") コマンドで, 定数項を除外 (+0) して一階差分推定を行い, 結果を gf に格納する. summary(gf) コマンドで推定結果の詳細を表示する.\n\ngf &lt;- plm(inv ~ value + capital+0, data = pdata, model = \"fd\")\nsummary(gf)\n## Oneway (individual) effect First-Difference Model\n## \n## Call:\n## plm(formula = inv ~ value + capital + 0, data = pdata, model = \"fd\")\n## \n## Balanced Panel: n = 10, T = 20, N = 200\n## Observations used in estimation: 190\n## \n## Residuals:\n##    Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n## -202.05  -15.23   -1.76   -1.39    7.95  199.27 \n## \n## Coefficients:\n##          Estimate Std. Error t-value  Pr(&gt;|t|)    \n## value   0.0890628  0.0082341  10.816 &lt; 2.2e-16 ***\n## capital 0.2786940  0.0471564   5.910  1.58e-08 ***\n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n## \n## Total Sum of Squares:    584410\n## Residual Sum of Squares: 345940\n## R-Squared:      0.40876\n## Adj. R-Squared: 0.40561\n## F-statistic: 70.5784 on 2 and 188 DF, p-value: &lt; 2.22e-16\n\n時間固定効果を含む一階差分モデルを推定する場合は, 年ダミーを追加する. plm(inv ~ value + capital+0+factor(year), data = pdata, model = \"fd\") コマンドで, 年ダミー (factor(year)) を含む一階差分推定を行い, 結果を gf2 に格納する. summary(gf2) コマンドで推定結果の詳細を表示する.\n\ngf2 &lt;-plm(inv ~ value + capital+0+factor(year), data = pdata, model = \"fd\")\nsummary(gf2)\n## Oneway (individual) effect First-Difference Model\n## \n## Call:\n## plm(formula = inv ~ value + capital + 0 + factor(year), data = pdata, \n##     model = \"fd\")\n## \n## Balanced Panel: n = 10, T = 20, N = 200\n## Observations used in estimation: 190\n## \n## Residuals:\n##       Min.    1st Qu.     Median    3rd Qu.       Max. \n## -179.69353  -18.68501    0.49555   14.27860  179.03692 \n## \n## Coefficients: (1 dropped because of singularities)\n##                    Estimate Std. Error t-value  Pr(&gt;|t|)    \n## value             0.0875445  0.0095107  9.2048 &lt; 2.2e-16 ***\n## capital           0.3246777  0.0571472  5.6814 5.727e-08 ***\n## factor(year)1935 52.1173697 67.1610018  0.7760   0.43883    \n## factor(year)1936 44.5420725 65.0001486  0.6853   0.49412    \n## factor(year)1937 32.2308400 62.5656219  0.5152   0.60712    \n## factor(year)1938 19.6675926 60.6802571  0.3241   0.74625    \n## factor(year)1939 -3.0067716 58.4729853 -0.0514   0.95905    \n## factor(year)1940 23.9596588 56.8175845  0.4217   0.67378    \n## factor(year)1941 48.5989734 54.8059164  0.8867   0.37648    \n## factor(year)1942 40.9122279 52.7118790  0.7761   0.43875    \n## factor(year)1943 22.8491024 50.5894648  0.4517   0.65209    \n## factor(year)1944 23.6577035 48.8480758  0.4843   0.62879    \n## factor(year)1945 14.7036587 46.6708001  0.3151   0.75311    \n## factor(year)1946 41.6241613 44.2490709  0.9407   0.34821    \n## factor(year)1947 27.5209677 40.4024259  0.6812   0.49670    \n## factor(year)1948 23.6476936 37.0841079  0.6377   0.52455    \n## factor(year)1949 -4.3351290 33.6481639 -0.1288   0.89764    \n## factor(year)1950 -4.2709916 30.2836724 -0.1410   0.88801    \n## factor(year)1951 16.8493484 26.2244634  0.6425   0.52142    \n## factor(year)1952 18.0590591 20.8995024  0.8641   0.38876    \n## factor(year)1953 24.3453549 13.9307034  1.7476   0.08235 .  \n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n## \n## Total Sum of Squares:    584410\n## Residual Sum of Squares: 293000\n## R-Squared:      0.49864\n## Adj. R-Squared: 0.4393\n## F-statistic: 8.5881 on 21 and 169 DF, p-value: &lt; 2.22e-16\n\n時間固定効果が統計的に有効かどうかを検定するには, F検定を実施する. pFtest(gf2,gf) コマンドで, 時間効果を含むモデル (gf2) と含まないモデル (gf) を比較するF検定を実行する.\n\npFtest(gf2,gf)\n## \n##  F test for individual effects\n## \n## data:  inv ~ value + capital + 0 + factor(year)\n## F = 1.607, df1 = 19, df2 = 169, p-value = 0.05928\n## alternative hypothesis: significant effects\n\n\n11.4.1 平均差分法と一階差分法\n平均差分法と一階差分法は誤差項の仮定をどのようにおくかによって変わってくる. 誤差項の階差をとることによって時間を通じて無相関になるなら一階差分法が望ましいであろう. しかしながら, 固定効果, 時間効果の値がきちんと計算して, それが経済学的解釈が可能なら, 平均差分法が望ましい. さらに他のプーリングOLSの仮定と変量効果モデルとの比較の意味でも平均差分法がよく使われる.\nなお時間が2期間のパネルデータのとき, 平均差分法も一階差分法も計算値は同じである. たとえば \\(t=2\\)のときの変数 \\(x_{it}\\) の平均差分値は \\[\nx_{2t}-\\bar{x}_i=x_{2t}-\\frac{x_{i1}+x_{i2}}{2}=\\frac{x_{i2}-x_{i1}}{2}\n\\] となる.",
    "crumbs": [
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>パネル分析</span>"
    ]
  },
  {
    "objectID": "10-panel.html#変量効果",
    "href": "10-panel.html#変量効果",
    "title": "11  パネル分析",
    "section": "11.5 変量効果",
    "text": "11.5 変量効果\n次のモデルを考える. \\[\ninv_{it} = \\beta_1 value_{it} + \\beta_2 capital_{it} +\\alpha_i + u_{it}\n\\] この \\(\\alpha_i\\) は時間 \\(t\\) について一定であるが, \\(i\\) について独立同一分布の確率変数にしたがう. さらに \\(\\alpha_i\\) は説明変数と無相関である時, この \\(\\alpha_i\\) は個別変量効果と呼ばれている. 個別固定効果は説明変数と無相関を仮定していない. この個別変量効果を持つ重回帰モデルを変量効果モデルと呼ぶことにする.\n変量効果モデルを推定するには, plm() 関数で model = \"random\" を指定する. plm(inv ~ value + capital, data = pdata, model = \"random\") コマンドで変量効果推定を行い, 結果を gr に格納する. summary(gr) コマンドで推定結果の詳細を表示する.\n\ngr &lt;- plm(inv ~ value + capital, data = pdata, model = \"random\")\nsummary(gr)\n## Oneway (individual) effect Random Effect Model \n##    (Swamy-Arora's transformation)\n## \n## Call:\n## plm(formula = inv ~ value + capital, data = pdata, model = \"random\")\n## \n## Balanced Panel: n = 10, T = 20, N = 200\n## \n## Effects:\n##                   var std.dev share\n## idiosyncratic 2784.46   52.77 0.282\n## individual    7089.80   84.20 0.718\n## theta: 0.8612\n## \n## Residuals:\n##      Min.   1st Qu.    Median   3rd Qu.      Max. \n## -177.6063  -19.7350    4.6851   19.5105  252.8743 \n## \n## Coefficients:\n##               Estimate Std. Error z-value Pr(&gt;|z|)    \n## (Intercept) -57.834415  28.898935 -2.0013  0.04536 *  \n## value         0.109781   0.010493 10.4627  &lt; 2e-16 ***\n## capital       0.308113   0.017180 17.9339  &lt; 2e-16 ***\n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n## \n## Total Sum of Squares:    2381400\n## Residual Sum of Squares: 548900\n## R-Squared:      0.7695\n## Adj. R-Squared: 0.76716\n## Chisq: 657.674 on 2 DF, p-value: &lt; 2.22e-16\n\n推定された変量効果の値を確認するには, ranef() 関数を使用する. ranef(gr) コマンドで各企業の変量効果の推定値を表示する.\n\nranef(gr)\n##            1            2            3            4            5            6 \n##   -9.5242955  157.8910235 -172.8958044   29.9119801  -54.6790089   34.3461316 \n##            7            8            9           10 \n##   -7.8977584    0.6726376  -28.1393497   50.3144442\n\n\n11.5.1 ハウスマン検定\n帰無仮説が変量効果モデル, 対立仮説が固定効果モデルの検定はハウスマン検定を実施する. ハウスマン検定では, 変量効果モデルと固定効果モデルの係数の差が統計的に有意かどうかを検定する. phtest(gi,gr) コマンドで, 固定効果モデル (gi) と変量効果モデル (gr) のハウスマン検定を実行する.\n\nphtest(gi,gr)\n## \n##  Hausman Test\n## \n## data:  inv ~ value + capital\n## chisq = 2.3304, df = 2, p-value = 0.3119\n## alternative hypothesis: one model is inconsistent",
    "crumbs": [
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>パネル分析</span>"
    ]
  },
  {
    "objectID": "10-panel.html#クラスターロバスト分散",
    "href": "10-panel.html#クラスターロバスト分散",
    "title": "11  パネル分析",
    "section": "11.6 クラスターロバスト分散",
    "text": "11.6 クラスターロバスト分散\n固定効果モデルにおいて, 分散不均一が疑われる場合, クラスターロバスト分散を用いる. 時間効果がない固定効果モデル (gi) について, クラスターロバスト標準誤差を計算するには, coeftest() 関数と vcovHC() 関数を組み合わせて使用する. coeftest(gi, vcov=vcovHC(gi, type=\"sss\")) コマンドで, type=\"sss\" を指定したクラスターロバスト分散を用いた係数検定を実行する.\n\ncoeftest(gi,vcov=vcovHC(gi,type=\"sss\"))\n## \n## t test of coefficients:\n## \n##         Estimate Std. Error t value  Pr(&gt;|t|)    \n## value   0.110124   0.015156  7.2660 9.596e-12 ***\n## capital 0.310065   0.052618  5.8927 1.726e-08 ***\n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n時間効果モデル (gi2) についても同様に, クラスターロバスト標準誤差を計算できる. coeftest(gi2, vcov=vcovHC(gi2, type=\"sss\")) コマンドで, 時間効果モデルにおけるクラスターロバスト分散を用いた係数検定を実行する.\n\ncoeftest(gi2,vcov=vcovHC(gi2,type=\"sss\"))\n## \n## t test of coefficients:\n## \n##         Estimate Std. Error t value  Pr(&gt;|t|)    \n## value   0.117716   0.010263 11.4697 &lt; 2.2e-16 ***\n## capital 0.357916   0.045367  7.8893  3.62e-13 ***\n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nSTATA の計算結果に合わせるには, 個別固定効果モデルに年ダミーを明示的に追加する必要がある. update(gi, .~. + factor(year)) コマンドで, モデル gi に年ダミーを追加して更新し, git に格納する. その後 coeftest(git, vcov=vcovHC(git, type=\"sss\")) コマンドで, クラスターロバスト分散を用いた係数検定を実行する. gi2 と git のどちらを採用するかによって結果が変わってしまうので注意されたい.\n\ngit &lt;- update(gi, .~. + factor(year))\ncoeftest(git,vcov=vcovHC(git,type=\"sss\"))\n## \n## t test of coefficients:\n## \n##                    Estimate Std. Error t value  Pr(&gt;|t|)    \n## value              0.117716   0.010794 10.9055 &lt; 2.2e-16 ***\n## capital            0.357916   0.047715  7.5012 3.424e-12 ***\n## factor(year)1936 -19.197405  20.640669 -0.9301 0.3536580    \n## factor(year)1937 -40.690009  33.190087 -1.2260 0.2219160    \n## factor(year)1938 -39.226404  15.692472 -2.4997 0.0133837 *  \n## factor(year)1939 -69.470288  26.923231 -2.5803 0.0107211 *  \n## factor(year)1940 -44.235085  17.323706 -2.5534 0.0115505 *  \n## factor(year)1941 -18.804463  17.797543 -1.0566 0.2922130    \n## factor(year)1942 -21.139792  14.125147 -1.4966 0.1363608    \n## factor(year)1943 -42.977623  12.509017 -3.4357 0.0007437 ***\n## factor(year)1944 -43.098772  10.965103 -3.9305 0.0001234 ***\n## factor(year)1945 -55.683040  15.159383 -3.6732 0.0003212 ***\n## factor(year)1946 -31.169284  20.858408 -1.4943 0.1369549    \n## factor(year)1947 -39.392242  26.363118 -1.4942 0.1369835    \n## factor(year)1948 -43.716514  38.769856 -1.1276 0.2610913    \n## factor(year)1949 -73.495099  38.147491 -1.9266 0.0557069 .  \n## factor(year)1950 -75.896112  36.695524 -2.0683 0.0401383 *  \n## factor(year)1951 -62.480912  49.279892 -1.2679 0.2065854    \n## factor(year)1952 -64.632341  51.417852 -1.2570 0.2104874    \n## factor(year)1953 -67.717966  43.622288 -1.5524 0.1224442    \n## factor(year)1954 -93.526221  31.637576 -2.9562 0.0035603 ** \n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n11.6.1 分散不均一の検定\n固定効果モデルにおいて, 分散不均一かどうかを検定するには, Breusch-Pagan 検定を実施する. bptest() 関数を使用して, 企業ダミーを含むモデルで検定を行う. bptest(inv ~ value + capital + factor(firm), data=pdata) コマンドで, 個別固定効果モデルの分散不均一性を検定する.\n\nbptest(inv ~ value + capital + factor(firm), data=pdata)\n## \n##  studentized Breusch-Pagan test\n## \n## data:  inv ~ value + capital + factor(firm)\n## BP = 85.836, df = 11, p-value = 1.086e-13\n\n時間効果モデルの場合, 企業ダミーと年ダミーの両方を含めて検定を行う. bptest(inv ~ value + capital + factor(firm) + factor(year), data=pdata) コマンドで, 時間効果モデルの分散不均一性を検定する.\n\nbptest(inv ~ value + capital + factor(firm) + factor(year),data=pdata)\n## \n##  studentized Breusch-Pagan test\n## \n## data:  inv ~ value + capital + factor(firm) + factor(year)\n## BP = 97.357, df = 30, p-value = 4.833e-09",
    "crumbs": [
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>パネル分析</span>"
    ]
  },
  {
    "objectID": "01-base.html",
    "href": "01-base.html",
    "title": "2  R の基本",
    "section": "",
    "text": "2.1 電卓としての R\nR は電卓としても利用できる。 代表的な算術演算子を以下に示す。\n演算は一般的な優先順位に従って処理されるが、() で囲めば計算の順序を明示的に指定できる。\n5 + 2\n## [1] 7\n5 - 2\n## [1] 3\n5 * 2\n## [1] 10\n5 / 2\n## [1] 2.5\n5 ^ 2\n## [1] 25\n5 ** 2\n## [1] 25\n5 %% 2\n## [1] 1\n5 %/% 2\n## [1] 2",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>R の基本</span>"
    ]
  },
  {
    "objectID": "01-base.html#電卓としての-r",
    "href": "01-base.html#電卓としての-r",
    "title": "2  R の基本",
    "section": "",
    "text": "演算子\n説明\n例\n\n\n\n\n+\n足し算\n5 + 2 = 7\n\n\n-\n引き算\n5 - 2 = 3\n\n\n*\n掛け算\n5 * 2 = 10\n\n\n/\n割り算\n5 / 2 = 2.5\n\n\n^, **\nべき算\n5 ^ 2 = 25, 5 ** 2 = 25\n\n\n%%\n割り算の余り\n5 %% 2 = 1\n\n\n%/%\n割り算の切り下げ\n5 %/% 2 = 2",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>R の基本</span>"
    ]
  },
  {
    "objectID": "01-base.html#関数電卓としての-r",
    "href": "01-base.html#関数電卓としての-r",
    "title": "2  R の基本",
    "section": "2.2 関数電卓としての R",
    "text": "2.2 関数電卓としての R\nR は関数電卓のようにさまざまな関数を呼び出して計算できる。たとえば以下の関数がある。\n\n\n\n関数\n説明\n\n\n\n\nsqrt()\n平方根 \\(\\sqrt{\\cdot}\\)\n\n\nexp()\n指数\n\n\nlog()\n対数\n\n\nfactorial()\n階乗\n\n\nchoose()\n組み合わせ\n\n\nabs()\n絶対値\n\n\nround()\n四捨五入\n\n\nfloor()\n切り下げ\n\n\nceiling()\n切り上げ\n\n\n\n\nsqrt(10)\n## [1] 3.162278\nexp(10)\n## [1] 22026.47\nlog(10)\n## [1] 2.302585\nfactorial(4)\n## [1] 24\nchoose(4,2)\n## [1] 6\nabs(-10)\n## [1] 10\nround(3.5)\n## [1] 4\nfloor(3.5)\n## [1] 3\nceiling(3.5)\n## [1] 4\n\n関数に渡す値は引数と呼ばれる。 組み合わせを計算する関数 choose の引数は 2 つあり、複数の引数は , で区切る。 引数の順序は、名前を明示すれば入れ替えられる。\n\nchoose(4, 2)\n## [1] 6\nchoose(n=4, k=2)\n## [1] 6\nchoose(k=2, n=4)\n## [1] 6\n\n引数によっては省略しても既定値が自動的に補われることがある。 詳細は関数ごとのヘルプを参照するとよい。\nたとえば choose のヘルプは次のように参照できる。\n\nhelp(choose)\n?choose\n\nで確認できる。\nヘルプには関数の説明、使用例、引数の既定値などがまとまっている。 RStudio を利用している場合は、ヘルプペインに整形されたドキュメントが表示される。",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>R の基本</span>"
    ]
  },
  {
    "objectID": "01-base.html#r-の型",
    "href": "01-base.html#r-の型",
    "title": "2  R の基本",
    "section": "2.3 R の型",
    "text": "2.3 R の型\nR では値に型 (type) があり、数値 (numeric)、文字列 (character)、論理値 (logical) など1が用意されている。 多くの言語と異なり、型をあらかじめ宣言しなくても自動的に決まる。\n数値には整数 (integer) や、実数をコンピュータ上で扱う倍精度浮動小数点数 (double) など2が含まれる。 整数か倍精度浮動小数点数かは自動的に振り分けられるが、数字の後ろに L を付けて整数を明示することもできる。\n文字列は \" (ダブルクォーテーション) もしくは ' (シングルクォーテーション) で囲む。 TRUE もしくは FALSE を取る値は論理値 (logical) と呼ばれる。省略して T や F と表せるが、混乱を招きやすいので推奨しない。\n値の型は関数 typeof() で確認できる。\n\ntypeof(3)\n## [1] \"double\"\ntypeof(3L)\n## [1] \"integer\"\ntypeof(\"3\")\n## [1] \"character\"\ntypeof(TRUE)\n## [1] \"logical\"\ntypeof(FALSE)\n## [1] \"logical\"\ntypeof(T)\n## [1] \"logical\"\ntypeof(F)\n## [1] \"logical\"\n\nオブジェクトのクラス（統計的な型付け）を確認するには class() を使う。 より複雑なオブジェクトでは typeof() と class() の結果が異なることもある点を覚えておきたい。\n特殊な値として、無限大を表す Inf、非数を表す NaN、欠損値を表す NA、空を表す NULL がある。 Inf と NaN は数値として分類され、NA の型は論理値として扱われる。 また、NULL は独自の型として扱われる。 NaN は 0 を 0 で割ったときのように値が定まらない計算で現れる。 NA はデータが欠損している場合に使われ、数値・文字列など別の型の NA も存在する。\n\n1/0\n## [1] Inf\ntypeof(1/0)\n## [1] \"double\"\n0/0\n## [1] NaN\ntypeof(0/0)\n## [1] \"double\"\ntypeof(NA)\n## [1] \"logical\"\ntypeof(NULL)\n## [1] \"NULL\"",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>R の基本</span>"
    ]
  },
  {
    "objectID": "01-base.html#変数",
    "href": "01-base.html#変数",
    "title": "2  R の基本",
    "section": "2.4 変数",
    "text": "2.4 変数\n値は変数 (variable) に代入すると再利用できる。 R では代入のことを付値 (assign) といい、次のように実行する。\n\nx &lt;- 4 \n4 -&gt; x\nx = 4\nassign(\"x\",4)\n\n多くのプログラミング言語では 3 番目の方法のみが一般的だが、 R では最初の方法が推奨されている。3\n代入した値は、その変数名を入力すれば確認できる。 代入と同時に確認したい場合は式全体を丸括弧で囲む。\n\nx\n## [1] 4\n(x&lt;-3)\n## [1] 3\n\n変数名は記号や数字で始まらなければ、ほぼ自由に付けられる。 アルファベットは大文字と小文字が区別される点に注意する。 日本語も変数名に使えるが、環境によって文字コードが異なるため避けるのが無難である。 アンダースコア _ やピリオド . は途中に入れられるが、a.b と a_b は別の名前として扱われる。\n予約語である if など一部の名前4は変数名に使えずエラーになる。 一方で pi のように既存の組み込み変数を上書きすることは可能である。\n\npi\n## [1] 3.141593\npi &lt;- 3\npi\n## [1] 3\n\n関数 objects() を使うと、現在存在するオブジェクトを確認できる。 ls() も同じ結果を返すエイリアスである。 R は変数や関数をすべてオブジェクトとして扱う言語である。 既存のオブジェクトを削除するには rm() を使う。 組み込み変数を上書きしていても、pi を削除すれば元の値が復活する。\n\nrm(pi)\npi\n## [1] 3.141593\n\nさらに、すべてのオブジェクトを削除したい場合は rm(list=ls(all=TRUE)) と入力する。",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>R の基本</span>"
    ]
  },
  {
    "objectID": "01-base.html#パッケージ",
    "href": "01-base.html#パッケージ",
    "title": "2  R の基本",
    "section": "2.5 パッケージ",
    "text": "2.5 パッケージ\nR ではパッケージを導入することで機能を拡張できる。\nパッケージ pkg を導入する際は次を 1 度だけ実行する。\n\ninstall.packages(\"pkg\")\n\nオプション dependencies = TRUE を指定すると、依存パッケージもまとめて導入される。 インストールは 1 度実行すればよいが、R を起動し直すたびに library() などで読み込む必要がある点に注意する。\nパッケージ pkg が導入済みであれば、そのパッケージ内のコマンド cmd を実行するには\n\npkg::cmd\n\nと、パッケージ名とコマンド名の間に :: を挟む必要がある。 この書き方は、パッケージを読み込まずに特定の関数だけを呼び出したいときや、名前が衝突したときに便利である。\nまた、事前に library(pkg) や require(pkg) を実行しておけば、 関数呼び出し時の pkg:: を省略できる。 複数のパッケージに同名のコマンドが含まれる場合は、 後から library や require で読み込んだパッケージが優先される点に注意する。\nlibrary と require の使い方はほとんど同じだが、 require では次のようにパッケージがなければインストールするといった書き方ができる。\n\nif (!require(lattice)){\n  install.packages(\"lattice\")\n  require(lattice)\n} \n\nlibrary() はパッケージが見つからない場合にエラーで処理を止めるのに対し、require() は失敗すると FALSE を返し、処理を続行できる。 私自身は慣れもあって library を使うことが多い。",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>R の基本</span>"
    ]
  },
  {
    "objectID": "01-base.html#footnotes",
    "href": "01-base.html#footnotes",
    "title": "2  R の基本",
    "section": "",
    "text": "他にも日付 (Date) やバイナリ (raw) がある。↩︎\n他にも複素数 (complex) がある。↩︎\n 例えば以下を参照されたい: http://adv-r.had.co.nz/Style.html↩︎\nbreak, else, FALSE, for, function, if, in, Inf, NA, NaN, next, NULL, repeat, TRUE, while など↩︎",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>R の基本</span>"
    ]
  },
  {
    "objectID": "08-regression2.html",
    "href": "08-regression2.html",
    "title": "9  現代的仮定のもとでの最小二乗法",
    "section": "",
    "text": "9.1 正規性の仮定について\n標本サイズが十分大きければ、誤差項 \\(u_i\\) が正規分布でなくとも中心極限定理により推定量は正規分布に近似される。これは大標本を扱う実務上、正規性の仮定が多少破れていても t 検定や信頼区間が大きく崩れない理由づけになる。\nここで係数がゼロかどうかを検定するときは AER パッケージの coeftest() を用いると便利である。推定した lm オブジェクトと分散共分散行列の指定を渡すだけで、t 統計量と p 値を表示してくれる。 まず lm コマンドを用いて2つのモデルを推定する. fm1 は説明変数 x、ダミー変数 w、およびその交差項を含むモデル、fm0 は x のみを含むモデルである。\nfm1 &lt;- lm(y~x*w,data=df)\nfm0 &lt;- lm(y~x,data=df)\ncoeftest(fm1,df=Inf)\n## \n## z test of coefficients:\n## \n##             Estimate Std. Error z value  Pr(&gt;|z|)    \n## (Intercept) 11.33598    0.37427 30.2883 &lt; 2.2e-16 ***\n## x            1.96015    0.59767  3.2797  0.001039 ** \n## wT          -1.36810    0.49283 -2.7760  0.005503 ** \n## x:wT         0.42122    0.82069  0.5132  0.607780    \n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\ncoeftest() は係数の検定を行う関数である。 オプション df=Inf を指定すると, ティー分布の代わりに標準正規分布（自由度無限大のティー分布）を用いた検定を実行する. これは大標本を前提とした漸近的な検定である。 ただしサンプルサイズが大きければ、通常の t 検定でも大きく結果は変わらない。\n複数係数の同時検定では、F 統計量に制約数を掛けたものが自由度を制約数とするカイ二乗分布に従う。この性質を利用すると、漸近的な Wald 検定としてカイ二乗ベースの判断が行える。 R では waldtest() を用いれば簡単に検定できる。 waldtest() は制約付きモデル（fm0）と制約なしモデル（fm1）を比較し、複数係数の同時仮説を検定する関数である。\nwaldtest(fm0,fm1,test=\"Chisq\")\n## Wald test\n## \n## Model 1: y ~ x\n## Model 2: y ~ x * w\n##   Res.Df Df Chisq Pr(&gt;Chisq)    \n## 1     98                        \n## 2     96  2 22.76  1.142e-05 ***\n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\nオプション test=\"Chisq\" を指定すると, エフ検定統計量に制約の数を乗じた統計量が自由度が制約数のカイ二乗分布にしたがうことを利用した検定を実行する. これは大標本での漸近的な検定である.\nサンプルサイズが十分大きければ、F 検定でも同様の結論が得られる。\nオプションを省略すると標準の F 検定が実行される。\nwaldtest(fm0,fm1)\n## Wald test\n## \n## Model 1: y ~ x\n## Model 2: y ~ x * w\n##   Res.Df Df     F    Pr(&gt;F)    \n## 1     98                       \n## 2     96  2 11.38 3.671e-05 ***\n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n出力には F 統計量とその p 値が含まれる。\nこれは anova() の結果と同じで、2 つのモデルの当てはまりを比較している。\nanova(fm0,fm1)\n## Analysis of Variance Table\n## \n## Model 1: y ~ x\n## Model 2: y ~ x * w\n##   Res.Df    RSS Df Sum of Sq     F    Pr(&gt;F)    \n## 1     98 170.88                                 \n## 2     96 138.13  2     32.75 11.38 3.671e-05 ***\n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\nanova() もモデルを比較して F 検定を行うためのコマンドである。\n複数制約の検定として LM 検定（Lagrange Multiplier test）を用いる方法もある。まず制約付きモデルの残差を使って補助回帰を組み、その決定係数を基に統計量を構成する。 制約付きの回帰分析を実行し, その残差を制約なしのモデルの説明変数に回帰する. 残差回帰の決定係数に観測数を掛けた統計量は、自由度を制約数とするカイ二乗分布に従う。\n以下では LM 統計量を手動で計算してみる。\nlmt &lt;- lm(I(resid(fm1))~w*x,data=df)\n(lmt &lt;- nrow(df)*summary(lmt)$r.squared)\n## [1] 5.906312e-30\n1-pchisq(lmt,df=1)\n## [1] 1\n最初の行では fm1 の残差を目的変数にして w*x を説明変数に回帰している。 続いて、決定係数に観測数を掛けて LM 統計量を計算する。 最後に pchisq() で自由度 1 のカイ二乗分布を用いて p 値を算出する。",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>現代的仮定のもとでの最小二乗法</span>"
    ]
  },
  {
    "objectID": "08-regression2.html#誤差項と説明変数が独立の仮定について",
    "href": "08-regression2.html#誤差項と説明変数が独立の仮定について",
    "title": "9  現代的仮定のもとでの最小二乗法",
    "section": "9.2 誤差項と説明変数が独立の仮定について",
    "text": "9.2 誤差項と説明変数が独立の仮定について\n誤差項 \\(u_i\\) と説明変数 \\(x_i\\) の独立性が満たされなくても、互いに無相関であれば最小二乗推定量は一致性を保つ。 ただしその場合でも不偏性は保証されない。 また線形推定量の中で最小分散とは限らない。1 さらに、独立性が崩れると従来の標準誤差推定量は一致性を失う。\nしかし別の分散推定を用いれば、推定量は依然として正規分布に近似できることが知られている。2 すなわち説明変数と誤差項が無相関であっても独立とまでは言えない状況では、分散をロバストに推定する必要がある。 この代替的な分散をロバスト分散と呼ぶ。誤差の分散が説明変数によって変わるような状況（不均一分散）でも、推定係数の信頼区間を信頼できるようにするための工夫である。\nR では AER パッケージを使うとロバスト分散を簡単に計算できる。vcovHC() を coeftest() に渡すだけで、White（1980）型の頑健標準誤差が得られる。 次のコマンド coeftest を実行すればよい.\n\ncoeftest(fm1,vcov=vcovHC)\n## \n## t test of coefficients:\n## \n##             Estimate Std. Error t value  Pr(&gt;|t|)    \n## (Intercept) 11.33598    0.31826 35.6191 &lt; 2.2e-16 ***\n## x            1.96015    0.44821  4.3733 3.106e-05 ***\n## wT          -1.36810    0.46044 -2.9713  0.003747 ** \n## x:wT         0.42122    0.71740  0.5871  0.558487    \n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\ncoeftest コマンドのオプション vcov=vcovHC を指定することで, 不均一分散に頑健な（heteroskedasticity-consistent）標準誤差を用いた検定が実行される. vcovHC は分散共分散行列をロバスト推定する関数である.\nこの結果で標準誤差が変化していることが分かる。 ただし STATA のデフォルト設定とは若干異なる。 STATA と同じにするには\n\ncoeftest(fm1,vcov=vcovHC(fm1,type=\"HC1\"))\n## \n## t test of coefficients:\n## \n##             Estimate Std. Error t value  Pr(&gt;|t|)    \n## (Intercept) 11.33598    0.30627 37.0129 &lt; 2.2e-16 ***\n## x            1.96015    0.42983  4.5603 1.507e-05 ***\n## wT          -1.36810    0.44736 -3.0582  0.002886 ** \n## x:wT         0.42122    0.69417  0.6068  0.545423    \n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nとしなければならない. オプション type=\"HC1\" は小標本補正を施したロバスト分散推定量を指定している. これは STATA の既定設定と同じである。\nまたティー分布でなく正規分布とすることもできる.\n\ncoeftest(fm0,vcov=vcovHC,df=Inf)\n## \n## z test of coefficients:\n## \n##             Estimate Std. Error z value  Pr(&gt;|z|)    \n## (Intercept) 10.48846    0.26899  38.993 &lt; 2.2e-16 ***\n## x            2.38485    0.41861   5.697 1.219e-08 ***\n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nオプション df=Inf を追加することで, 標準正規分布を用いた検定を実行する.\n複数の係数についての検定は waldtest を実行すればよい.\n\nwaldtest(fm0,fm1,vcov=vcovHC)\n## Wald test\n## \n## Model 1: y ~ x\n## Model 2: y ~ x * w\n##   Res.Df Df      F    Pr(&gt;F)    \n## 1     98                        \n## 2     96  2 11.215 4.195e-05 ***\n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nオプション vcov=vcovHC を指定することで, ロバスト分散を用いたワルド検定を実行する.\n先の結果はエフ検定であるが, カイ二乗検定を実施するには以下を実施すればよい.\n\nwaldtest(fm0,fm1,vcov=vcovHC, test=\"Chisq\")\n## Wald test\n## \n## Model 1: y ~ x\n## Model 2: y ~ x * w\n##   Res.Df Df  Chisq Pr(&gt;Chisq)    \n## 1     98                         \n## 2     96  2 22.431  1.346e-05 ***\n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nオプション test=\"Chisq\" を追加することで, エフ統計量の代わりにカイ二乗統計量を用いた検定を実行する.\n近年の estimatr パッケージを使うと lm_robust() でロバスト分散を持つ推定を直接実行できる。推定と同時にヘテロスケダスティシティ対策の標準誤差が得られるので、コードを簡潔に保ちたい場合に有用である。\n\nfm2&lt;- lm_robust(y~x*w,data=df)\nsummary(fm2)\n## \n## Call:\n## lm_robust(formula = y ~ x * w, data = df)\n## \n## Standard error type:  HC2 \n## \n## Coefficients:\n##             Estimate Std. Error t value  Pr(&gt;|t|) CI Lower CI Upper DF\n## (Intercept)  11.3360     0.3090 36.6876 2.775e-58  10.7226  11.9493 96\n## x             1.9602     0.4344  4.5122 1.819e-05   1.0979   2.8225 96\n## wT           -1.3681     0.4492 -3.0457 2.997e-03  -2.2597  -0.4765 96\n## x:wT          0.4212     0.6985  0.6031 5.479e-01  -0.9652   1.8077 96\n## \n## Multiple R-squared:  0.3727 ,    Adjusted R-squared:  0.3531 \n## F-statistic: 24.66 on 3 and 96 DF,  p-value: 6.466e-12\n\nlm_robust コマンドは回帰分析を実行し, デフォルトでロバスト標準誤差を計算する. これにより lm() と coeftest() を別々に呼び出す手間が省ける。\nse_type = \"stata\" を指定すると STATA と同じ補正が掛けられる。\nまた以下のオプションをつければ分散均一の場合も計算できる.\n\nfm3&lt;- lm_robust(y~x*w,data=df,se_type = \"classical\")\nsummary(fm3)\n## \n## Call:\n## lm_robust(formula = y ~ x * w, data = df, se_type = \"classical\")\n## \n## Standard error type:  classical \n## \n## Coefficients:\n##             Estimate Std. Error t value  Pr(&gt;|t|) CI Lower CI Upper DF\n## (Intercept)  11.3360     0.3743 30.2883 6.349e-51  10.5931  12.0789 96\n## x             1.9602     0.5977  3.2797 1.449e-03   0.7738   3.1465 96\n## wT           -1.3681     0.4928 -2.7760 6.616e-03  -2.3464  -0.3898 96\n## x:wT          0.4212     0.8207  0.5132 6.090e-01  -1.2078   2.0503 96\n## \n## Multiple R-squared:  0.3727 ,    Adjusted R-squared:  0.3531 \n## F-statistic: 19.01 on 3 and 96 DF,  p-value: 9.313e-10\n\nオプション se_type = \"classical\" を指定すると, 通常の（ロバストでない）標準誤差を計算する. これは lm コマンドの結果と同じである.",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>現代的仮定のもとでの最小二乗法</span>"
    ]
  },
  {
    "objectID": "08-regression2.html#分散均一の検定",
    "href": "08-regression2.html#分散均一の検定",
    "title": "9  現代的仮定のもとでの最小二乗法",
    "section": "9.3 分散均一の検定",
    "text": "9.3 分散均一の検定\n誤差項が説明変数と独立な場合と、単に無相関であるだけの場合では標準誤差の推定方法が異なる。 正確には、条件付き分散が説明変数に依存するか否かが標準誤差の推定量を分ける条件となる。実務で言えば、残差の分布を見て異常に広がりが大きい領域があるかどうかを確認することが、ロバスト手法を使うべきかどうかの判断材料になる。 この性質を分散均一（homoskedasticity）という。\n誤差項の分散が均一かどうかは検定可能である. 有名な検定方法としてBP (Breusch-Pagan) 検定というものがある. BP検定は帰無仮説が分散均一で, 対立仮説が分散が説明変数と線形関係になっている場合の検定である.\n残差の自乗を被説明変数として回帰分析をおこない, その決定係数に観測数をかけたものが検定統計量となる. 以下ではBP検定統計量を手動で計算している.\n\nbpt &lt;- lm(I(resid(fm1)^2)~w*x,data=df)\n(bpt &lt;-nrow(df)*summary(bpt)$r.squared)\n## [1] 2.023691\n1-pchisq(bpt,df=3)\n## [1] 0.567504\n\n最初の行では, fm1 の残差の二乗（resid(fm1)^2）を被説明変数とし, w*x を説明変数として回帰分析を実行している. I() 関数は, 数式内で算術演算を実行するために用いる. 2行目では, その決定係数に観測数を掛けてBP検定統計量を計算している. 3行目では, 自由度3（説明変数の数）のカイ二乗分布のもとでP値を計算している.\nここでの例ではP値が5%を超えているので帰無仮説を棄却できないので, 分散均一を仮定してよいことが示唆されている.\nR では bptest コマンドを用いて簡単にBP検定を実施できる.\n\nbptest(fm1)\n## \n##  studentized Breusch-Pagan test\n## \n## data:  fm1\n## BP = 2.0237, df = 3, p-value = 0.5675\n\nbptest コマンドは自動的にBP検定統計量とP値を計算してくれる.\nこれまでのBPテストは誤差項の分散が説明変数の線形関係あることを暗黙に仮定している. 非線形性を考慮するために説明変数の二次項を導入した分散不均一性の検定をホワイト検定という. 説明変数が複数ある場合ホワイト検定は煩雑になるため, 被説明変数の予測値を使って計算することがある. そのときホワイトテストは以下で実施する.\n\nwht &lt;- lm(I(resid(fm1)^2)~fitted(fm1)+I(fitted(fm1)^2),data=df)\n(wht &lt;- nrow(df)*summary(wht)$r.squared)\n## [1] 3.032939\n1-pchisq(wht,df=2)\n## [1] 0.2194854\n\n最初の行では, 残差の二乗を被説明変数とし, 予測値（fitted(fm1)）とその二乗を説明変数として回帰分析を実行している. これにより分散の非線形性を検出できる. 2行目では, その決定係数に観測数を掛けてホワイト検定統計量を計算している. 3行目では, 自由度2のカイ二乗分布のもとでP値を計算している.\nホワイト検定でも分散均一が示唆されている.\nもしくは bptest コマンドに予測値とその二乗を指定して実行することもできる.\n\nbptest(fm1,~fitted(fm1)+I(fitted(fm1)^2))\n## \n##  studentized Breusch-Pagan test\n## \n## data:  fm1\n## BP = 3.0329, df = 2, p-value = 0.2195\n\nこのコマンドは上記の手動計算と同じ結果を返す.\nこのように分散均一性は検定することが可能であるが, そもそも分散均一が疑われる場合は, ロバスト分散で推定するので十分であるため最近の実証分析ではこの検定は実施されない.",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>現代的仮定のもとでの最小二乗法</span>"
    ]
  },
  {
    "objectID": "08-regression2.html#footnotes",
    "href": "08-regression2.html#footnotes",
    "title": "9  現代的仮定のもとでの最小二乗法",
    "section": "",
    "text": "正確にいえば、不偏推定量を得るためには条件付き期待値が説明変数に依存しないことが必要である。また線形推定量のなかで最小分散を実現するには、条件付き分散が説明変数に依存しないことが求められる。↩︎\n正確には観測される変数に 4 次のモーメントが存在するという仮定が必要となる。この仮定の直感的な意味は極端な外れ値が存在しないことである。↩︎",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>現代的仮定のもとでの最小二乗法</span>"
    ]
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "R と RStudio",
    "section": "",
    "text": "はじめに",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>R と RStudio</span>"
    ]
  },
  {
    "objectID": "index.html#r-とは",
    "href": "index.html#r-とは",
    "title": "R と RStudio",
    "section": "0.1 R とは",
    "text": "0.1 R とは\nRは統計・データ解析・統計グラフ作成のためのオープンソースソフトである. 基本的に無料で使える。 最近はその統合環境であるRStudioがデファクトスタンダードとなっている。 さらにそれらは RStudio Cloud (https://rstudio.cloud/) としてクラウド環境でも使用できる。 ここではまずローカル環境でR言語をいれる方法を解説する。 第2節にRStudioのローカル環境での導入方法を述べる。\nRStudio Cloud　については直接サイトに行き、そのヘルプを見て導入すれば良いだろう。 日本語の解説としては以下が参考になるだろう。\nhttps://qiita.com/ZaKama/items/937e6d7fa25f6d3cb385",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>R と RStudio</span>"
    ]
  },
  {
    "objectID": "index.html#r-のインストール",
    "href": "index.html#r-のインストール",
    "title": "R と RStudio",
    "section": "0.2 R のインストール",
    "text": "0.2 R のインストール\nRをインストールするには\nhttps://cran.r-project.org/\nにいき, 該当機種のファイルをダウンロードする. ダウンロードしたあとに実行すればインストールされる.\nWindows の場合, 32bit か 64bit を選択する. 最近のパソコンの CPU は 64bit と考えられるが, どちらかわからなければ 32bit にしておけばよい.\nUbuntu なら ppa を使って導入してもよい.\nsudo add-apt-repository ppa:marutter/rrutter\nsudo apt-get update\nsudo apt-get install r-base r-base-dev",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>R と RStudio</span>"
    ]
  },
  {
    "objectID": "index.html#r-の設定",
    "href": "index.html#r-の設定",
    "title": "R と RStudio",
    "section": "0.3 R の設定",
    "text": "0.3 R の設定\n設定ファイル .Rprofile をホームディレクトリに作成すれば, 設定を変更できる. ホームディレクトリはユーザー名が kenji のとき, Windows なら通常 C:\\Users\\kenji である. バックスラッシュ \\ は \\(\\yen\\) と読み替えて頂きたい. 最初は .Rprofile を特に作成しなくても大丈夫である.\nWindowsを利用して日本語のユーザー名を使用している場合に使えない。 Rを実施するためのユーザー名を別に作成するか、アカウント名を変えた方がよいだろう。 なお日本語ユーザー名のままファイルパスを英語化するには以下を参考されたい:\nhttps://clean-copy-of-onenote.hatenablog.com/entry/R_japanese_username",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>R と RStudio</span>"
    ]
  },
  {
    "objectID": "index.html#r-の使い方",
    "href": "index.html#r-の使い方",
    "title": "R と RStudio",
    "section": "0.4 R の使い方",
    "text": "0.4 R の使い方\nWindows だとコマンドプロンプトから R と入力して立ち上げるか, R のアイコンをダブルクリックすると, Rコンソールと言われる画面が現れる. コマンドプロンプトからだと最初の表示が文字化けしている可能性があるが, その後の起動に問題ないはずである. アイコンがなければ, Winキーを押した後, rgui と入力すれば起動できる. Mac や Ubuntu だとターミナルから R と入力して起動できる.\n立ち上げた後, コンソールから そこにコマンドを入力すると, その結果が直後に出力される. 終了には q() とする. 作業スペースを保存するかと聞かれたなら, No を意味する n を選択する.\nコマンド入力中, 最後の括弧を付け忘れたり, 正しく実行ができないときがある. たとえば, rnorm(5 としてEnterキーを押せば, 次の行に + とでてくる. ここでは正しく ) を付けて再度Enterキーを押せば正しく実行されるが, ときにはどれを入力すれば正しく実行されるかわからない一方で, 単にEnterを押すだけだと, 再度入力を求められることがある. そうしたとときは通常左上にあるエスケープキー (ESC) を押せば途中入力がキャンセルされる.\nR はRコンソールから対話式にコマンドを入力していく方法と, 拡張子 R のスクリプトファイルを実行していくやり方がある. 実行履歴を記録するためにスクリプトファイルを作成していくやり方を推奨する.\nスクリプトファイル project.R を Rコンソールから実行するには,\nsource(\"project.R\")\nとすればよい.\nR外部のコマンドプロンプトから実行するには\nRscript project.R\nとすればよい. 起動できないときには, 環境変数の PATH にRの実行ファイルの場所が登録されていない可能性がある.\nまた外部ファイルを導入する際やファイルを外部出力する際には, 現在の作業ディレクトリに気をつけなければならない. 現在の作業ディレクトリの場所はRコンソールから\ngetwd()\nとすれば, 確認できる. Windows だと通常の表記と異なっていることに注意されたい.\n作業ディレクトリの指定は以下のようにする.\nsetwd(PATH)\nWindows のとき指定の仕方に注意が必要である. たとえば作業ディレクトリが C:\\Users\\kenji\\work\\project のとき,\nsetwd(\"C:/Users/kenji/work/project\")\nとなる. バックスラッシュ \\ (\\(\\yen\\)) を スラッシュ / に変更しなければならない.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>R と RStudio</span>"
    ]
  },
  {
    "objectID": "03-vector.html",
    "href": "03-vector.html",
    "title": "4  ベクトル",
    "section": "",
    "text": "4.1 ベクトル\nR では同じ型の値を集めたものをベクトルという。 ベクトルは c()（concatenate の略）を用いて構成する。既存のベクトルを渡すと、ひと続きのベクトルとして結合される点にも注意する。\n(num&lt;-c(2,3,7,9))\n## [1] 2 3 7 9\n(chr &lt;- c(\"cat\",\"dog\",\"cow\"))\n## [1] \"cat\" \"dog\" \"cow\"\nベクトルには長さという属性 (attribute) が付く。length() で要素数を取得できるほか、str() を使えばオブジェクトの構造をまとめて確認できる。\nlength(num)\n## [1] 4\nlength(chr)\n## [1] 3\nベクトルはオブジェクトの基本単位であり、単一の値も長さ 1 のベクトルとみなせる。\n型が混在している場合は、自動的に最も表現力の高い型へ変換される。強制変換の優先順位は、おおむね「論理値 → 数値 → 文字列」の順と覚えておくとよい。 文字列が 1 つでも含まれると、すべて文字列に変換される。 数値と論理値が混在している場合は、論理値が数値に強制変換され、TRUE は 1、FALSE は 0 になる。\n(x&lt;- c(1,4))\n## [1] 1 4\ntypeof(x)\n## [1] \"double\"\n(y &lt;- c(2,FALSE,\"4\"))\n## [1] \"2\"     \"FALSE\" \"4\"\ntypeof(y)\n## [1] \"character\"\n(z &lt;- c(2,FALSE))\n## [1] 2 0\ntypeof(z)\n## [1] \"double\"",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>ベクトル</span>"
    ]
  },
  {
    "objectID": "03-vector.html#算術演算子",
    "href": "03-vector.html#算術演算子",
    "title": "4  ベクトル",
    "section": "4.2 算術演算子",
    "text": "4.2 算術演算子\n四則演算などの算術演算子は要素ごとに適用される。^ は累乗、%% は剰余、%/% は整数除算（切り捨て）を表す。\n\na&lt;-c(2,3,3,3)\nb&lt;-c(3,3,5,7)\na+b\n## [1]  5  6  8 10\na-b\n## [1] -1  0 -2 -4\na*b\n## [1]  6  9 15 21\na/b\n## [1] 0.6666667 1.0000000 0.6000000 0.4285714\na^b\n## [1]    8   27  243 2187\n\n片方がスカラーであっても、同じ長さのベクトルに再利用されて演算される。\n\na+2\n## [1] 4 5 5 5\na-2\n## [1] 0 1 1 1\na*2\n## [1] 4 6 6 6\na/2\n## [1] 1.0 1.5 1.5 1.5\na^2\n## [1] 4 9 9 9\n\n長さが異なるベクトル同士を演算する場合、短い方のベクトルが自動的にリサイクルされて長さを揃える。\n\nc&lt;-c(1,2)\na+c\n## [1] 3 5 4 5\na-c\n## [1] 1 1 2 1\na*c\n## [1] 2 6 3 6\na/c\n## [1] 2.0 1.5 3.0 1.5\na^c\n## [1] 2 9 3 9\n\nただし、短いベクトルの長さが長いベクトルの長さの約数でない場合は警告が表示される。",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>ベクトル</span>"
    ]
  },
  {
    "objectID": "03-vector.html#論理演算子",
    "href": "03-vector.html#論理演算子",
    "title": "4  ベクトル",
    "section": "4.3 論理演算子",
    "text": "4.3 論理演算子\n論理値を入力に取り、論理値を返す演算子を論理演算子という。 R では、否定 (!)、論理和 (|)、論理積 (&) などの演算子が用意されている。 これらの演算子も要素ごとに評価される。 || や && といった二重記号の演算子は、最初の要素のみを評価する短絡演算子であり、条件分岐で判定回数を抑えたいときに使う。\n\nlogic1 &lt;- c(TRUE, FALSE, FALSE)\nlogic2 &lt;- c(TRUE, TRUE, FALSE)\n!logic1\n## [1] FALSE  TRUE  TRUE\nlogic1 | logic2\n## [1]  TRUE  TRUE FALSE\nlogic1 & logic2\n## [1]  TRUE FALSE FALSE\n\nall() はすべての要素が TRUE かどうか、any() は少なくとも 1 つが TRUE かどうかを判定する。\n\nany(logic1)\n## [1] TRUE\nall(logic1)\n## [1] FALSE",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>ベクトル</span>"
    ]
  },
  {
    "objectID": "03-vector.html#比較演算子",
    "href": "03-vector.html#比較演算子",
    "title": "4  ベクトル",
    "section": "4.4 比較演算子",
    "text": "4.4 比較演算子\n2 つの値を比較して論理値を返す演算子を比較演算子という。 R では等しいかどうかを判定する ==、大小を判定する &gt; や &lt; などが用意されている。 これらもベクトルの要素ごとに評価される。\n\nvec1 &lt;- 1:4\nvec2 &lt;- c(2,1,3,4)\nvec1 == vec2\n## [1] FALSE FALSE  TRUE  TRUE\nvec1 &gt; vec2\n## [1] FALSE  TRUE FALSE FALSE\nvec1 &lt; vec2\n## [1]  TRUE FALSE FALSE FALSE\n\n不等号として !=（等しくない）、&gt;=（以上）、&lt;=（以下）も利用できる。\n\nvec1 != vec2 # !(vec1==vec2)\n## [1]  TRUE  TRUE FALSE FALSE\nvec1 &gt;= vec2 # (vec1 &gt; vec2 | vec1 == vec2)\n## [1] FALSE  TRUE  TRUE  TRUE\nvec1 &lt;= vec2 # (vec1 &lt; vec2 | vec1 == vec2)\n## [1]  TRUE FALSE  TRUE  TRUE\n\nスカラーとベクトルを比較する場合は、スカラーが再利用されて要素ごとに評価される。\n\nvec1 &gt; 2\n## [1] FALSE FALSE  TRUE  TRUE\n\n%in% 演算子を使うと、左側のベクトル要素が右側のベクトルに含まれているかを判定できる。返り値は論理値のベクトルで、元の長さと同じになる。\n\nvec1 %in% 4:5\n## [1] FALSE FALSE FALSE  TRUE",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>ベクトル</span>"
    ]
  },
  {
    "objectID": "03-vector.html#要素",
    "href": "03-vector.html#要素",
    "title": "4  ベクトル",
    "section": "4.5 要素",
    "text": "4.5 要素\nベクトルの要素は角括弧で取り出す。\n\nnum &lt;- c(2,3,7,9)\nnum[3]\n## [1] 7\n\n取り出すだけでなく、新しい値を代入することもできる。\n\nnum[3] &lt;- 500\nnum\n## [1]   2   3 500   9\n\n負のインデックスを指定すると、その位置の要素を除いたベクトルが得られる。\n\nnum[-3]\n## [1] 2 3 9\n\n複数の要素を同時に取り出すことも容易である。\n\nnum[c(1,4)]\n## [1] 2 9\n\n論理値ベクトルをインデックスとして使えば、条件に合致する要素のみを抽出できる。\n\nidx &lt;- c(TRUE,FALSE,TRUE,TRUE)\nnum[idx]\n## [1]   2 500   9\n\n比較演算子と組み合わせれば、条件式を直接インデックスに渡してフィルタリングできる。\n\n(num &gt; 4)\n## [1] FALSE FALSE  TRUE  TRUE\nnum[num &gt; 4]\n## [1] 500   9\n\n: 演算子で連続した整数ベクトルを生成し、その範囲を指定して抜き出すこともできる。非整数のステップや逆順が必要な場合は seq() を利用すると柔軟に制御できる。\n\n2:4\n## [1] 2 3 4\nnum[2:4]\n## [1]   3 500   9\n\nベクトルには名前属性を付与できる。\n\nvec &lt;- c(x= 3, y =3, z = 4)\n\n別の方法として次のように設定できる。\n\nnames(num) &lt;- letters[1:4]\n\n名前を付けると、文字列で要素を参照できる。\n\nvec[\"x\"]\n## x \n## 3\nnum[\"d\"]\n## d \n## 9\n\n現在の名前一覧は names() で取得でき、不要になった場合は names(num) &lt;- NULL のようにして削除する。",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>ベクトル</span>"
    ]
  },
  {
    "objectID": "03-vector.html#関数",
    "href": "03-vector.html#関数",
    "title": "4  ベクトル",
    "section": "4.6 関数",
    "text": "4.6 関数\nベクトルを引数に取る関数も多数用意されており、和や積などを簡単に計算できる。累積和（cumsum()）や累積積（cumprod()）は系列データの推移を追跡したいときに便利である。\n\nx&lt;-c(1,2,3,4,5)\nsum(x)\n## [1] 15\ncumsum(x)\n## [1]  1  3  6 10 15\nprod(x)\n## [1] 120\ncumprod(x)\n## [1]   1   2   6  24 120\n\n平均、中央値、分散、標準偏差といった統計量もワンライナーで求められる。\n\nx &lt;- c(x,10)\nmean(x)\n## [1] 4.166667\nmedian(x)\n## [1] 3.5\nvar(x)\n## [1] 10.16667\nsd(x)\n## [1] 3.188521\n\nベクトルを並べ替えたり、最小値・最大値やその位置を取得したりする関数も充実している。\n\nx &lt;- c(3,3,5,0)\nsort(x)\n## [1] 0 3 3 5\nsort(x,decreasing = TRUE)\n## [1] 5 3 3 0\nmin(x)\n## [1] 0\nmax(x)\n## [1] 5\nwhich.min(x)\n## [1] 4\nwhich.max(x)\n## [1] 3\n\n欠損値 NA が含まれている場合、mean() など多くの集計関数は既定の挙動として NA を返す。 集計から欠損を除外したいときは、na.rm = TRUE を指定する。\n\nx &lt;- c(4,2,NA,3)\nmean(x)\n## [1] NA\nmean(x, na.rm = TRUE)\n## [1] 3",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>ベクトル</span>"
    ]
  },
  {
    "objectID": "03-vector.html#規則的なベクトル",
    "href": "03-vector.html#規則的なベクトル",
    "title": "4  ベクトル",
    "section": "4.7 規則的なベクトル",
    "text": "4.7 規則的なベクトル\n1:5 のような規則的なベクトルを柔軟に作成するのに seq を用いるとよい。\n\n1:5\n## [1] 1 2 3 4 5\nseq(1, 5)\n## [1] 1 2 3 4 5\nseq(1, 5, by = 2)\n## [1] 1 3 5\nseq(1, 5, length.out = 4)\n## [1] 1.000000 2.333333 3.666667 5.000000\n\n繰り返しを作成することができる rep も覚えておくと便利である。\n\nrep(1, 5)\n## [1] 1 1 1 1 1\nrep(c(1, 2), times = 3)\n## [1] 1 2 1 2 1 2\nrep(c(1, 2), each = 3)\n## [1] 1 1 1 2 2 2\n\nまたアルファベットの文字列もあらかじめ組み込まれている。\n\nletters\n##  [1] \"a\" \"b\" \"c\" \"d\" \"e\" \"f\" \"g\" \"h\" \"i\" \"j\" \"k\" \"l\" \"m\" \"n\" \"o\" \"p\" \"q\" \"r\" \"s\"\n## [20] \"t\" \"u\" \"v\" \"w\" \"x\" \"y\" \"z\"\nLETTERS\n##  [1] \"A\" \"B\" \"C\" \"D\" \"E\" \"F\" \"G\" \"H\" \"I\" \"J\" \"K\" \"L\" \"M\" \"N\" \"O\" \"P\" \"Q\" \"R\" \"S\"\n## [20] \"T\" \"U\" \"V\" \"W\" \"X\" \"Y\" \"Z\"\nLETTERS[1:2]\n## [1] \"A\" \"B\"",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>ベクトル</span>"
    ]
  },
  {
    "objectID": "03-vector.html#乱数ベクトル",
    "href": "03-vector.html#乱数ベクトル",
    "title": "4  ベクトル",
    "section": "4.8 乱数ベクトル",
    "text": "4.8 乱数ベクトル\nベクトルを無作為に並べ替えたり抽出したりするには sample() を使う。\n\nset.seed(10)\nsample(1:5)\n## [1] 3 1 2 5 4\n\nここで set.seed() は乱数の種を固定し、別の環境でも同じ結果を再現できるようにするための設定である。\n上記は一度選ばれた値を再度選ばない非復元抽出である。復元抽出にする場合は replace = TRUE を指定する。\n\nsample(1:5, replace = TRUE)\n## [1] 3 2 2 2 5\n\nsize 引数を指定すれば、取り出す要素数も制御できる。\n\nsample(LETTERS[1:2], size = 10, replace = TRUE)\n##  [1] \"A\" \"B\" \"B\" \"A\" \"B\" \"A\" \"A\" \"B\" \"B\" \"A\"\n\n非復元抽出では、size を母集合の長さより大きくすることはできない点に注意する。\nさらに prob で各要素が選ばれる確率を指定できる（確率の合計は 1 になるようにする）。\n\nsample(LETTERS[1:2], prob = c(0.8, 0.2), size = 10, replace = TRUE)\n##  [1] \"A\" \"A\" \"A\" \"B\" \"A\" \"A\" \"B\" \"B\" \"A\" \"A\"\n\n独立な一様分布に従う長さ size のベクトルは runif(size)、平均と分散を指定した正規分布なら rnorm(size, mean, sd) で生成できる（既定値は平均 0、標準偏差 1）。\n\nsize &lt;- 8\nrunif(size)\n## [1] 0.27548386 0.22890394 0.01443391 0.72896456 0.24988047 0.16118328 0.01704265\n## [8] 0.48610035\nrnorm(size)\n## [1] -1.26519802 -0.37366156 -0.68755543 -0.87215883 -0.10176101 -0.25378053\n## [7] -1.85374045 -0.07794607",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>ベクトル</span>"
    ]
  },
  {
    "objectID": "02-rstudio.html",
    "href": "02-rstudio.html",
    "title": "3  RStudio",
    "section": "",
    "text": "3.1 RStudio とは\nRStudio は R の統合開発環境 (IDE, Integrated Development Enviroment) の一つである. オープンソース版が存在する.\nhttps://ja.wikipedia.org/wiki/R-Studio",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>RStudio</span>"
    ]
  },
  {
    "objectID": "02-rstudio.html#rstudio-のインストール",
    "href": "02-rstudio.html#rstudio-のインストール",
    "title": "3  RStudio",
    "section": "3.2 RStudio のインストール",
    "text": "3.2 RStudio のインストール\nオープンソース版のRStudio のインストールは\nhttps://www.rstudio.com/products/rstudio/download/\nにいき, 該当機種のファイルをダウンロードする. ダウンロードしたあとに実行すればインストールされる.\nUbuntu ならサーバー版を導入するとよい.\nhttps://www.rstudio.com/products/rstudio/download-server/",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>RStudio</span>"
    ]
  },
  {
    "objectID": "02-rstudio.html#rstudio-の設定",
    "href": "02-rstudio.html#rstudio-の設定",
    "title": "3  RStudio",
    "section": "3.3 RStudio の設定",
    "text": "3.3 RStudio の設定\nメニューバーの [Tools] から [Global Options…] を選択することで設定を変更できる.\n[General] で以下のように [Restore .RData …] のチェックを外していいて, その下を Never にしている. これは, 立ち上げたきに環境をクリーンし, 終了時に, データの保存を聞かれないようにするためである.\n\n\n\n\n\n\n\n\n\n次に, [Code] の タブ [Saving] で. [Default text encoding] を UTF-8 とする. Windows 以外だとOSのシステムフォントが同じなので問題ない. しかし Windows は SJIS を拡張した CP932 なので, 注意が必要である.\nWindows のRは UTF-8 を選択してもR自身はCP932処理している. ただ, 他のOSとの併用の場合, UTF-8 にしたほうがよいだろう. またHTMLファイルは UTF-8 でのファイルが前提になりつつあるので, HTML として出力を考えているなら, UTF-8 としたほうが無難である.\nまたインターネットで公開されている日本語のRファイルは Windows の使用が前提となっているため, 文字コードが CP932 であることが多い. Windows 以外を使っている場合, 一時的に文字コードを SJIS を選択する必要がある.\n\n\n\n\n\n\n\n\n\nあと, [R Markdown] で 真ん中あたりの [Show output preview in:] を View Pane に変更する",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>RStudio</span>"
    ]
  },
  {
    "objectID": "02-rstudio.html#rstudio-の使い方",
    "href": "02-rstudio.html#rstudio-の使い方",
    "title": "3  RStudio",
    "section": "3.4 RStudio の使い方",
    "text": "3.4 RStudio の使い方\nRStudio の使い方として日本語版のチートシートがある.\nhttps://github.com/rstudio/cheatsheets/raw/master/translations/japanese/rstudio-IDE-cheatsheet_ja.pdf\n英語であるがこの動画も有益である. 第一章だけ公開されている.\nhttps://www.datacamp.com/courses/working-with-the-rstudio-ide-part-1\nRStudio プロジェクト単位で複数のソースコードを管理するのことが推奨される. そうするとプロジェクトごとに作業ディレクトリが設定される. プロジェクトはメニューバー の [File] から [New Project] を選択する. そうすると新たに新たにディレクトリを作成するか, 既存のディレクトリを採用するかなどが選べる. また, バージョン管理ソフトを導入していればそこから取り入れることも可能となる.\n\n\n\n\n\n\n\n\n\nプロジェクトを立ち上げると左にコンソールペイン (Console Pane) が, 右側に上下に二分割されたペインが現れる. この配置は メニューバーの [Tools] から [Project Options -&gt; Pane Layout] を選べば変更可能である. コンソールペインにコマンドを入力するとその結果が直下に返される. 何か入力した後に, Ctrl + l (Cmd + l) を押すと, 画面が更新される. 上下の矢印キーで過去に実行したコマンドを選択できる.\nメニューバー の [File] から [New File -&gt; RScript] を選択するか, Ctrl + Shift + n (Cmd + Shift + n) と入力するか, メニューバー下の一番左の白紙のアイコンをクリックすると, Rのスクリプトファイルが新規に作られる. スクリプフォファイルを開くと左側のコンソール画面の上にソースペインが登場する. ここにソースコードを書く.\nソースペインで何かコマンドを書いていきながら, ソースコードの該当行で Ctrl + Enter (Cmd + Return) と入力するか, ソースペインの上側の右に並んでいるアイコンのうち, 左側のRunと書かれたアイコンをクリックすると, 該当行がコンソール画面で実行される. 複数行選択した後に, メニューバー の [Code] から [Run Selected line(s)] を選ぶか, Ctrl + Shift + Enter (Cmd + Shift + Enter) と入力すると複数行をまとめて実行させることも可能である.\nメニューバー の [File] から [Save] を選択するか, Ctrl + s (Cmd + s) と入力するか, メニューバー下の左から3番目のフロッピーディスクアイコンをクリック すると, スクリプトファイルを保存することができる. またメニューバー の [File] から [Open] を選択するか, Ctrl + o (Cmd + o) と入力するか, メニューバー下の左から2番めのフォルダを開くアイコンをクリックすると, 既存のスクリプトファイルを開くことができる.\n\n\n\n\n\n\n\n\n\n右上のペインには Environment と History のタブがある. Environment は現在使っているオブジェクトが表示される. 最初は空白である. 変数に数値を代入 (R の言い方ではオブジェクトに付値) することによって, 値が付け加わっている. History はこれまでの履歴が記録される. 履歴の一部ををエディトペインかコンソールペインに挿入することができる.\n右下のペインには Files, Plots, Packages, Help, Viewer のタブがある. Files ペインはWindowsではエクスプローラーのようなもので, Mac はFinder のようなもので, ファイル管理をおこなう. ファイル管理として新たなフォルダを作成したり, ファイルを削除したり, ファイル名を変更したりする.\nまたワーキングディレクトリを直感的に設定することもできる. ワーキングを設定したい場所に移動して, Files ペインの上に並んでいるアイコンのうち, Moreをクリックし, [Set As Working Directory] をクリックすればよい.\nPlots ペインはコンソール画面で作図をコマンドの実行したら, 表示されるペインである. そこで作成した図をコマンドを使わずに保存したりすることができる. Packages ペインは現在Rに導入されているパッケージリストが表示される. そこに無いパッケージはメニューバーの [Tools] から [Install Packages…] を選択して実行すればよい. すでにあるパッケージは, パッケージ名の左側のボックスをチェックすれば, ライブライリ名を付けずにコマンドを実行させることができる.\nHelp ペインはその名の通り, ヘルプ画面が表示される. コンソールペインから help (コマンド) もしくは ?コマンド と入力するとそのコマンドのヘルプがこのペインに表示される. R ではソースペインやコンソールペインで, コマンド入力していると, コマンドの後補があらわてくる. [TAB] でコマンドを補完できる. さらにそのコマンドでどのような引数が使われるのかも示される. さらに [TAB] を押せば, 引数を選べるだけでなく, 簡単なコマンドの説明がある. そのときに [F1] を押せば, より詳細なヘルプが立ち上がる. また Packages パインから該当パッケージをクリックするとそのパッケージのコマンド一覧が Help ペインに表示される.\n\n\n\n\n\n\n\n\n\n最後のViewer ペインは R Markdown で作成したファイルを HTMLで出力したときに表示されるペインである. 最初の設定だと別のウィンドウ画面として結果が表示される. このペインに出力されるためには [Tools -&gt; R Markdown] にいき, 真ん中あたりの [Show output preview in:] を View Pane に変更する必要がある. その上でソースペインから [Ctrl + Shift + k] とするか, ソースペインの左側のアイコン群の一番右側のノートのアイコンをクリックすると, 確認画面が現れるので HTML を押す. そうするとそのコードがすべて実行されて, 実行結果が作図も含めてHTMLファイルに出力される. もしくはメニューバーの [File] から [Knit Document…] としを選択するとよい.\n\n\n\n\n\n\n\n\n\nこれは knitr と rmarkdown いわれるパッケージを利用したもので, Rのコードを埋め込んだマークダウンファイルを作成し, そこからHTMLファイルを作成する. 他にも word ファイル や pdf ファイル生成することも適切に設定していれば可能である. ソースコードだけでなく, マークダウンファイルに R コマンドを埋め込んだ Rmd ファイルを作成することができる それは新規作成でRスクリプトでなく, R Notebook や R Markdown を選択すればよい.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>RStudio</span>"
    ]
  },
  {
    "objectID": "09-ivreg.html",
    "href": "09-ivreg.html",
    "title": "10  操作変数法",
    "section": "",
    "text": "10.1 データ\nlibrary(AER)\nlibrary(wooldridge)\nlibrary(estimatr)\ndata(\"mroz\", package=\"wooldridge\")\ndf &lt;- subset(mroz, inlf==1)",
    "crumbs": [
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>操作変数法</span>"
    ]
  },
  {
    "objectID": "09-ivreg.html#操作変数",
    "href": "09-ivreg.html#操作変数",
    "title": "10  操作変数法",
    "section": "10.2 操作変数",
    "text": "10.2 操作変数\nこれまで回帰モデルで一致推定量を得るためには次の仮定が必要であった.\n\n母集団が線形モデル\n標本が無作為抽出\n誤差項が平均ゼロで説明変数と無相関\n説明変数に多重共線性が存在しない\n\n3つ目の仮定が必ずしも成立しない場合の推定方法を紹介する.\nそのために, 外生変数と内生変数と操作変数の3つの概念を導入する. 誤差項と相関が無い説明変数を 外生変数 といい, 誤差項と相関がある説明変数を 内生変数 という. 操作変数 とは, 説明変数に含まれず, 説明変数と相関をもち, 誤差項と相関をもたない変数のことである. なお操作変数の個数は内生変数の個数より多苦なければならない。\nR においては ivreg コマンドを用いて操作変数法を実行する. このコマンドは AER パッケージに含まれており, 基本的な書式は ivreg(被説明変数 ~ 内生変数 | 操作変数, data=データフレーム) である. ここで被説明変数は log(wage), 内生変数は educ, 操作変数は fatheduc である.\n以下のコマンドで操作変数法を実行し, coef コマンドで推定された係数を取り出す.\n\nfm  &lt;- ivreg(log(wage)~educ|fatheduc, data=df)\ncoef(fm)\n## (Intercept)        educ \n##  0.44110339  0.05917348\n\n傾きの推定値は操作変数推定量の公式を用いて直接計算することもできる. 具体的には, 被説明変数と操作変数の共分散を内生変数と操作変数の共分散で割ることで得られる. 以下のコマンドで cov 関数を用いて共分散を計算し, 同じ推定値が得られることを確認する.\n\nwith(df, cov(log(wage),fatheduc)/cov(educ,fatheduc))\n## [1] 0.05917348",
    "crumbs": [
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>操作変数法</span>"
    ]
  },
  {
    "objectID": "09-ivreg.html#段階最小二乗法",
    "href": "09-ivreg.html#段階最小二乗法",
    "title": "10  操作変数法",
    "section": "10.3 2段階最小二乗法",
    "text": "10.3 2段階最小二乗法\n複数の説明変数あり, 操作変数の数が内生変数の数以上のとき, 係数の一致推定量を得るには二段階最小自乗法を用いる. 二段階最小二乗法は次の手順で実行される:\n\nそれぞれの内生変数を外生変数と操作変数に回帰させて, その予測値を得る.\n被説明変数を外生変数と内生変数の予測値に回帰させて, その係数を得る.\n\nこの係数が一致推定量になるための条件は以下である.\n\n母集団が線形モデル\n標本が無作為抽出\n誤差項が平均ゼロで操作変数と外生変数に対して独立.\n操作変数は内生変数と相関をもつ.\n外生変数と内生変数の予測値に多重共線性が存在しない`\n\nR においては ivreg コマンドを用いて二段階最小二乗法を実行する. 複数の説明変数がある場合の書式は ivreg(被説明変数 ~ 内生変数 + 外生変数 | 外生変数 + 操作変数, data=データフレーム) である. ここで被説明変数は log(wage), 内生変数は educ, 外生変数は exper, I(exper^2), 操作変数は motheduc, fatheduc である. 注意点として, パイプ記号 | の右側には外生変数も含める必要がある.\n以下のコマンドで二段階最小二乗法を実行し, summary コマンドで推定結果の要約を表示する.\n\nfm  &lt;- ivreg(log(wage)~educ+exper+I(exper^2)|\n            exper+I(exper^2)+motheduc+fatheduc,\n            data=df)\nsummary(fm)\n## \n## Call:\n## ivreg(formula = log(wage) ~ educ + exper + I(exper^2) | exper + \n##     I(exper^2) + motheduc + fatheduc, data = df)\n## \n## Residuals:\n##     Min      1Q  Median      3Q     Max \n## -3.0986 -0.3196  0.0551  0.3689  2.3493 \n## \n## Coefficients:\n##               Estimate Std. Error t value Pr(&gt;|t|)   \n## (Intercept)  0.0481003  0.4003281   0.120  0.90442   \n## educ         0.0613966  0.0314367   1.953  0.05147 . \n## exper        0.0441704  0.0134325   3.288  0.00109 **\n## I(exper^2)  -0.0008990  0.0004017  -2.238  0.02574 * \n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n## \n## Residual standard error: 0.6747 on 424 degrees of freedom\n## Multiple R-Squared: 0.1357,  Adjusted R-squared: 0.1296 \n## Wald test: 8.141 on 3 and 424 DF,  p-value: 2.787e-05\n\n二段階最小二乗法の手順を lm コマンドを用いて手動で実行し, 同じ係数推定値が得られることを確認できる. ただし標準誤差の値が異なっている. なぜなら残差は内生変数および外生変数から算出させる必要があるが, 以下のやりかただと内生変数の予測値および外生変数から算出するためである.\n以下では第一段階として lm コマンドで内生変数 educ を外生変数と操作変数に回帰し, fitted コマンドで予測値を取得する. 第二段階として被説明変数を外生変数と内生変数の予測値に回帰する.\n\nols1 &lt;- lm(educ~exper+I(exper^2)+motheduc+fatheduc,  data = df)\nols2 &lt;- lm(log(wage)~fitted(ols1)+exper+I(exper^2),  data = df)\nsummary(ols2)\n## \n## Call:\n## lm(formula = log(wage) ~ fitted(ols1) + exper + I(exper^2), data = df)\n## \n## Residuals:\n##     Min      1Q  Median      3Q     Max \n## -3.1631 -0.3539  0.0326  0.3818  2.3727 \n## \n## Coefficients:\n##                Estimate Std. Error t value Pr(&gt;|t|)   \n## (Intercept)   0.0481003  0.4197565   0.115  0.90882   \n## fitted(ols1)  0.0613966  0.0329624   1.863  0.06321 . \n## exper         0.0441704  0.0140844   3.136  0.00183 **\n## I(exper^2)   -0.0008990  0.0004212  -2.134  0.03338 * \n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n## \n## Residual standard error: 0.7075 on 424 degrees of freedom\n## Multiple R-squared:  0.04978,    Adjusted R-squared:  0.04306 \n## F-statistic: 7.405 on 3 and 424 DF,  p-value: 7.615e-05\n\n\n10.3.1 複数制約の検定\n帰無仮説が複数の係数制約を課す場合のワルド検定を実施する. 例えば, 2つの外生変数 exper と I(exper^2) の係数がともにゼロであるという仮説を検定する.\nまず ivreg コマンドで制約モデル（外生変数を含まないモデル）を推定し, waldtest コマンドで制約なしモデルと比較する. waldtest コマンドは2つのモデルを引数にとり, ワルド検定を実行する.\n\nfm0 &lt;- ivreg(log(wage)~educ|motheduc+fatheduc,data=df)\nwaldtest(fm0,fm)\n## Wald test\n## \n## Model 1: log(wage) ~ educ | motheduc + fatheduc\n## Model 2: log(wage) ~ educ + exper + I(exper^2) | exper + I(exper^2) + \n##     motheduc + fatheduc\n##   Res.Df Df  Chisq Pr(&gt;Chisq)    \n## 1    426                         \n## 2    424  2 19.639  5.439e-05 ***\n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nLM検定（ラグランジュ乗数検定）も実行可能である. まず resid コマンドで制約モデルの残差を取得し, その残差を制約される説明変数に回帰する. nrow コマンドで観測数を取得し, 決定係数 r.squared を乗じてLM統計量を計算する. 最後に pchisq コマンドでカイ二乗分布のP値を計算する（自由度は制約の数3）.\n\nlmt &lt;- lm(resid(fm0)~educ + exper + I(exper^2) ,data=df)\n(lmt &lt;- nrow(df)*summary(lmt)$r.squared)\n## [1] 33.97987\n1-pchisq(lmt,df=3)\n## [1] 2.000665e-07",
    "crumbs": [
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>操作変数法</span>"
    ]
  },
  {
    "objectID": "09-ivreg.html#特定化検定",
    "href": "09-ivreg.html#特定化検定",
    "title": "10  操作変数法",
    "section": "10.4 特定化検定",
    "text": "10.4 特定化検定\n操作変数法が妥当かどうかを検証するために, 複数の特定化検定を実施する. summary コマンドにオプション diagnostics = TRUE を追加すると, 弱操作変数検定（Weak instruments）, Wu-Hausman検定, Sargan検定を一度に実行できる. これらの検定結果から, 操作変数の妥当性, 内生性の有無, 操作変数の外生性を確認できる.\n\nsummary(fm, diagnostics = TRUE)\n## \n## Call:\n## ivreg(formula = log(wage) ~ educ + exper + I(exper^2) | exper + \n##     I(exper^2) + motheduc + fatheduc, data = df)\n## \n## Residuals:\n##     Min      1Q  Median      3Q     Max \n## -3.0986 -0.3196  0.0551  0.3689  2.3493 \n## \n## Coefficients:\n##               Estimate Std. Error t value Pr(&gt;|t|)   \n## (Intercept)  0.0481003  0.4003281   0.120  0.90442   \n## educ         0.0613966  0.0314367   1.953  0.05147 . \n## exper        0.0441704  0.0134325   3.288  0.00109 **\n## I(exper^2)  -0.0008990  0.0004017  -2.238  0.02574 * \n## \n## Diagnostic tests:\n##                  df1 df2 statistic p-value    \n## Weak instruments   2 423    55.400  &lt;2e-16 ***\n## Wu-Hausman         1 423     2.793  0.0954 .  \n## Sargan             1  NA     0.378  0.5386    \n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n## \n## Residual standard error: 0.6747 on 424 degrees of freedom\n## Multiple R-Squared: 0.1357,  Adjusted R-squared: 0.1296 \n## Wald test: 8.141 on 3 and 424 DF,  p-value: 2.787e-05\n\n\n10.4.1 Weak instruments\n操作変数が内生変数と弱い相関関係しかない場合, 弱操作変数という. 弱操作変数の場合, 推定量の性質が悪化するため, 操作変数が十分に強い相関を持つかを検定する必要がある.\n検定手順は以下の通りである: それぞれの内生変数に対して, 帰無仮説を内生変数を外生変数のみに回帰させたモデルとし, 対立仮説を内生変数を外生変数および操作変数に回帰させたモデルとし, F検定を実施する.\n以下のコマンドで lm による制約モデルを推定し, anova コマンドで第一段階の回帰モデル ols1 と比較してF検定を実行する. この結果が先の diagnostics = TRUE で得られた弱操作変数検定と同じであることを確認されたい.\n\nols0 &lt;- lm(educ ~ exper + I(exper^2), data = df)\nanova(ols0, ols1)\n## Analysis of Variance Table\n## \n## Model 1: educ ~ exper + I(exper^2)\n## Model 2: educ ~ exper + I(exper^2) + motheduc + fatheduc\n##   Res.Df    RSS Df Sum of Sq    F    Pr(&gt;F)    \n## 1    425 2219.2                                \n## 2    423 1758.6  2    460.64 55.4 &lt; 2.2e-16 ***\n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\n10.4.2 Wu-Hausman 検定\nWu-Hausman 検定は 帰無仮説が誤差項と説明変数が無相関, 対立仮説が誤差項と説明変数が相関ありの検定をおこなう. 帰無仮説のもとでは, OLSも2SLSも一致推定量であるが, OLSの方が効率的である. よって検定統計量のP値が十分小さいなら帰無仮説は棄却され, 内生性があることになり操作変数法（2SLS）を選択する. そうでなければより効率的な最小二乗法（OLS）を実施する.\n具体的には以下のF検定を実施する:\n\nlm コマンドでそれぞれの内生変数を外生変数に回帰し, resid コマンドで残差を得る (resid(ols1))\nlm コマンドで被説明変数を説明変数に回帰する (ols3)\nupdate コマンドで被説明変数を説明変数および先程の残差に回帰する (ols4)\nanova コマンドでこれらの残差の係数はゼロであるという帰無仮説のもとF検定を実施する\n\n以下のコマンドが先の diagnostics = TRUE で得られたWu-Hausman検定と同じであることを確認されたい.\n\nols3 &lt;- lm(log(wage) ~ educ  + exper + I(exper^2), data = df)\nols4 &lt;- update(ols3, . ~ . + resid(ols1))\nanova(ols3,ols4)\n## Analysis of Variance Table\n## \n## Model 1: log(wage) ~ educ + exper + I(exper^2)\n## Model 2: log(wage) ~ educ + exper + I(exper^2) + resid(ols1)\n##   Res.Df    RSS Df Sum of Sq      F  Pr(&gt;F)  \n## 1    424 188.31                              \n## 2    423 187.07  1     1.235 2.7926 0.09544 .\n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\n10.4.3 Sargan 検定\nSargan 検定は 誤差項が操作変数 (および外生変数) と相関しているかどうかを検定する. 帰無仮説は操作変数が外生的である（相関が無い）場合で, 対立仮説は操作変数が内生的である（相関がある）場合である. この検定は操作変数が過剰識別されている（操作変数の数が内生変数の数より多い）場合にのみ実施可能である.\nLM検定（ラグランジュ乗数検定）を以下の手順で実施する:\n\nresid コマンドで二段階最小二乗法を実施したときの残差を得る (resid(fm))\nlm コマンドで残差を外生変数および操作変数に回帰する\nnrow コマンドで観測数を取得し, 回帰の決定係数 r.squared を乗じたLM統計量を得る\npchisq コマンドで検定統計量のP値を計算する. 検定統計量は帰無仮説のもと, 操作変数の数から内生変数の数を差し引いた自由度（この例では1）のカイ二乗分布にしたがう\n\n以下のコマンドが先の diagnostics = TRUE で得られたSargan検定と同じであることを確認されたい.\n\njt &lt;- lm(resid(fm)~exper+I(exper^2)+motheduc+fatheduc,data=df)\n(jt &lt;- nrow(df)*summary(jt)$r.squared)\n## [1] 0.3780714\n1-pchisq(jt,df=1)\n## [1] 0.5386372",
    "crumbs": [
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>操作変数法</span>"
    ]
  },
  {
    "objectID": "09-ivreg.html#ロバスト分散",
    "href": "09-ivreg.html#ロバスト分散",
    "title": "10  操作変数法",
    "section": "10.5 ロバスト分散",
    "text": "10.5 ロバスト分散\n以上の分析は, 誤差項が操作変数と独立かつ均一分散の場合の分析である. 独立でない場合や分散不均一の場合, 推定量の分散が変わりうる. そうした場合に頑健な分散推定量をロバスト分散という.\nロバスト分散にもとづく推定結果を得るには, summary コマンドにオプション vcov = vcovHC を追加する. vcovHC は不均一分散に頑健な分散共分散行列を計算する関数である. オプション df = Inf は自由度を無限大とし, t分布ではなく正規分布を用いて検定を行う.\n\nsummary(fm, vcov = vcovHC, df = Inf)\n## \n## Call:\n## ivreg(formula = log(wage) ~ educ + exper + I(exper^2) | exper + \n##     I(exper^2) + motheduc + fatheduc, data = df)\n## \n## Residuals:\n##     Min      1Q  Median      3Q     Max \n## -3.0986 -0.3196  0.0551  0.3689  2.3493 \n## \n## Coefficients:\n##               Estimate Std. Error z value Pr(&gt;|z|)   \n## (Intercept)  0.0481003  0.4337795   0.111  0.91171   \n## educ         0.0613966  0.0336597   1.824  0.06815 . \n## exper        0.0441704  0.0157661   2.802  0.00508 **\n## I(exper^2)  -0.0008990  0.0004391  -2.047  0.04062 * \n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n## \n## Residual standard error: 0.6747 on Inf degrees of freedom\n## Multiple R-Squared: 0.1357,  Adjusted R-squared: 0.1296 \n## Wald test: 18.11 on 3 DF,  p-value: 0.0004168\n\n係数の検定結果のみを表示したい場合は, coeftest コマンドを用いる. このコマンドは推定されたモデルオブジェクトと分散共分散行列を引数にとり, 係数のt検定結果を表示する.\n\ncoeftest(fm, vcov=vcovHC)\n## \n## t test of coefficients:\n## \n##                Estimate  Std. Error t value Pr(&gt;|t|)   \n## (Intercept)  0.04810030  0.43377952  0.1109 0.911759   \n## educ         0.06139663  0.03365975  1.8240 0.068850 . \n## exper        0.04417039  0.01576605  2.8016 0.005318 **\n## I(exper^2)  -0.00089897  0.00043908 -2.0474 0.041233 * \n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nロバスト分散のもとでの複数制約のワルド検定を実施するには, waldtest コマンドにオプション vcov=vcovHC を追加する.\n\nwaldtest(fm0,fm, vcov=vcovHC)\n## Wald test\n## \n## Model 1: log(wage) ~ educ | motheduc + fatheduc\n## Model 2: log(wage) ~ educ + exper + I(exper^2) | exper + I(exper^2) + \n##     motheduc + fatheduc\n##   Res.Df Df  Chisq Pr(&gt;Chisq)    \n## 1    426                         \n## 2    424  2 14.582  0.0006816 ***\n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n最近開発されたパッケージ estimatr のコマンド iv_robust を用いるとロバスト分散のもとの推定値が簡単に計算できる. このコマンドはデフォルトでロバスト標準誤差（HC2型）を計算し, オプション diagnostics = TRUE で特定化検定も同時に実行できる. 書式は ivreg と同じである.\n以下のコマンドで iv_robust による推定を実行し, summary コマンドで結果を表示する.\n\nfm2 &lt;- iv_robust(log(wage)~educ+exper+I(exper^2)|\n            exper+I(exper^2)+motheduc+fatheduc,\n            data=df,diagnostics =TRUE)\nsummary(fm2)\n## \n## Call:\n## iv_robust(formula = log(wage) ~ educ + exper + I(exper^2) | exper + \n##     I(exper^2) + motheduc + fatheduc, data = df, diagnostics = TRUE)\n## \n## Standard error type:  HC2 \n## \n## Coefficients:\n##              Estimate Std. Error t value Pr(&gt;|t|)  CI Lower   CI Upper  DF\n## (Intercept)  0.048100  0.4307514  0.1117 0.911141 -0.798574  8.948e-01 424\n## educ         0.061397  0.0334146  1.8374 0.066848 -0.004282  1.271e-01 424\n## exper        0.044170  0.0156233  2.8272 0.004918  0.013462  7.488e-02 424\n## I(exper^2)  -0.000899  0.0004337 -2.0730 0.038777 -0.001751 -4.658e-05 424\n## \n## Multiple R-squared:  0.1357 ,    Adjusted R-squared:  0.1296 \n## F-statistic: 6.117 on 3 and 424 DF,  p-value: 0.0004426\n## \n## Diagnostics:\n##                  numdf dendf  value p.value    \n## Weak instruments     2   423 49.374  &lt;2e-16 ***\n## Wu-Hausman           1   423  2.535   0.112    \n## Overidentifying      1    NA  0.443   0.505    \n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nオプション se_type = \"stata\" を用いればSTATAと同じ標準誤差の計算が可能である. また, ロバスト分散のもとで特定化検定（弱操作変数検定, Wu-Hausman検定, Sargan検定）が実行される.\n分散均一性を仮定した古典的な標準誤差を計算したい場合は, オプション se_type = \"classical\" を追加する.\n\nfm3 &lt;- iv_robust(log(wage)~educ+exper+I(exper^2)|\n            exper+I(exper^2)+motheduc+fatheduc,\n            data=df,diagnostics =TRUE,se_type = \"classical\")\nsummary(fm3)\n## \n## Call:\n## iv_robust(formula = log(wage) ~ educ + exper + I(exper^2) | exper + \n##     I(exper^2) + motheduc + fatheduc, data = df, se_type = \"classical\", \n##     diagnostics = TRUE)\n## \n## Standard error type:  classical \n## \n## Coefficients:\n##              Estimate Std. Error t value Pr(&gt;|t|)   CI Lower   CI Upper  DF\n## (Intercept)  0.048100  0.4003281  0.1202 0.904419 -0.7387744  0.8349750 424\n## educ         0.061397  0.0314367  1.9530 0.051474 -0.0003945  0.1231878 424\n## exper        0.044170  0.0134325  3.2883 0.001092  0.0177679  0.0705729 424\n## I(exper^2)  -0.000899  0.0004017 -2.2380 0.025740 -0.0016885 -0.0001094 424\n## \n## Multiple R-squared:  0.1357 ,    Adjusted R-squared:  0.1296 \n## F-statistic: 8.141 on 3 and 424 DF,  p-value: 2.787e-05\n## \n## Diagnostics:\n##                  numdf dendf  value p.value    \n## Weak instruments     2   423 55.400  &lt;2e-16 ***\n## Wu-Hausman           1   423  2.793  0.0954 .  \n## Overidentifying      1    NA  0.378  0.5386    \n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n10.5.1 分散不均一の検定\n誤差項が操作変数と独立なら条件付き分散は操作変数に無関係で均一である. これを利用して分散均一を帰無仮説に, 分散不均一を対立仮説にしたBP検定（Breusch-Pagan検定）が実行可能である. ただし, 通常のコマンド bptest では正しく実行できないので, 手動で実行する必要がある.\n以下の手順でBP検定を実行する:\n\nI 関数と resid コマンドを用いて二段階最小二乗法の残差の二乗を計算する (I(resid(fm)^2))\nlm コマンドで残差の二乗を外生変数および操作変数に回帰する\nnrow コマンドで観測数を取得し, 決定係数 r.squared を乗じてLM統計量を得る\npchisq コマンドで検定統計量のP値を計算する. 検定統計量は帰無仮説のもと, 説明変数の数（この例では4）の自由度のカイ二乗分布にしたがう\n\n\nbpt &lt;- lm(I(resid(fm)^2)~exper + I(exper^2) + motheduc + fatheduc,data=df)\n(bpt &lt;- nrow(df)*summary(bpt)$r.squared)\n## [1] 12.41758\n1-pchisq(bpt,df=4)\n## [1] 0.01450172",
    "crumbs": [
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>操作変数法</span>"
    ]
  }
]