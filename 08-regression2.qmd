---
output: 
  html_document:default
  html_notebook:default
editor_options: 
  markdown: 
    wrap: sentence
---

# 現代的仮定のもとでの最小二乗法

```{r}
#| message: false
#| warning: false
library(AER)
library(estimatr)
```

前節では以下の仮定を置いていた。

- $(x_i, y_i)$ は独立同一分布に従う。
- $E[u_i] = 0$ である。
- $u_i$ と $x_i$ は独立である。
- $u_i$ は正規分布に従う。

ここではこれらの仮定を緩めた場合に、推定結果や検定にどのような影響が生じるかを確認する。

まずは仮想データを用いて状況を設定する。

```{r}
N <- 100
x<-runif(N)
w<-sample(c("H","T"),N,replace=TRUE)
y <- 10 + 2*x + ifelse(w=="H",1,0) + rnorm(N)
df <- data.frame(w,x,y)
```

散布図を描くと次のようになる。 散布図を描く際には、点の雲が線形からどの程度離れているかを目視で把握しておくと、後で外れ値や非線形性を疑う際の手がかりになる。

```{r}
plot(y~x)
```

## 正規性の仮定について

標本サイズが十分大きければ、誤差項 $u_i$ が正規分布でなくとも中心極限定理により推定量は正規分布に近似される。これは大標本を扱う実務上、正規性の仮定が多少破れていても t 検定や信頼区間が大きく崩れない理由づけになる。

ここで係数がゼロかどうかを検定するときは `AER` パッケージの `coeftest()` を用いると便利である。推定した `lm` オブジェクトと分散共分散行列の指定を渡すだけで、t 統計量と p 値を表示してくれる。
まず `lm` コマンドを用いて2つのモデルを推定する.
`fm1` は説明変数 `x`、ダミー変数 `w`、およびその交差項を含むモデル、`fm0` は `x` のみを含むモデルである。

```{r}
fm1 <- lm(y~x*w,data=df)
fm0 <- lm(y~x,data=df)
coeftest(fm1,df=Inf)
```

`coeftest()` は係数の検定を行う関数である。
オプション `df=Inf` を指定すると, ティー分布の代わりに標準正規分布（自由度無限大のティー分布）を用いた検定を実行する.
これは大標本を前提とした漸近的な検定である。
ただしサンプルサイズが大きければ、通常の t 検定でも大きく結果は変わらない。

複数係数の同時検定では、F 統計量に制約数を掛けたものが自由度を制約数とするカイ二乗分布に従う。この性質を利用すると、漸近的な Wald 検定としてカイ二乗ベースの判断が行える。
R では `waldtest()` を用いれば簡単に検定できる。
`waldtest()` は制約付きモデル（`fm0`）と制約なしモデル（`fm1`）を比較し、複数係数の同時仮説を検定する関数である。

```{r}
waldtest(fm0,fm1,test="Chisq")
```

オプション `test="Chisq"` を指定すると, エフ検定統計量に制約の数を乗じた統計量が自由度が制約数のカイ二乗分布にしたがうことを利用した検定を実行する.
これは大標本での漸近的な検定である.

サンプルサイズが十分大きければ、F 検定でも同様の結論が得られる。

オプションを省略すると標準の F 検定が実行される。

```{r}
waldtest(fm0,fm1)
```

出力には F 統計量とその p 値が含まれる。

これは `anova()` の結果と同じで、2 つのモデルの当てはまりを比較している。

```{r}
anova(fm0,fm1)
```

`anova()` もモデルを比較して F 検定を行うためのコマンドである。

複数制約の検定として LM 検定（Lagrange Multiplier test）を用いる方法もある。まず制約付きモデルの残差を使って補助回帰を組み、その決定係数を基に統計量を構成する。
制約付きの回帰分析を実行し, その残差を制約なしのモデルの説明変数に回帰する.
残差回帰の決定係数に観測数を掛けた統計量は、自由度を制約数とするカイ二乗分布に従う。

以下では LM 統計量を手動で計算してみる。

```{r}
lmt <- lm(I(resid(fm1))~w*x,data=df)
(lmt <- nrow(df)*summary(lmt)$r.squared)
1-pchisq(lmt,df=1)
```

最初の行では `fm1` の残差を目的変数にして `w*x` を説明変数に回帰している。
続いて、決定係数に観測数を掛けて LM 統計量を計算する。
最後に `pchisq()` で自由度 1 のカイ二乗分布を用いて p 値を算出する。

## 誤差項と説明変数が独立の仮定について

誤差項 $u_i$ と説明変数 $x_i$ の独立性が満たされなくても、互いに無相関であれば最小二乗推定量は一致性を保つ。
ただしその場合でも不偏性は保証されない。
また線形推定量の中で最小分散とは限らない。[^08-regression2-1]
さらに、独立性が崩れると従来の標準誤差推定量は一致性を失う。

[^08-regression2-1]: 正確にいえば、不偏推定量を得るためには条件付き期待値が説明変数に依存しないことが必要である。また線形推定量のなかで最小分散を実現するには、条件付き分散が説明変数に依存しないことが求められる。

しかし別の分散推定を用いれば、推定量は依然として正規分布に近似できることが知られている。[^08-regression2-2]
すなわち説明変数と誤差項が無相関であっても独立とまでは言えない状況では、分散をロバストに推定する必要がある。
この代替的な分散をロバスト分散と呼ぶ。誤差の分散が説明変数によって変わるような状況（不均一分散）でも、推定係数の信頼区間を信頼できるようにするための工夫である。

[^08-regression2-2]: 正確には観測される変数に 4 次のモーメントが存在するという仮定が必要となる。この仮定の直感的な意味は極端な外れ値が存在しないことである。

R では `AER` パッケージを使うとロバスト分散を簡単に計算できる。`vcovHC()` を `coeftest()` に渡すだけで、White（1980）型の頑健標準誤差が得られる。
次のコマンド `coeftest` を実行すればよい.

```{r}
#| message: false
#| warning: false
coeftest(fm1,vcov=vcovHC)
```

`coeftest` コマンドのオプション `vcov=vcovHC` を指定することで, 不均一分散に頑健な（heteroskedasticity-consistent）標準誤差を用いた検定が実行される.
`vcovHC` は分散共分散行列をロバスト推定する関数である.

この結果で標準誤差が変化していることが分かる。
ただし STATA のデフォルト設定とは若干異なる。
STATA と同じにするには

```{r}
coeftest(fm1,vcov=vcovHC(fm1,type="HC1"))
```

としなければならない.
オプション `type="HC1"` は小標本補正を施したロバスト分散推定量を指定している.
これは STATA の既定設定と同じである。

またティー分布でなく正規分布とすることもできる.

```{r}
coeftest(fm0,vcov=vcovHC,df=Inf)
```

オプション `df=Inf` を追加することで, 標準正規分布を用いた検定を実行する.

複数の係数についての検定は `waldtest` を実行すればよい.

```{r}
waldtest(fm0,fm1,vcov=vcovHC)
```

オプション `vcov=vcovHC` を指定することで, ロバスト分散を用いたワルド検定を実行する.

先の結果はエフ検定であるが, カイ二乗検定を実施するには以下を実施すればよい.

```{r}
waldtest(fm0,fm1,vcov=vcovHC, test="Chisq")
```

オプション `test="Chisq"` を追加することで, エフ統計量の代わりにカイ二乗統計量を用いた検定を実行する.

近年の `estimatr` パッケージを使うと `lm_robust()` でロバスト分散を持つ推定を直接実行できる。推定と同時にヘテロスケダスティシティ対策の標準誤差が得られるので、コードを簡潔に保ちたい場合に有用である。

```{r}
fm2<- lm_robust(y~x*w,data=df)
summary(fm2)
```

`lm_robust` コマンドは回帰分析を実行し, デフォルトでロバスト標準誤差を計算する.
これにより `lm()` と `coeftest()` を別々に呼び出す手間が省ける。

`se_type = "stata"` を指定すると STATA と同じ補正が掛けられる。

また以下のオプションをつければ分散均一の場合も計算できる.

```{r}
fm3<- lm_robust(y~x*w,data=df,se_type = "classical")
summary(fm3)
```

オプション `se_type = "classical"` を指定すると, 通常の（ロバストでない）標準誤差を計算する.
これは `lm` コマンドの結果と同じである.

## 分散均一の検定

誤差項が説明変数と独立な場合と、単に無相関であるだけの場合では標準誤差の推定方法が異なる。
正確には、条件付き分散が説明変数に依存するか否かが標準誤差の推定量を分ける条件となる。実務で言えば、残差の分布を見て異常に広がりが大きい領域があるかどうかを確認することが、ロバスト手法を使うべきかどうかの判断材料になる。
この性質を分散均一（homoskedasticity）という。

誤差項の分散が均一かどうかは検定可能である.
有名な検定方法としてBP (Breusch-Pagan) 検定というものがある.
BP検定は帰無仮説が分散均一で, 対立仮説が分散が説明変数と線形関係になっている場合の検定である.

残差の自乗を被説明変数として回帰分析をおこない, その決定係数に観測数をかけたものが検定統計量となる.
以下ではBP検定統計量を手動で計算している.

```{r}
bpt <- lm(I(resid(fm1)^2)~w*x,data=df)
(bpt <-nrow(df)*summary(bpt)$r.squared)
1-pchisq(bpt,df=3)
```

最初の行では, `fm1` の残差の二乗（`resid(fm1)^2`）を被説明変数とし, `w*x` を説明変数として回帰分析を実行している.
`I()` 関数は, 数式内で算術演算を実行するために用いる.
2行目では, その決定係数に観測数を掛けてBP検定統計量を計算している.
3行目では, 自由度3（説明変数の数）のカイ二乗分布のもとでP値を計算している.

ここでの例ではP値が5%を超えているので帰無仮説を棄却できないので, 分散均一を仮定してよいことが示唆されている.

R では `bptest` コマンドを用いて簡単にBP検定を実施できる.

```{r}
bptest(fm1)
```

`bptest` コマンドは自動的にBP検定統計量とP値を計算してくれる.

これまでのBPテストは誤差項の分散が説明変数の線形関係あることを暗黙に仮定している.
非線形性を考慮するために説明変数の二次項を導入した分散不均一性の検定をホワイト検定という.
説明変数が複数ある場合ホワイト検定は煩雑になるため, 被説明変数の予測値を使って計算することがある.
そのときホワイトテストは以下で実施する.

```{r}
wht <- lm(I(resid(fm1)^2)~fitted(fm1)+I(fitted(fm1)^2),data=df)
(wht <- nrow(df)*summary(wht)$r.squared)
1-pchisq(wht,df=2)
```

最初の行では, 残差の二乗を被説明変数とし, 予測値（`fitted(fm1)`）とその二乗を説明変数として回帰分析を実行している.
これにより分散の非線形性を検出できる.
2行目では, その決定係数に観測数を掛けてホワイト検定統計量を計算している.
3行目では, 自由度2のカイ二乗分布のもとでP値を計算している.

ホワイト検定でも分散均一が示唆されている.

もしくは `bptest` コマンドに予測値とその二乗を指定して実行することもできる.

```{r}
bptest(fm1,~fitted(fm1)+I(fitted(fm1)^2))
```

このコマンドは上記の手動計算と同じ結果を返す.

このように分散均一性は検定することが可能であるが, そもそも分散均一が疑われる場合は, ロバスト分散で推定するので十分であるため最近の実証分析ではこの検定は実施されない.
