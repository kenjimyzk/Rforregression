---
output: 
  html_document:default
  html_notebook:default
editor_options: 
  markdown: 
    wrap: sentence
---

# 現代的仮定のもとでの最小二乗法

```{r}
#| message: false
#| warning: false
library(AER)
library(estimatr)
```

前節において以下の仮定を置いていた.

-   $(x_i,y_i)$ は独立同一分布にしたがう.
-   $E[u_i]=0$ である.
-   $u_i$ と $x_i$ は独立である.
-   $u_i$ は正規分布にしたがう.

これらの仮定を緩めることで分析にどのような影響をあたえるのかを見ていく.

仮想的に以下のモデルを考える.

```{r}
N <- 100
x<-runif(N)
w<-sample(c("H","T"),N,replace=TRUE)
y <- 10 + 2*x + ifelse(w=="H",1,0) + rnorm(N)
df <- data.frame(w,x,y)
```

作図すると以下である.

```{r}
plot(y~x)
```

## 正規性の仮定について

十分な観測値が得られるばあい, $u_i$ が正規分布にしたがっていないくても, 中心極限定理定理より, 最小二乗法推定量は正規分布に近似できる.

ここの係数ゼロのティー検定について, ライブラリ `AER` を導入して `coeftest` を用いればよい.
まず `lm` コマンドを用いて2つのモデルを推定する.
`fm1` は説明変数 `x` とダミー変数 `w` およびそれらの交差項を含むモデル, `fm0` は `x` のみを含むモデルである.

```{r}
fm1 <- lm(y~x*w,data=df)
fm0 <- lm(y~x,data=df)
coeftest(fm1,df=Inf)
```

`coeftest` コマンドは係数の検定を実行する関数である.
オプション `df=Inf` を指定すると, ティー分布の代わりに標準正規分布（自由度無限大のティー分布）を用いた検定を実行する.
これは大標本のもとでの漸近的な検定である.
ただ十分なデータのもとではティー値のままでもよい.

同様に複数制約の場合, エフ検定統計量に制約の数を乗じた統計量が 自由度が制約数のカイ二乗分布にしたがうことが知られている.
これをR で実施するには `waldtest` を用いればよい.
`waldtest` コマンドは制約のあるモデル（`fm0`）と制約のないモデル（`fm1`）を比較して, 複数の係数がゼロかどうかを検定する関数である.

```{r}
waldtest(fm0,fm1,test="Chisq")
```

オプション `test="Chisq"` を指定すると, エフ検定統計量に制約の数を乗じた統計量が自由度が制約数のカイ二乗分布にしたがうことを利用した検定を実行する.
これは大標本での漸近的な検定である.

エフ検定も十分なデータのもとではそのままでよいであろう.

オプション `test` を付けなければエフ検定を実施する.

```{r}
waldtest(fm0,fm1)
```

この結果はエフ統計量とそのP値を表示している.

これは `anova` コマンドと同じである.

```{r}
anova(fm0,fm1)
```

`anova` コマンドも2つのモデルを比較してエフ検定を実行する.

複数制約の検定としてLM検定というのもある.
制約付きの回帰分析を実行し, その残差を制約なしのモデルの説明変数に回帰する.
その決定係数に観測数を掛けた統計量が自由どが制約の数のカイ二乗分布にしたがうことが知られている.

以下ではLM検定統計量を手動で計算している.

```{r}
lmt <- lm(I(resid(fm1))~w*x,data=df)
(lmt <- nrow(df)*summary(lmt)$r.squared)
1-pchisq(lmt,df=1)
```

最初の行では, `fm1` の残差（`resid(fm1)`）を被説明変数とし, `w*x` を説明変数として回帰分析を実行している.
2行目では, その決定係数（`summary(lmt)$r.squared`）に観測数（`nrow(df)`）を掛けてLM検定統計量を計算している.
3行目では, `pchisq` コマンドを用いて自由度1のカイ二乗分布のもとでP値を計算している.

## 誤差項と説明変数が独立の仮定について

また $u_i$ と $x_i$ は独立でなく, $u_i$ と $x_i$ が無相関という弱い条件のもとでも, 一致推定量であることが知られている.
ただ不偏推定量は保証できない.
また 線形推定量のなかで最小の分散とも言えない.[^08-regression2-1]
また独立のときの標準誤差の推定量が一致推定量でない.

[^08-regression2-1]: 正確にいえば, 不偏推定量のとめには条件付き期待値が説明変数に依存しないことが必要である.
    また線形推定量のなかで最小の分散になるためには 条件付き分散が説明変数に依存しないことが必要である.

ただし, 別の分散のもとで正規分布に近似できることがしられている.[^08-regression2-2]
つまり, 説明変数と誤差項が無相関であるが, 独立とまでは言い切れない場合, 最小二乗推定量を実行した際, 別の方法で分散を推定する必要がある.
この別の分散をロバスト分散という.

[^08-regression2-2]: 正確には観測される変数に4次のモーメントが存在するという仮定が必要となる.
    この仮定の直感的な意味は異常値が存在しないことである.

R でロバスト分散を推定するにはパッケージ `AER` を導入するのが簡単である.
次のコマンド `coeftest` を実行すればよい.

```{r}
#| message: false
#| warning: false
coeftest(fm1,vcov=vcovHC)
```

`coeftest` コマンドのオプション `vcov=vcovHC` を指定することで, 不均一分散に頑健な（heteroskedasticity-consistent）標準誤差を用いた検定が実行される.
`vcovHC` は分散共分散行列をロバスト推定する関数である.

先の値と標準誤差が違っていることが確認できるであろう.
ただこの値は STATA と少し異なっている.
STATA と同じにするには

```{r}
coeftest(fm1,vcov=vcovHC(fm1,type="HC1"))
```

としなければならない.
オプション `type="HC1"` は小標本補正を施したロバスト分散推定量を指定している.
これはSTATAのデフォルト設定と同じである.

またティー分布でなく正規分布とすることもできる.

```{r}
coeftest(fm0,vcov=vcovHC,df=Inf)
```

オプション `df=Inf` を追加することで, 標準正規分布を用いた検定を実行する.

複数の係数についての検定は `waldtest` を実行すればよい.

```{r}
waldtest(fm0,fm1,vcov=vcovHC)
```

オプション `vcov=vcovHC` を指定することで, ロバスト分散を用いたワルド検定を実行する.

先の結果はエフ検定であるが, カイ二乗検定を実施するには以下を実施すればよい.

```{r}
waldtest(fm0,fm1,vcov=vcovHC, test="Chisq")
```

オプション `test="Chisq"` を追加することで, エフ統計量の代わりにカイ二乗統計量を用いた検定を実行する.

最近開発されたパッケージ `estimatr`のコマンド　`lm_robust`　を用いるとロバスト分散のもとの推定値が簡単に計算できる.

```{r}
fm2<- lm_robust(y~x*w,data=df)
summary(fm2)
```

`lm_robust` コマンドは回帰分析を実行し, デフォルトでロバスト標準誤差を計算する.
これにより `lm` と `coeftest` を別々に実行する手間が省ける.

オプション　`se_type = "stata"` を用いればSTATAと同じ計算が可能である.

また以下のオプションをつければ分散均一の場合も計算できる.

```{r}
fm3<- lm_robust(y~x*w,data=df,se_type = "classical")
summary(fm3)
```

オプション `se_type = "classical"` を指定すると, 通常の（ロバストでない）標準誤差を計算する.
これは `lm` コマンドの結果と同じである.

## 分散均一の検定

誤差項が説明変数と独立のときと無相関のときでは標準誤差の推定量が異なる.
正確にいうと, 条件付き分散が説明変数に依存するかどうかによって標準誤差の推定量が異なる.
このことは分散均一と呼ばれている.

誤差項の分散が均一かどうかは検定可能である.
有名な検定方法としてBP (Breusch-Pagan) 検定というものがある.
BP検定は帰無仮説が分散均一で, 対立仮説が分散が説明変数と線形関係になっている場合の検定である.

残差の自乗を被説明変数として回帰分析をおこない, その決定係数に観測数をかけたものが検定統計量となる.
以下ではBP検定統計量を手動で計算している.

```{r}
bpt <- lm(I(resid(fm1)^2)~w*x,data=df)
(bpt <-nrow(df)*summary(bpt)$r.squared)
1-pchisq(bpt,df=3)
```

最初の行では, `fm1` の残差の二乗（`resid(fm1)^2`）を被説明変数とし, `w*x` を説明変数として回帰分析を実行している.
`I()` 関数は, 数式内で算術演算を実行するために用いる.
2行目では, その決定係数に観測数を掛けてBP検定統計量を計算している.
3行目では, 自由度3（説明変数の数）のカイ二乗分布のもとでP値を計算している.

ここでの例ではP値が5%を超えているので帰無仮説を棄却できないので, 分散均一を仮定してよいことが示唆されている.

R では `bptest` コマンドを用いて簡単にBP検定を実施できる.

```{r}
bptest(fm1)
```

`bptest` コマンドは自動的にBP検定統計量とP値を計算してくれる.

これまでのBPテストは誤差項の分散が説明変数の線形関係あることを暗黙に仮定している.
非線形性を考慮するために説明変数の二次項を導入した分散不均一性の検定をホワイト検定という.
説明変数が複数ある場合ホワイト検定は煩雑になるため, 被説明変数の予測値を使って計算することがある.
そのときホワイトテストは以下で実施する.

```{r}
wht <- lm(I(resid(fm1)^2)~fitted(fm1)+I(fitted(fm1)^2),data=df)
(wht <- nrow(df)*summary(wht)$r.squared)
1-pchisq(wht,df=2)
```

最初の行では, 残差の二乗を被説明変数とし, 予測値（`fitted(fm1)`）とその二乗を説明変数として回帰分析を実行している.
これにより分散の非線形性を検出できる.
2行目では, その決定係数に観測数を掛けてホワイト検定統計量を計算している.
3行目では, 自由度2のカイ二乗分布のもとでP値を計算している.

ホワイト検定でも分散均一が示唆されている.

もしくは `bptest` コマンドに予測値とその二乗を指定して実行することもできる.

```{r}
bptest(fm1,~fitted(fm1)+I(fitted(fm1)^2))
```

このコマンドは上記の手動計算と同じ結果を返す.

このように分散均一性は検定することが可能であるが, そもそも分散均一が疑われる場合は, ロバスト分散で推定するので十分であるため最近の実証分析ではこの検定は実施されない.
